[
{
	"uri": "http://kimmj.github.io/jenkins/install/",
	"title": "Jenkins Install",
	"tags": ["jenkins", "install"],
	"description": "",
	"content": "Download docker-compose.yaml 링크를 참조하여 docker-compose.yml을 다운로드 받습니다.\ncurl -sSL https://raw.githubusercontent.com/bitnami/bitnami-docker-jenkins/master/docker-compose.yml \u0026gt; docker-compose.yml 현재 yaml은 다음과 같은 구성입니다.\nversion: \u0026#39;2\u0026#39; services: jenkins: image: \u0026#39;bitnami/jenkins:2\u0026#39; ports: - \u0026#39;80:8080\u0026#39; - \u0026#39;443:8443\u0026#39; - \u0026#39;50000:50000\u0026#39; volumes: - \u0026#39;jenkins_data:/bitnami\u0026#39; volumes: jenkins_data: driver: local 여기서 몇가지 설정을 추가해주도록 합니다.\nversion: \u0026#39;2\u0026#39; services: jenkins: image: \u0026#39;bitnami/jenkins:2\u0026#39; ports: - \u0026#39;38080:8080\u0026#39; - \u0026#39;38443:8443\u0026#39; - \u0026#39;50000:50000\u0026#39; volumes: - \u0026#39;jenkins_data:/bitnami\u0026#39; volumes: jenkins_data: driver: local driver_opts: type: none device: $PWD/jenkins_data o: bind jenkins_data는 jenkins가 사용할 데이터들입니다. 이를 local에 폴더로 만들어줍니다.\nmkdir jenkins_data 그 다음 실행합니다.\ndocker-compose up -d http://$IP:38080 으로 접속할 수 있습니다. 기본 ID/PASSWD는 (user/bitnami)입니다.\nReference  https://hub.docker.com/r/bitnami/jenkins/  "
},
{
	"uri": "http://kimmj.github.io/english/himym/season2/episode01/",
	"title": "Episode01",
	"tags": [],
	"description": "",
	"content": "Hey, cut her some slack.\nDo you know why you're not over Lily yet?\nI think he's beyond repair.\nEat Haagen-Dazs and watch Love Actually till your periods sync up?\nThat's really the only reason I've been able to hold it together so far this summer.\nYou are the miserable, whining, shampoo-sniffing ghost of Marshall, and frankly, a guy like you doesn't have a shot in hell with a girl like Lily.\nBut if you go down there right now like this, you're going to blow it for him, and he's never going to forgive you.\nBold. Bold to go for the car.\nSo you're a gun nut?\nI was so freaked out, and I got up to my room, and there was my roommate, lying on the bed with his feet up on the wall\nIt took him 67 days and one really disgusting batch of pancakes..\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode1/",
	"title": "Episode1",
	"tags": [],
	"description": "",
	"content": "Generated by Language Learning with Netflix\n   Eng Kor     OLDER TED: Kids, I'm gonna tell you an incredible story. 얘들아, 아빠가 굉장한 얘기를 해 주마   The story of how I met your mother. 어떻게 네 엄마를 만났는지 말이야   We being punished for something? OLDER TED: No. - 저희 벌받는 거예요? - 아니   Yeah, is this gonna take a while? 오래 걸려요?   OLDER TED: Yes. Twenty-five years ago, before I was Dad, I had this whole other life. 응. 25년 전, 아빠가 되기 전에 완전히 다른 삶을 살았어   It was way back in 2005. 오래전, 2005년이었어   I was 27, just starting to make it as an architect 스물일곱의 난 막 건축가로 자리 잡고   and living in New York with Marshall, my best friend from college. 대학 때 절친 마셜과 뉴욕에서 살고 있었지   My life was good. And then Uncle Marshall went and screwed the whole thing up. 잘 살고 있었는데 마셜 삼촌이 일을 다 망쳤어   Will you marry me? 나랑 결혼해 줄래?   Yes. Perfect. And then you're engaged, 그래, 완벽해! 이제 약혼했으니   you pop the champagne, you drink a toast, 샴페인 터뜨리고 건배하고   you have sex on the kitchen floor. 부엌에서 섹스하겠네   Don't have sex on our floor. Got it. - 부엌에선 하지 마 - 알았어   Thanks for helping me plan this out, Ted. 테드, 도와줘서 고마워   Dude, are you kidding? It's you and Lily. 무슨 소리야? 너하고 릴리 일이잖아   I've been there for all the big moments of you and Lily. 너희의 중요한 순간마다 난 늘 함께였어   The night you met, your first date, other first things. 첫 만남, 첫 데이트 또 첫 번째 그것까지   Yeah, sorry, we thought you were asleep. 미안해 너 자는 줄 알았어   It's physics, Marshall. 물리 법칙 몰라?   If the bottom bunk moves, the top bunk moves, too. 아래 침대가 흔들리면 위층 침대도 흔들려   My God, you're getting engaged tonight. 세상에, 너 오늘 약혼하네?   Yeah. What are you doin\u0026rsquo; tonight? 응, 넌 오늘 밤에 뭐 할 거야?   OLDER TED: What was I doing? 아빤 뭘 했을까?   Here, Uncle Marshall was taking the biggest step of his life. 마셜 삼촌이 인생의 큰 변화를 맞이했을 때   And me? I'm calling up your Uncle Barney. 난 바니 삼촌에게 전화했단다   Hey, so you know how I've always had a thing for half-Asian girls? 내가 아시아계 혼혈 여자 좋아하는 거 알지?   Well, now I've got a new favorite. Lebanese girls. 요새 취향이 바뀌었어 레바논 여자야   Lebanese girls are the new half-Asians. 이제 레바논 여자가 내 취향이야   Hey, you wanna do something tonight? 오늘 밤에 한잔 어때?   Okay, meet me at the bar in 15 minutes. And suit up! 좋아, 15분 후 바에서 보자 정장 입어!   Hey. Where's your suit? 바니 정장 입으랬잖아   Just once, when I say \u0026ldquo;suit up,\u0026rdquo; I wish you'd put on a suit. 정장 입으라고 하면 한 번쯤 입어 주면 안 돼?   I did. That one time. 한 번 입었잖아   It was a blazer. 그건 블레이저였어   You know, ever since college it's been Marshall and Lily and me. 대학 때부터 난 늘 마셜, 릴리와 함께였는데   Now it's gonna be Marshall and Lily and me. 이제 걔들과 난 별개야   They'll get married, start a family. 둘은 곧 결혼할 테고   Before long, I'm that weird middle-aged bachelor their kids call \u0026ldquo;Uncle Ted.\u0026rdquo; 오래지 않아 난 노총각이 돼서 테드 삼촌 소리나 듣겠지   I see what this is about. 왜 그러는지 알겠다   Have you forgotten what I said to you the night we met? 우리 처음 만난 날 내가 한 말 잊었어?   Ted, I'm gonna teach you how to live. 테드, 내가 사는 법을 가르쳐 줄게   Barney. We met at the urinal. 난 바니야 오줌 눌 때 봤지   Oh, right. Hi. 그랬지   Lesson one, lose the goatee. It doesn't go with your suit. 첫째, 수염 깎아 정장하고 안 어울리니까   I'm not wearing a suit. Lesson two, get a suit. - 정장 안 입었는데 - 둘째, 정장을 살 것   Suits are cool. Exhibit A. 정장이 얼마나 멋진데. 봐, 증거 1호   Lesson three, don't even think about getting married till you're 30. 셋째, 서른 전에는 결혼 생각을 하지 말 것   Thirty. Right, you're right. 맞아, 서른이랬지   I guess it's just, your best friend gets engaged, you start thinkin\u0026rsquo; about that stuff. 절친이 약혼한다니까 괜히 그런 것 같아   I thought I was your best friend. Ted, say I'm your best friend. 내가 절친 아니었어? 테드, 그렇다고 말해   You're my best friend, Barney. Good. 네가 내 절친이야   Then as your best friend, I suggest we play a little game I like to call, 좋았어, 절친으로서 게임이나 하자. 뭐냐면~   \u0026ldquo;Have you met Ted?\u0026rdquo; - \u0026lsquo;테드 만나 봤어요?\u0026lsquo;야   No, no, no, no, we're not playing \u0026ldquo;Have you met Ted.\u0026rdquo; 잠깐, 안 돼. 그런 게임 안 해   Hi, have you met Ted? 안녕, 테드 만나 봤어요?   Hi, I'm Ted. 안녕하세요, 테드예요   Yasmin. It's a very pretty name. - 야스민이에요 - 이름 참 예쁘네요   Thanks. It's Lebanese. 고마워요. 레바논 이름이죠   Hey. 왔어?   I'm exhausted. 너무 피곤해   It was finger-painting day at school 학교에서 핑거 페인팅 했는데   and a 5-year-old boy got to second base with me. 다섯 살짜리 꼬마가 내 가슴을 만졌어   Wow, you're cooking? 요리하는 거야?   Yes, I am. 그래   Are you sure that's a good idea after last time. 요리해도 괜찮겠어?   You looked really creepy without eyebrows. 지난번에 눈썹 다 타서 정말 징그러웠거든   I can handle this. I think you'll find I'm full of surprises tonight. 괜찮아, 오늘 밤엔 자기 놀랄 일이 많을걸?   So there's more surprises? Like what? 더 놀랄 일? 그게 뭔데?   OLDER TED: Marshall was in his second year of law school, 마셜은 로스쿨 2년 차라   so he was pretty good at thinking on his feet. 순발력이 뛰어났지   Boogedy boo! And that's all of them. 이게 다야   I'm gonna go cook. 가서 요리할게   I'm so happy for Marshall, I really am. 마셜을 진심으로 축하해요   I just couldn't imagine settling down right now. 난 정착하는 건 꿈도 못 꾸거든요   So do you think you'll ever get married? 결혼 생각은 있어요?   Well, maybe eventually. 언젠가는 하겠죠   Some fall day. Possibly in Central Park. 어느 가을날 센트럴 파크면 좋겠어요   Simple ceremony. We'll write our own vows. 스몰 웨딩에 서약서도 직접 쓰고   Band, no DJ. People will dance, I'm not gonna worry about it. DJ는 없을거고, 밴드도 부를 거예요 사람들은 알아서 춤추겠죠   Damn it, why did Marshall have to get engaged? 제길, 왜 마셜은 약혼하겠단 거야?   Yeah, nothing hotter than a guy planning out his own imaginary wedding, huh? 결혼식 상상이나 하다니 엄청나죠?   Actually, I think it's cute. Well, you're clearly drunk. - 귀여운데요? - 취하셨네요   One more for the lady! 여자분께 한 잔 더요!   Oh, hey, look what I got. 이것 좀 볼래?   Oh, honey, champagne. 자기야, 샴페인이네   Yeah. 그래   No, you are too old to be scared to open a bottle of champagne. 샴페인 병 따는 거 무서워할 나이는 지났잖아    I'm not scared. 안 무서워   Then open it. Fine. - 그럼 해 봐 - 알았어   Please, open it. 자기가 해 줘   Gosh, you are unbelievable, Marshall. 정말 못 말려   OLDER TED: There are two big questions a man has to ask in life. 인생에서 남자가 물어야 할 질문 두 가지가 있어   One you plan out for months, the other just slips out 하나는 몇 달을 계획하고 묻지만 다른 하나는   when you're half-drunk at some bar. 취하면 그냥 튀어나오지   Will you marry me? 나랑 결혼해 줄래?   You wanna go out sometime? 나중에 데이트할래요?   Of course, you idiot! 당연하지, 바보야!   I'm sorry, Carl's my boyfriend. 미안해요 칼이 남자 친구예요   What's up, Carl? 안녕하세요, 칼   I promised Ted we wouldn't do that. 부엌에선 안 하겠다고 약속했는데   Did you know there's a Pop-Tart under your fridge? 냉장고 밑에 팝타르트 있는 거 봤어?   No, but dibs. 아니, 내가 찜!   Where's that champagne? I wanna drink a toast with my fiancee. Oh. 샴페인 어디 있지? 내 약혼녀와 건배해야지   I don't know why I was so scared of this. It's pretty easy, right? 이걸 왜 무서워했지? 쉽잖아, 안 그래?   Why am I freaking out all of a sudden? This is crazy. I'm not ready to settle down. 갑자기 왜 이러지? 난 정착할 준비도 안 됐는데   How does Carl land a Lebanese girl? 칼은 어떻게 레바논 여자를 만났지?   The plan's always been don't even think about it until you're 30. 서른 전에는 결혼 생각 않기로 했는데   Exactly. The guy doesn't even own a suit. 맞아, 녀석은 정장도 한 벌 없는데   Plus, Marshall's found the love of his life. 마셜은 인생의 짝도 찾았잖아   Even if I was ready, which I'm not, 난 아직 준비도 안 됐지만   but if I was, it's like, \u0026ldquo;Okay, I'm ready. Where is she?\u0026rdquo; 설령 준비됐다 한들 나의 그녀는 어디 있는데?   OLDER TED: And there she was. 거기 그 여자가 있었단다   OLDER TED: It was like something from an old movie 옛날 영화를 보면   where the sailor sees the girl across the crowded dance floor 뱃사람이 군중 속에서 춤추는 여자를 보고   turns to his buddy and says, 친구에게 말하지   \u0026ldquo;See that girl? I'm gonna marry her someday.\u0026rdquo; 친구에게 말하지 \u0026lsquo;저 여자 보여? 저 여자랑 결혼할 거야\u0026rsquo;   Hey, Barney, see that girl? 바니, 저 여자 보여?   Oh, yeah. You just know she likes it dirty. 응, 음란한 걸 좋아하는 여자 같네   Go say hi. 가서 인사해   I can't just go say hi. I need a plan. 어떻게 그래 계획을 세워야지   I'm gonna wait until she goes to the bathroom, then I'll strategically place myself by the jukebox so that\u0026hellip; 화장실에 갔을 때 주크박스 옆에 서 있어야지   Hi, have you met Ted? 혹시 테드 만나 봤어요?   Hi. 안녕하세요   Let me guess. Ted. 맞혀 볼게요, 테드죠?   I'm sorry, Lily. 릴리, 정말 미안해   I'm so sorry. Take us to the hospital. 릴리, 정말 미안해 병원으로 가 주세요   Whoa, whoa, whoa. Did you hit her? 잠깐만, 여자를 때렸나?   Hit me? Please. This guy can barely even spank me in bed for fun. 설마요, 잠자리에서 재미로도 못 때리는걸요   He's all, like, \u0026ldquo;Oh, honey, did that hurt?\u0026rdquo; \u0026lsquo;안 아파?\u0026lsquo;라고 묻는 남자예요   And I'm, like, \u0026ldquo;Come on, let me have it, you pansy.\u0026rdquo; 오히려 제가 \u0026lsquo;어서 쳐, 호모야!\u0026lsquo;라고 해요   Wow, a complete stranger. No, no, no, it's okay. Go on. - 모르는 분께 실례를\u0026hellip; - 괜찮아요, 계속해요   So, these, uh, spankings, 그러니까, 때릴 때   are you in pajamas or au naturel? 잠옷 입고 해요? 다 벗고 해요?   So what do you do? A reporter for Metro News 1. 무슨 일 하세요? \u0026lsquo;메트로 뉴스 1\u0026rsquo; 기자예요   Oh. Well, kind of a reporter. 리포터라고 할 수 있죠   I do those dumb little fluff pieces at the end of the news. 뉴스 끝날 때 웃기는 단신을 다뤄요   You know, like, \u0026ldquo;Monkey who can play the ukulele.\u0026rdquo; 우쿨렐레를 연주하는 원숭이 같은 거요   But I'm hoping to get some bigger stories soon. 조만간 큰 건을 맡으면 좋겠어요   Bigger, like, uh, \u0026ldquo;Gorilla with an upright bass?\u0026rdquo; 더블베이스 연주하는 고릴라 같은 거요?   Sorry. You're really pretty. 미안해요 당신 정말 예쁘네요   Oh, your friends don't seem too happy. 친구들 기분이 별로인가 봐요   Yeah. The one in the middle just got dumped by her boyfriend. So tonight, every guy is \u0026ldquo;the enemy.\u0026rdquo; 가운데 애가 막 차여서 오늘 모든 남자가 적이죠   You know, if it'll make your friend feel better you could throw a drink in my face. I don't mind. 친구를 즐겁게 할 수 있다면 내 얼굴에 술 끼얹어도 돼요   She would love that. 친구가 좋아하겠어요   And it does look fun in the movies. 영화에서 보면 재미있어 보이던데   Hey, you wanna have dinner with me Saturday night? 토요일에 저녁 같이 할래요?   Oh, I can't. I'm going to Orlando for a week on Friday. 안 돼요, 금요일부터 일주일간 올랜도에 가거든요   Some guy's attempting to make the world's biggest pancake. 어떤 사람이 세계 최대 크기의 팬케이크 만든대요   Guess who's covering it? That's gonna take a week? - 누가 취재할까요? - 일주일이나요?   Yeah, he's gonna eat it, too. It's another record. 그걸 또 먹는다네요 또 다른 신기록이죠   Hey, what's takin\u0026rsquo; so long? 뭐가 이렇게 오래 걸려?   I know this is a long shot, but how about tomorrow night? 가능할지 모르겠지만 내일 저녁은 어때요?   Yeah. What the hell. 좋아요, 까짓거   Jerk! 멍청한 자식!   That was fun. 재미있었어요   De\u0026hellip; Wait for it \u0026hellip;nied. 역시나 거절당했지?   Denied. 거절당했어   We're goin\u0026rsquo; out tomorrow night. 내일 만나기로 했어   I thought we were playing Lazer Tag tomorrow night. 내일 레이저태그 하기로 했잖아   Yeah, I was never gonna go play Lazer Tag. 애초에 갈 생각 없었어   OLDER TED: The next night, I took her out to this little bistro in Brooklyn. 다음 날, 브루클린의 작은 식당에 데려갔어   That is one bad-ass blue French horn. 멋진 파란색 프렌치 호른이네요   Yeah. Sort of looks like a Smurf penis. 그렇네요 스머프 고추 같아요   OLDER TED: Son, a piece of advice. 아들아, 충고하마   When you go on a first date, you really don't want to say Smurf penis. 첫 데이트에서 \u0026lsquo;스머프 고추'는 말하지 마   Girls don't ordinarily like that. 보통 여자들은 안 좋아하거든   But this was no ordinary girl. 그런데 이 여자는 남달랐어   Lily. 릴리?   How long have you been sitting there? 언제부터 거기 있었어?   Stupid eye patch. 망할 안대 같으니   Mom, Dad, I have found the future Mrs. Ted Mosby. 엄마, 아빠 미래의 제 부인을 찾았어요   Marshall, how have I always described my perfect woman? 마셜, 내 이상형이 뭐랬지?   Ah. Let's see. She likes dogs? 보자, 개를 좋아해?   I've got five dogs. 개가 다섯 마리 있어요   She drinks Scotch? 위스키를 마셔?   I love a Scotch that's old enough to order its own Scotch. 아주 오래된 위스키를 좋아해요   Can quote obscure lines from Ghostbusters? \u0026lsquo;고스트버스터즈\u0026rsquo; 대사도 읊어야 해   \u0026ldquo;Ray, when someone asks you if you're a God, you say, \u0026lsquo;Yes!'\u0026rdquo; \u0026lsquo;레이, 누군가 네게 신이냐고 물으면 그렇다고 해\u0026rsquo;   And I'm saving the best for last. 그중에서도 최고는 말이야   Do you want these? I hate olives. 이거 드실래요? 난 올리브가 싫어요   She hates olives. Awesome! 올리브를 싫어한대! 완벽해!   The Olive Theory. 올리브 이론이네   The Olive Theory is based on my friends, Marshall and Lily. 올리브 이론은 제 친구 얘기인데   He hates olives, she loves them. And in a weird way, that's what makes them such a great couple. 한쪽은 싫어하고 한쪽은 좋아해서 멋진 커플이래요   Perfect balance. 완벽한 조화라나?   You know, I've had a jar of olives just sitting in my fridge forever. 우리 집 냉장고에 올리브 한 통 있어요   I could take them off your hands. 제가 치워 드리죠   They're all yours. 다 가지세요   Oh, it is on! 완전, 시작됐네!   It is on till the break of dawn. 이제 밤새워도 모자라겠는걸?   But, wait, it's only the break of 10:30. What happened? 잠깐, 이제 열 시 반인데 왜 벌써 왔어?   I gotta get one of those blue French horns for over my fireplace. 아까 본 프렌치 호른을 사서 벽난로 위에 걸어야겠어요   It's gotta be blue, it's gotta be French. 반드시 파란색이어야 하고 다른 건 안 돼요   No green clarinet? Nope. - 녹색 클라리넷은요? - 안 돼요   Come on, no purple tuba? 자주색 튜바도요?   It's a Smurf penis or no dice. 스머프 고추 아니면 안 돼요   There you are! 여기 있었네   We got a jumper. Some crazy guy on the Manhattan Bridge. 맨해튼 다리에 자살하려는 사람이 있어   Come on, you're covering it. 어서 와, 보도해야지   Um. All right, I'll be right there. 알았어요, 바로 갈게요   I'm sorry. 미안해요   I had a really great time tonight. 오늘 정말 즐거웠어요   Yeah, well. 네   So, did you kiss her? 그래서? 키스했어?   No, the moment wasn't right. 아니, 타이밍이 별로였어   Look, this woman could actually be my future wife. I want our first kiss to be amazing. 미래의 아내일지도 모르는데 첫 키스는 멋져야지   Oh, Ted, that is so sweet. 테드, 정말 다정하다   So, you chickened out like a little bitch. 그래서 겁먹고 꼬릴 내렸어?   What? I did not chicken out. 겁먹은 거 아니야   You know what? I don't need to take first kiss advice from some pirate who hasn't been single since the first week of college. 관두자 대학 입학부터 지금까지 커플인 사람한테 첫 키스 충고는 듣고 싶지 않아   Ted, anyone who's single would tell you the same thing. 싱글들도 똑같이 말할 거야   Even the dumbest single person alive. 세상에서 가장 멍청한 싱글도 그럴걸?   And if you don't believe me, call him. 못 믿겠으면 전화해 봐   Hey, loser, how's not playing Lazer Tag? 루저, 레이저태그 안 하니까 좋냐?   Because playing Lazer Tag is awesome. 이 게임 완전 끝내주는데   Oh, I killed you, Connor. Don't make me get your mom. 코너, 너 죽었어 네 엄마한테 이른다   Hey, listen, I need your opinion on something. 나 물어볼 게 있어   Okay, meet me at the bar in 15 minutes. And suit up! 좋아, 15분 뒤 바에서 봐 정장 입고!   So, these guys think I chickened out. What do you think? 얘네는 내가 겁먹었대 네 생각은 어때?   I can't believe you're still not wearing a suit. 넌 어떻게 된 게 아직도 정장을 안 입었냐?   She didn't even give me the signal. 아무런 신호도 없었어   What, is she gonna bat her eyes at you in Morse code? 그럼 눈으로 모스 부호라도 보내야 하냐?   \u0026ldquo;Ted, kiss me.\u0026rdquo; No, you just kiss her. \u0026lsquo;테드, 키스해 줘요\u0026rsquo; 그냥 키스하면 된다고!   Not if you don't get the signal. 신호도 안 보냈는데!   Did Marshall give me the signal? 마셜이 신호 보냈어?   No! I didn't, I swear. 천만에 절대 안 그랬어, 맹세해   But, see, at least tonight, I get to sleep knowing Marshall and me, never gonna happen. 최소한 오늘밤에 난 잠에 들며 마셜과 난 안된다는걸 알겠지   You should've kissed her. 키스했어야지   Oh, I should've kissed her. Well, maybe in a week when she gets back from Orlando. 키스를 놓치다니 일주일 뒤에 올랜도에서 돌아올 때는 어떨까?   A week? That's like a year in hot-girl time. She'll forget all about you. 일주일? 미녀에게 일주일은 1년이지. 넌 기억도 못 할걸?   Mark my words, you will never see that one again. 잘 들어 그 여자 다시 못 볼 거야   There she is. 저기 있네   Ooh. She's cute. Hey, Carl, turn it up. 저기 있네 귀엽다 칼, 소리 좀 올려 줘요   \u0026hellip;persuaded him to reconsider. 설득에 성공했습니다   At which point the man came down off the ledge, 그제야 남자는 난간에서 내려왔고   giving this bizarre story a happy ending. 자살 소동은 잘 마무리됐습니다   Reporting from Metro 1 News, back to you, Bill. The guy didn't jump. - 메트로 뉴스 1의\u0026hellip; - 남자가 안 뛰었군   I'm gonna go kiss her. 가서 키스해야겠어   Right now. Look, dude, it's midnight. 지금? 야 지금 한밤중이야   As your future lawyer, I'm gonna advise you 미래의 네 변호사로서 충고하지   that's freakin\u0026rsquo; crazy. I never do anything crazy. - 이건 미친 짓이야 - 난 미친 짓을 안 해왔어   I'm always waiting for the moment, planning the moment. 늘 때를 기다리고 계획만 짜고 있지   Well, she's leavin\u0026rsquo; tomorrow and this may be the only moment I'm gonna get. 내일 떠나니까 지금이 유일한 기회야   I gotta do what that guy couldn't. I gotta take the leap. 저 남자가 못 한 걸 해야 해 뛰어들어야 한다고   Okay, not a perfect metaphor 비유가 적절하진 않군   \u0026lsquo;cause for me it's fall in love and get married and for him it's death. 난 사랑에 뛰어드는 거지만 저 남잔 죽음이었으니까   Actually, that is a perfect metaphor. 사실 정확한 비유였어   By the way, did I congratulate you two? 너희들 약혼은 축하했던가?   I'm doing this. 가야겠어   Let's go. 우리도 가자   Word up. We're coming with you. - 당근이지 - 우리도 같이 갈게   Barney? 바니, 넌?   All right, but under one condition. 좋아, 하지만 조건이 있어   Look at you, you beautiful bastard, you suited up. 이 자식, 정장 입으니까 얼마나 멋지냐   This is totally going in my blog. 블로그에 올려야지   Stop the car. Uh, pull over right here. 잠깐만 차 좀 세워 주세요   I gotta do something. 할 일이 있어   Excuse me. Pardon me, just a sec. 실례합니다, 잠시만요   Enjoy your coffee. 커피 맛있게 드세요   Hey! 저기요, 이봐요!   Go, go, go! 빨리 출발하죠!   Everybody brings flowers. 보통은 꽃을 준비하는데..   Okay, moment of truth. Wish me luck. 이제, 중요한 순간이야 행운을 빌어 줘   Ted's gonna get it on with a TV reporter. 테드가 TV 리포터와 자다니   \u0026ldquo;This just in.\u0026rdquo; Okay. \u0026lsquo;방금 들어온 소식입니다\u0026rsquo; 괜찮았어?   Kiss her, Ted. Kiss her good. 키스해, 테드! 잘하라고   Kiss the crap out of that girl. 키스로 끝내 버리는 거야   Marshall, remember this night. 마셜, 오늘 밤을 기억해 둬   When you're the best man at our wedding and you give a speech, you're gonna tell this story. 내 결혼식 때 들러리로서 이 얘기를 해야 할 테니까   Why does he get to be the best man? I'm your best friend! 왜 마셜이 들러리야? 내가 네 절친이잖아!   OLDER TED: As I walked up to that door, a million thoughts raced through my mind. 집 앞으로 걸어갈 때 온갖 생각을 다 했지만   Unfortunately, one particular thought did not. 그만 한 가지를 깜빡했어   I've got five dogs. 개가 다섯 마리 있어요   Not good, not good. 안 좋아   No! Get back in there. - 안 돼 - 빨리 돌아가   You're wearing a suit! 정장도 입었잖아   ROBIN: Ted? 테드?   Hi. 반가워요   I was just, uh\u0026hellip; 그냥 저기\u0026hellip;   Come on up. 들어와요   MARSHALL: He's in. 들어갔어   So, Ranjit, you must have done it with a Lebanese girl? 저기, 란지트 레바논 여자하고 해 봤죠?   Okay, that's my Barney limit. 그래 이게 바니의 한계지   I'm gonna see if that bodega has a bathroom. 저 가게에 화장실 있겠지?   Actually, I'm from Bangladesh. 사실 난 방글라데시 출신이에요   The women hot there? 거기 여자들도 섹시해요?   Here's a picture of my wife. 우리 집사람 사진이에요   [WHISPERING] A simple \u0026ldquo;no\u0026rdquo; would have sufficed. 그냥 아니라고 했으면 충분했을텐데   She's lovely. 아름다우시네요   So, Ted, what brings you back to Brooklyn at 1:00 in the morning in a suit? 테드 새벽 한 시에 정장까지 입고 브루클린엔 무슨 일이죠?   I was just hoping to 그러니까\u0026hellip;   get those olives that you said I could have. 나한테 준다던 올리브 가져가려고요   Would you like those olives with some gin and vermouth? 올리브 안주로 칵테일 한잔할래요?   Are you trying to get me drunk? 나 취하게 하려고요?   For starters. 일단은요   So, Marshall, this Olive Theory based on you and Lily. 마셜, 올리브 이론이 - 너하고 릴리 얘기라며?   Yeah. 맞아   You hate olives. Lily loves them, you can't stand them. 넌 올리브를 싫어하고 릴리는 무척 좋아하지   Yeah, I hate olives. 그래, 올리브 싫어   Two weeks ago, Spanish bar on 79th Street. Dish of olives. You had some. What up? 2주 전 바에서 올리브 시켰을 때 너도 먹지 않았나?   You have to swear that this does not leave this cab. 이 얘기가 택시 밖으로 안새어 나간다고 맹세해   I swear. 맹세할게   I swear. 나도 맹세하지   On our first date, I ordered a Greek salad. 첫 데이트에 그리스 샐러드를 시켰는데   Lily asked if she could have my olives. 내 올리브를 먹어도 되느냐고 묻잖아   I said, \u0026ldquo;Sure, I hate olives.\u0026rdquo; 그래서 난 싫어한다고 먹으라고 했지   But you like olives. 너 올리브 좋아하잖아   Well, I was 18, okay? I was a virgin. 그때 난 열여덟이었고 총각이었어   Been waiting my whole life for a pretty girl to want my olives. 내 올리브를 먹어줄 미녀를 기다렸다고   Marshall, I'm gonna give you an early wedding present. 마셜, 결혼 선물 미리 줄게   Don't get married. 결혼하지 마   I think I like your Olive Theory. 당신 올리브 이론이 맘에 드네요   I think I like your new French horn. 당신 새 프렌치 호른이 맘에 드네요   I think I like your nose. 당신 코가 맘에 드네요   I think I'm in love with you. 당신을 사랑하는 것 같아요   ALL: What? 뭐라고?   BOTH: What? What? - 뭐라고요? - 뭐라고요?   Come on, man, you said your stomach's been hurting, right? 너 배가 아프다고 했지?   You know what that is? Hunger. You're hungry for experience. 그게 뭔지 알아? 배고픔이야. 넌 경험이 고픈 거라고   Hungry for something new. Hungry for olives. 뭔가 새로운 것이 고프고 올리브가 고픈 거라고   But you're too scared to do anything about it. 하지만 겁쟁이라 아무것도 못 하지   Yeah, I'm scared, okay? 그래, 나 겁쟁이야   But when I think of spending the rest of my life with Lily, 하지만 릴리와 함께 평생 살 생각을 하면   committing forever, no other women, 앞으로 한 여자에게만 헌신해야 한다고 해도   doesn't scare me at all. 하나도 겁 안 나   I'm marrying that girl. 릴리랑 결혼할 거야   Lily. 릴리   Lily, I like olives. 사실 나 올리브 좋아해   We'll make it work. 해결할 수 있을 거야   So, Orlando? You gonna hit Disney World? 올랜도에 가면 디즈니월드에도 가요?   You love me? Oh, God. 사랑한다고요?   I can't believe I said that. Why did I say that? 내가 그런말을 했다는게 안 믿겨지네요 왜 그랬을까요?   Who says that? 대체 누가 그런 소릴 하죠?   I should just go. 가야겠네요   Hold on. Wait a minute. 잠깐만요, 기다려요   I promised you these. 이거 주기로 했잖아요   Olives. Yeah. Thanks. I love you. 올리브네요, 고마워요 사랑해요   What is wrong with me? 대체 왜 이러는 거지?   Why are we still sitting here? Let's go. We can still make last call. 왜 안 가? 바 문 닫기 전에 가자   What do you say, Lil? \u0026ldquo;Yo-ho-ho, and a bottle of rum\u0026rdquo;? 어때, 릴리? 럼주로 나팔 한번 불어야지   \u0026lsquo;Cause you're a pirate? 해적답게 말이야   Okay, eye patch gone. 안대를 벗어야지   And we can't just abandon Ted. 테드는 어쩌고 그냥 가   If it doesn't go well up there, he's gonna need some support. 일이 잘 안되면 우리가 위로해줘야지   It's been, like, 20 minutes. 벌써 20분이나 됐어   Do you think they're doin\u0026rsquo; it? 하고 있을까?   You think they're doing it in front of the dogs? Doggie style. - 개 앞에서 하고있냐고? - 개처럼 후배위로?   I knew this girl in college, she had this Golden Retriever\u0026hellip; 대학 때 개를 키우던 여자가 있었는데\u0026hellip;   Okay, we can go to the bar. Just stop talking. 말은 그만하고 바에 가자   Hit it, Ranjit. 출발하죠   So, when you tell this story to your friends, could you avoid the word \u0026ldquo;psycho\u0026rdquo;? 친구들한테 내 얘길 하더라도 사이코란 표현은 피해 줘요   I'd prefer \u0026ldquo;eccentric.\u0026rdquo; 차라리 괴짜가 낫겠어요   Goodnight, psycho. 잘 가요, 사이코   Great. Um, how do I get to the F train? 망했네 F 기차는 어디서 타죠?   Oh. Um, two blocks, that way and take a right. 저쪽으로 두 블록 가서 오른쪽이에요   You know what? 그거 알아요?   I'm done being single. I'm not good at it. 싱글은 그만할래요 난 혼자 잘 못 지내요   Look, obviously, you can't tell a woman you just met you love her, but it sucks that you can't. 물론 처음 본 여자한테 사랑한다고 하면 안 되지만 꼭 안 될 건 없잖아요   I'll tell you something, though. If a woman, not you, just some hypothetical woman, 있잖아요, 어떤 여자가 당신 말고 가상의 여자요   were to bear with me through all this, I think I'd make a damn good husband 내 미숙함을 견뎌 준다면 난 정말 좋은 남편이 될 거예요   because that's the stuff I'd be good at. 난 그런 걸 잘해요   Stuff like makin\u0026rsquo; her laugh and bein\u0026rsquo; a good father 여자를 웃게 하고 좋은 아빠가 되고   and walking her five hypothetical dogs. Bein\u0026rsquo; a good kisser. 상상의 개 다섯 마리 산책시키고 키스 잘하는 것도요   Everyone thinks they're a good kisser. Oh, I've got references. - 다들 자기가 잘하는 줄 알죠 - 증명할 수 있어요   Goodnight, Ted. 잘 가요, 테드   And I'm a good handshaker. 악수도 잘해요   That's a pretty great handshake. 정말 멋진 악수군요   And that was it. I'll probably never see her again. 그게 끝이었어 다시는 못 보겠지   What? That was the signal. - 왜? - 그게 바로 신호였어   That long, lingering handshake. You should've kissed her. 악수를 오래 했잖아! 키스했어야지   There's no such thing as the signal. 세상에 신호 따윈 없어   But, yeah, that was the signal. 근데 그건 신호였어   Signal. 신호예요   Carl, thank you. 칼, 고마워요   There's something I gotta do. 샴페인 따는 건 내 몫이지   By the way, you should've kissed her. 그나저나, 키스했어야죠   Carl, you guys weren't there. 칼! 너희는 거기에 없었잖아   I am so turned on right now. 자기, 나 너무 흥분돼   Guys, trust me. I've seen the signal. That was not the signal. 신호가 뭔지 나도 아는데 그건 신호가 아니었대도   Yeah, Ted, we're not on you anymore. 알았으니까 네 얘긴 그만해   To my fiancee. To the future. - 내 약혼녀를 위해 - 미래를 위해   To one hell of a night. 끝내주는 밤을 위해!   That was not the signal. 그건 신호가 아니었어!   OLDER TED: I asked her about it years later, and, yeah, that was the signal. 몇 년 뒤에 물었더니 신호가 맞았다더구나   I could've kissed her. 키스했어야 했어   But that's the funny thing about destiny, it happens whether you plan it or not. 하지만 운명은 계획과 상관없이 일어나게 돼 있어   I mean, I never thought I'd see that girl again. 사실 다시는 못 볼 줄 알았거든   But it turns out, 근데 알고 보니   I was just too close to the puzzle to see the picture that was forming. 근데 알고 보니 퍼즐이 완성되기 바로 직전이었던 거야   Because that, kids, is the true story of how I met your Aunt Robin. 이게 내가 로빈 이모를 만나게 된 이야기란다   Aunt Robin? 로빈 이모요?   I thought this was how you met Mom. 엄마 얘기인 줄 알았는데   Will you relax? I'm getting to it. 조급해 마 그 얘기 할 거니까   Like I said, it's a long story. 아까 말했잖아 얘기가 길다고    "
},
{
	"uri": "http://kimmj.github.io/prometheus/install/",
	"title": "Install Prometheus",
	"tags": ["install", "prometheus"],
	"description": "",
	"content": "Prometheus Prometheus는 opensource monitoring system입니다. 음악을 하는 사람들이 많이 이용하는 사이트인 SoundCloud에서 개발된 오픈소스입니다.\nPromQL이라는 Query문을 사용하여 metric을 수집할 수 있습니다. 자세한 내용은 나중에 따로 포스트를 작성하도록 하겠습니다.\n이 문서에서는 docker-compose를 통해 간단하게 prometheus를 설치해볼 것입니다. 또한 prometheus와 뗄레야 뗄 수 없는 단짝 Grafana도 함께 설치할 것입니다.\nPrometheus의 설치 제가 docker-compose를 선호하는 이유는 너무나도 간단하게, dependency가 있는 어플리케이션을 설치할 수 있기 때문입니다. 아래에 예시에서도 잘 드러나있습니다.\n저는 monitoring/ 폴더 아래에 docker-compose.yaml이라는 이름으로 파일을 생성했습니다.\nversion: \u0026#39;3\u0026#39; networks: back-tier: services: prometheus: image: prom/prometheus restart: unless-stopped volumes: - ./config/prometheus.yml:/etc/prometheus/prometheus.yml ports: - \u0026#34;9090:9090\u0026#34; networks: - back-tier grafana: image: grafana/grafana:6.5.3 ports: - 9080:3000 user: \u0026#34;0\u0026#34; # $(id -u) https://community.grafana.com/t/new-docker-install-with-persistent-storage-permission-problem/10896/5 depends_on: - prometheus volumes: - ./grafana/provisioning/:/etc/grafana/provisioning/ - ./grafana_data:/var/lib/grafana networks: - back-tier 위의 예시에서 services.grafana.user=\u0026quot;0\u0026quot;으로 설정이 되어있는 것이 보이실 것입니다. 이 부분을 $(id -u)의 결과값으로 변경하시면 됩니다. 관련된 내용은 옆에 주석에서도 확인이 가능합니다.\n이렇게 하고난 뒤, 설치하는 방법은 너무나도 간단합니다.\ncd monitoring docker-compose up -d 잠시 내리고 싶을땐 다음과 같이 하면 됩니다.\ndocker-compose down 설정상, Prometheus는 9090 포트를 통해서 expose 되어있습니다. 또한 Grafana는 9080 포트를 사용하고 있습니다. Grafana의 기본 ID/PW는 admin/admin입니다.\n설정 Prometheus를 사용하기 위해서는 prometheus.yml이라는 파일을 관리해주어야 합니다. 이곳에서 어느 서비스의 metric을 가지고 올지 설정할 수 있습니다.\n해당 파일은 docker-compose.yaml을 참조해 보았을 때, monitoring/config/prometheus.yml을 수정하면 된다는 것을 알 수 있습니다. 수정 후에는 docker-compose down을 통해 잠시 내렸다가 docker-compose up -d를 통해 올리면 수정사항이 반영됩니다.\n"
},
{
	"uri": "http://kimmj.github.io/kubernetes/installation/",
	"title": "Install",
	"tags": [],
	"description": "",
	"content": "Kubernetes Install Install Kubernetes on bare-metal\n"
},
{
	"uri": "http://kimmj.github.io/kubernetes/installation/overview/",
	"title": "Overview",
	"tags": ["kubernetes", "install", "overview"],
	"description": "",
	"content": "저의 vm으로 구성한 클러스터를 설명드리고자 합니다.\n Cloud Provider: Kubernetes on-prem (4 VMs)  1 for master (4GB Mem, 2 CPU) 3 for worker (each 8GM Mem, 4 CPU)   Kubernetes 1.17.0 Storage Class: Ceph OS: Ubuntu 18.04.2 Server Internal Network: VirtualBox Host-Only Ethernet Adapter (192.168.x.0/24) External Network: Bridge to adapter (192.168.y.0/24)  한번에 쳐야하는 명령어가 많기 때문에, tmux를 사용해서 여러개의 pane을 생성하고 각각에 대해 ssh로 접속하였습니다.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/",
	"title": "Season1",
	"tags": [],
	"description": "",
	"content": "HIMWM Season1 "
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Spinnaker Installation spinnaker를 설치해 볼 것입니다.\n쉽지 않았던 여정들을 기록하려고 합니다.\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/overview/",
	"title": "Overview",
	"tags": ["install", "spinnaker"],
	"description": "",
	"content": "Overview of install Spinnaker 어떻게 Spinnaker를 설치 및 배포하는지 알아보도록 하겠습니다.\n가장 먼저 최소 사양을 확인해보도록 하겠습니다.\n링크 : https://www.spinnaker.io/guides/developer/getting-set-up/#system-requirements\n 램 18 GB CPU 4코어 Ubuntu 14.04, 16.04, 18.04  Spinnaker 자체가 클라우드 환경에만 배포가 가능하기 때문에, 아마도 \u0026ldquo;전체 클라우드를 합하여 저정도면 된다\u0026quot;를 의미하는 것 같습니다.\n설치 방법은 두가지로 나뉩니다.\n 테스트를 목적으로 Helm Chart를 통한 설치 실제로 사용할 목적으로 halyard를 통한 설치  저는 여기서 2번 halyard를 통한 설치를 해보려고 합니다.\n전체적인 프로세스를 먼저 설명드리자면 다음과 같습니다.\n halyard 설치 Cloud Provider(클라우드 제공자) 선택 배포 환경 선택 Storage Service 선택 배포 및 접속 config 백업하기  그리고 저는 다음과 같은 환경에서 테스트를 할 예정입니다.\n Cloud Provider: Kubernetes on-prem (4 VMs)  1 for master (4GB Mem, 1 CPU) 3 for worker (each 8GM Mem, 4 CPU)   Environment: Distributed installation on Kubernetes Storage Service: Minio Deploy and Connect: expose by NodePort OS : Ubuntu 18.04.2 Server  "
},
{
	"uri": "http://kimmj.github.io/ibiza/importance-of-record/",
	"title": "Importance of Record",
	"tags": ["record", "blog"],
	"description": "",
	"content": "기록의 중요성 몇개월 전부터 Spinnaker라는 툴을 가지고 일을 하기 시작했다.\n처음 halyard를 통해 deploy하기까지 꽤나 많은 시간을 소요했던 것으로 기억한다. 집에서 하는게 아니라 회사에서 구축을 해야했기 때문에, 프록시와 관련된 설정들이 너무나도 어려웠다. 특히 spinnaker의 docs가 제대로 되어있는 것도 아니기에, 문제가 하나 발생하면 이를 해결하는 데 너무나도 많은 시간이 걸렸다.\n하지만 나의 최대 실수는 바로 기록하지 않은 것이다.\n그렇게 많은 노력끝에 약 한달만에 첫 deploy를 할 수 있었는데, 이 때 했던 설정을 \u0026ldquo;나중에 정리해야지\u0026quot;라는 안일한 생각으로 지금까지 정리를 안하고 있었다.\n요즘들어 회사에서 spinnaker를 사용할 일이 잦아지고, 다른 시료에도 deploy하게되는 일이 많아졌는데 내가 기록을 해놓지 않음으로 인해서 많은 차질이 생기고 있다. 당장만 해도 deploy 자체를 할 수 없으며, 내가 예전에 해 두었던 pipeline 설정들이 다 날아가버려서 지금 복구하는 데 한숨만 나올 뿐이다.\n그 많은 정보들을 정리해두었다면, 로그를 남겨두었다면 이런 일은 발생하지 않았을수도 있다.\n오늘 난 기록의 중요성을 다시 한번 깨달았고, 차곡차곡 이 블로그에 쌓아두기로 마음먹었다. 하루에 하나씩 쓴다는 것은 어려운 일일지 모르지만, 그래도 최대한 자주 기록을 함으로써, 나의 성장에도 도움이 되고 다른 사람들의 암흑같은 여정에 한줄기 빛이 될 수 있으면 좋겠다.\n"
},
{
	"uri": "http://kimmj.github.io/ibiza/",
	"title": "Ibiza",
	"tags": [],
	"description": "",
	"content": "Ibiza 子曰\n學而時習之 不亦說乎\n배우고 때때로 익히니 이 또한 기쁘지 아니한가.\n"
},
{
	"uri": "http://kimmj.github.io/",
	"title": "Ibiza",
	"tags": [],
	"description": "",
	"content": "Ibiza "
},
{
	"uri": "http://kimmj.github.io/ansible/ansible-for-devops/getting-started-with-ansible/",
	"title": "Chapter 1 - Getting Started With Ansible",
	"tags": ["ansible", "ansible-for-devops"],
	"description": "",
	"content": "Ansible and Infrastructure Management On snowflakes1 and shell scripts 보통은 SSH를 통해서 접속하여 필요한 작업을 하고 접속을 종료한다. 이 때, 어떤 것들은 기록되고 어떤 것들은 기록되지 않는다. 결국 관리자가 똑같은 작업을 여러 서버에 해야하는 책임소지가 있다.\n서버가 동작 중일 때 몇가지 변경사항이 생기고 적용할 방법이 쉽다면 문제가 되진 않을 것이다. 그러나 불행하게도 대부분은 그렇지 않다.\n이 때 기존과 똑같은 서버를 만드려고 한다면 정말 많은, 쓸데없는 시간을 소비하게 된다.\nshell script로 보완을 하려고 하지만, 모든 edge case를 커버하기란 어려운게 현실이다.\nConfiguration management CFEngine, Puppet, Chef같은 서비스들이 이런 Infrastructure를 구성하는 툴로 사용되고 있었다. 하지만 command line configuration이 아닌 다른 방법을 새로 익혀야 한다. Puppet이나 Chef는 Ruby나 기타 커스텀 언어들에 대한 이해가 필요하다.\n반면 Ansible은 command line을 그대로 실행하게 한다. 따라서 기존의 스크립트를 이용할 수 있다. 이를 idempotent2 playbook으로 전환할 수 있다. command line에 익숙한 사람들에게는 훨씬 좋은 옵션이 될 것이다.\nAnsible은 변경사항들을 모든 서버에(default) push하고 추가적인 소프트웨어를 서버에 설치할 필요가 없다. 따라서 memory footprint, 관리를 위한 추가적인 daemon같은 것은 없다.\nIdempotence 멱등성은 여러번 동작을 해도 동일한 결과가 나온다는 속성이다.\n이는 configuration management tool의 중요한 기능으로 몇번을 실행하더라도 동일한 설정이 유지되어야 한다는 것을 의미한다. 많은 shell script가 한 번 이상 실행되면 의도하지 않은 결과를 발생시키는데, Ansible은 추가적인 설정 없이 동일한 결과가 나오게 한다.\n사실 대부분의 Ansible modules와 commands는 idempotent이고, 그렇지 않은 것은 Ansible에서 언제 command가 동작해야 하는지, 변경되거나 실패한 command의 구성이 어떤지를 제공하여 모든 서버에 대해 idempotent configuration을 유지하도록 도와준다.\nInstalling Ansible Ansible은 Python에만 dependency가 있다. Python이 있으면 pip로 설치가 가능하다.\nMac 환경이면 더 쉽다.\n Homebrew 설치 (홈페이지에서 설치) Python 2.7.x 설치 (brew install python) Ansible 설치 (sudo pip install ansible)  brew install ansible로 설치해도 되고 이 경우 update 시 brew를 사용하면 된다.\nWindows를 사용한다면 조금은 복잡하다. 둘 중 하나를 선택해서 설치하면 된다.\n Linux Virtual Machine을 사용해서 설치하기 Cygwin 환경에서 Ansible이 동작하도록 하기  Linux를 사용한다면 이미 Ansible이 설치되어 있을 수 있다.\npython-pip와 python-devel이 있다면 pip를 통해 Ansible을 설치할 수 있다. 이 때 \u0026ldquo;Development Tools\u0026quot;가 이미 설치되어 있어 gcc, make 등이 설치되어있음을 가정한다.\nsudo pip install ansible Fedora같은 시스템은 yum 패키지를 통해 설치하는 것이 가장 쉽다. RHEL/CentOS는 Ansible 설치 전에 EPEL의 RPM을 설치해야한다.\nyum -y install ansible Ubuntu에서의 가장 간단한 설치 방법은 apt package를 통해 설치하는 것이다.\nsudo apt-add-repository -y ppa:ansible/ansible sudo apt-get update sudo apt-get install -y ansible Ansible이 설치되고 나면 ansible --version으로 제대로 설치되어 있는지 확인한다.\nCreating a basic inventory file Ansible은 inventory file(보통, 서버들의 리스트)을 사용하여 서버와 통신한다. IP 주소를 domain name과 매칭시키는 hosts 파일처럼 Ansible inventory file은 서버(IP address이나 domain name)을 group에 매칭시킨다. Inventory file은 이보다 더 많은 것을 할 수 있지만 지금은 간단하게 하나의 서버에 대한 파일만 생성할 것이다. /etc/ansible/hosts(Ansible inventory file의 default location)에 파일을 다음과 같이 추가한다.\nsudo mkdir /etc/ansible sudo touch /etc/ansible/hosts 이제 파일을 수정한다. 이 때 sudo 권한으로 수정해야 한다.\n[example] www.example.com example은 우리가 관리하게 될 서버의 그룹이고, www.example.com은 그 그룹에 속하게 된다. ssh 포트가 22가 아니라면 www.example.com:2222처럼 하면 된다. Ansible이 ssh configuration을 확인하여 지정된 포트를 불러오지 않기 때문에 포트가 다를 경우 반드시 명시해 주어야 한다.\nRunning your first Ad-Hoc Ansible command Ansible과 inventory file을 설치하였으니, command를 실행시켜 잘 되는지 확인해볼 수 있다.\nansible example -m ping -u [username] 여기서 [username]은 ssh 접속할 때 사용하는 user를 입력하면 된다. 잘 된다면 ping의 결과들이 보일 것이고 안된다면 -vvvv 옵션을 추가해서 세부 결과를 확인할 수 있다. ssh username@www.example.com이 성공한다면 위의 명령어도 당연히 성공해야 한다.\nAnsible은 passwordless authentication을 가정한다. 따라서 ssh에 패스워드를 입력한다면, ssh-copy-id를 통해 패스워드 입력을 없앨 수 있다.\nansible example -a \u0026#34;free -m\u0026#34; -u [username] 위처럼 memory usage를 확인할 수 있다. 또한 df -h로 disk usage도 확인이 가능하다. 이런 방법으로 서버들에 에러가 없는지 확인할 수 있다.\nSummary configuration management와 Ansible에 대해 학습하였고, 이를 설치하고 서버에 대해 이야기하며 Ansible을 통해 서버에서 command를 실행시켜보았다.\n  문서화 하지 않고 구성하였기 때문에, 한번 구성하고 나면 동일하게 설정하기 힘든, 눈처럼 녹아버리는 서버 \u0026#x21a9;\u0026#xfe0e;\n 멱등의. 아무리 여러번해도 결과가 같음. \u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "http://kimmj.github.io/kubernetes/installation/install-kubeadm/",
	"title": "Install Kubeadm",
	"tags": ["install", "kubeadm"],
	"description": "",
	"content": "kubeadm은 Kubernetes cluster의 설정들을 관리하는 툴입니다.\nPrerequisites 먼저, 몇가지 전제사항이 있습니다.\n  모든 노드의 MAC 주소와 product_uuid가 달라야 합니다. ifconfig -a와 sudo cat /sys/class/dmi/id/product_uuid를 통해 알 수 있습니다.\n  network adapter를 확인합니다. 하나 이상의 network adapter가 있고, Kubernetes component들이 default route로 통신이 불가능하다면 IP route를 설정하여 Kubernetes cluster 주소가 적절한 adapter를 통해 이동할 수 있도록 해주는 것이 좋습니다.\n  iptables를 사용하는지 확인 Ubuntu 19.04 이후버전부터는 nftables라는 것을 사용한다고 합니다. 그러나 이는 kube-proxy와 호환이 잘 안되기 때문에 iptables를 사용해야한다고 하고 있습니다.\n다음과 같이 설정할 수 있습니다.\nsudo update-alternatives --set iptables /usr/sbin/iptables-legacy sudo update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy sudo update-alternatives --set arptables /usr/sbin/arptables-legacy sudo update-alternatives --set ebtables /usr/sbin/ebtables-legacy   필수 포트 확인\nControl-plane node(s)\n   Protocol Direction Port Range Purpose Used By     TCP Inbound 6443* Kubernetes API server All   TCP Inbound 2379-2380 etcd server client API kube-apiserver, etcd   TCP Inbound 10250 Kubelet API Self, Control plane   TCP Inbound 10251 kube-scheduler Self   TCP Inbound 10252 kube-controller-manager Self    Worker node(s)\n   Protocol Direction Port Range Purpose Used By     TCP Inbound 10250 Kubelet API Self, Control plane   TCP Inbound 30000-32767 NodePort Services** All    여기서 * 표시가 있는 것은 수정이 가능한 사항이라고 합니다. (API server의 port, NodePort Service로 열 수 있는 port의 범위)\n  container runtime 설치 여기에서는 Docker를 사용할 것입니다. Docker 홈페이지에는 script를 통해 최신 버전의 Docker를 다운로드 받는 방법을 제공합니다.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh   kubeadm, kubelet, kubectl 설치 Kubernetes에 필요한 세가지 툴을 설치하도록 하겠습니다. 간단하게 설명드리자면 kubeadm은 Kubernetes를 관리하는 툴이라고 생각하면 되고 kubelet은 명령을 이행하는 툴이라고 생각하면 됩니다. kubectl은 Kubernetes cluster와 통신하는 툴입니다.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl 마지막에 apt-mark를 통해 kubelet, kubeadm, kubectl의 버전을 고정시켰습니다.\n  이렇게 kubelet, kubeadm, kubectl을 설치하였으면 마지막으로 swap 영역을 제거할 것입니다. Kubernetes는 swap 영역이 없는 것이 필수 항목입니다. 따라서 다음의 명령어로 swap 영역을 삭제합니다.\nsudo swapoff -a 이는 현재 세션에서만 동작하고 재부팅시 해제됩니다. 따라서 /etc/fstab을 열고 swap 부분을 주석처리합니다.\n#/swapfile none swap sw 0 0 Reference https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/calico-network-policy/\nhttps://kubernetes.io/docs/concepts/cluster-administration/networking/\nhttps://docs.projectcalico.org/v3.11/getting-started/kubernetes/\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/install-halyard/",
	"title": "Install Halyard",
	"tags": ["spinnaker", "install", "halyard", "proxy"],
	"description": "",
	"content": "halyard란? halyard는 Spinnaker를 배포할 때 사용하는 CLI 툴입니다.\nhalyard는 Spinnaker 관련 설정들의 validation, 배포한 환경 백업, 설정 추가 및 변경에 사용됩니다.\n설치 방법 선택하기 총 2가지 방법으로 halyard를 설치할 수 있습니다.\n Debian/Ubuntu나 macOS에 직접 설치하기 Docker 사용하기  Spinnaker Docs에서는 실제 Production 환경이라면 직접 설치하는 방법을, 그게 아니라 간단하게 사용하려면 docker를 사용해도 된다고 하고 있습니다.\n그리고 한가지의 옵션이 더 있습니다.\n 인터넷이 되지 않는 환경 (프록시나 방화벽 등으로 halyard를 통한 설치가 어려운 경우)  이 글을 작성하고 있는 환경은 인터넷이 잘 되는 환경입니다. 그리고 두가지 모두 시도해 보도록 하겠습니다.\nDebian/Ubuntu나 macOS에 직접 설치하기 공식 Docs에서 halyard는 다음과 같은 환경에서 동작한다고 말하고 있습니다.\n Ubuntu 14.04, 16.04 or 18.04 (Ubuntu 16.04 requires Spinnaker 1.6.0 or later) Debian 8 or 9 macOS (tested on 10.13 High Sierra only)  이제 직접 설치를 시작해보도록 하겠습니다.\n시작하기 전에, halyard를 설치하기 위해서는 root 계정이 아닌 계정이 필요합니다. 만일 root만 있다면 spinnaker를 위한 계정을 생성해 줍니다.\nadduser spinnaker 위처럼 생성한 계정에 sudoers 권한을 줍니다.\nadduser spinnaker sudo 최신 버전의 halyard 다운로드 Debian/Ubuntu:\ncurl -O https://raw.githubusercontent.com/spinnaker/halyard/master/install/debian/InstallHalyard.sh macOS:\ncurl -O https://raw.githubusercontent.com/spinnaker/halyard/master/install/macos/InstallHalyard.sh 설치 sudo bash InstallHalyard.sh 확인 hal -v 추가사항 . ~/.bashrc를 실행하여 bash completion 활성화\n여기서 proxy 환경이라면 halyard의 jvm에 proxy 옵션을 추가해주어야 합니다.\nvi /opt/halyard/bin/halyard을 통해 halyard의 jvm 옵션을 추가할 수 있습니다.\nDEFAULT_JVM_OPTS=\u0026#39;\u0026#34;-Djava.security.egd=file:/dev/./urandom\u0026#34; \u0026#34;-Dspring.config.additional-location=/opt/spinnaker/config/\u0026#34; \u0026#34;-Dhttps.proxyHost=\u0026lt;proxyHost\u0026gt; -Dhttps.proxyPort=\u0026lt;proxyPort\u0026gt;\u0026#34; \u0026#34;-Dhttp.proxyHost=\u0026lt;proxyHost\u0026gt; -Dhttp.proxyPort=\u0026lt;proxyPort\u0026gt;\u0026#34;\u0026#39; 위의 설정에서 다음과 같이 proxy를 추가해줍니다. 그 다음 halyard를 재시동합니다.\nhal shutdown hal config 아랫줄의 hal config는 의도적으로 halyard를 구동시키기 위함입니다.\ndocker로 halyard 사용하기 다음의 명령어는 공식 docs에서 제공하는 명령어입니다.\ndocker run -p 8084:8084 -p 9000:9000 \\  --name halyard --rm \\  -v ~/.hal:/home/spinnaker/.hal \\  -it \\  gcr.io/spinnaker-marketplace/halyard:stable kubernetes로 배포하려 할 경우, kubectl 명령어에서 사용할 kubeconfig 파일이 필요합니다. 이 또한 -v 옵션으로 주어야 합니다. 그리고 그 kubeconfig 파일을 읽도록 설정해야 합니다.\ndocker run -p 8084:8084 -p 9000:9000 \\  --name halyard --rm \\  -v ~/.hal:/home/spinnaker/.hal \\  -v ~/.kube:/home/spinnaker/.kube \\  -e KUBECONFIG=/home/spinnaker/.kube/config -it \\  gcr.io/spinnaker-marketplace/halyard:stable 사실 5번째 줄의 -e KUBECONFIG=/home/spinnaker/.kube/config은 없어도 default로 들어가있는 설정입니다. 하지만 혹시나 위에서 /home/spinnaker/.kube가 아닌 다른곳을 저장공간으로 둔다면 아래의 설정도 바뀌어야 합니다.\n프록시 환경이라면 다음과 같이 JAVA_OPT를 추가해주어야 합니다.\ndocker run -p 8084:8084 -p 9000:9000 \\  --name halyard -d \\  -v ~/.hal:/home/spinnaker/.hal \\  -v ~/.kube:/home/spinnaker/.kube \\  -e http_proxy=http://\u0026lt;proxy_host\u0026gt;:\u0026lt;proxy_port\u0026gt; \\  -e https_proxy=https://\u0026lt;proxy_host\u0026gt;:\u0026lt;proxy_port\u0026gt; \\  -e JAVA_OPTS=\u0026#34;-Dhttps.proxyHost=\u0026lt;proxy_host\u0026gt; -Dhttps.proxyPort=\u0026lt;proxy_port\u0026gt;\u0026#34; \\  -e KUBECONFIG=/home/spinnaker/.kube/config \\  gcr.io/spinnaker-marketplace/halyard:stable 그래도 안된다면.. 아마도 관리가 엄격한 네트워크를 사용하고 계실 것이라고 예상됩니다. 저 또한 그랬으니까요.\nhalyard는 설정 및 버전등의 정보를 bucket (Google Cloud Storage)로 관리한다고 합니다. 따라서 이곳으로 연결이 되지 않는다면 validation, version list 등의 상황에서 timeout이 날 것입니다.\nSpinnaker에서는 이를 확인하기 위해 gsutil을 사용하여 bucket의 주소인 gs://halconfig에 연결할 수 있는지 확인해보라고 합니다.\n또는 curl을 이용해서도 확인이 가능합니다.\n먼저 gsutil은 google storage 서비스에 접속하는 CLI 툴입니다. Docs에서 설치방법을 확인하여 설치할 수 있습니다.\n설치가 완료되었다면 gsutil로 접속이 가능한지부터 확인합니다.\ngsutil ls gs://halconfig 두번째로 curl을 사용하는 방법입니다.\ncurl storage.googleapis.com/halconfig 결과물들이 나온다면 정상적으로 bucket에는 접속이 가능한 것입니다. hal config 명령어가 성공하지 않지만 bucket에 접속이 가능한 케이스는 아직 보지 못했습니다.\n우선 여기까지 해서 bucket에 접속이 불가능하다고 판단이 되면, 인터넷이 없는 환경에서 설치하는 방법을 고려해보아야 합니다. 또는 googleapis.com url로 proxy에서 사이트가 차단되었는지 확인하고, SSL도 해제할 경우 해결될 수도 있습니다.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/",
	"title": "HIMWM",
	"tags": [],
	"description": "",
	"content": "English How I Met Your Mother How I Met Your Mother(HIMYM)은 2005년부터 2014년까지 9시즌을 했던 시트콤입니다.\n영어로 된 스크립트도 많고 한글 자막도 있으며 최근 Netflix에 올라오기도 했습니다.\n저 또한 이 시트콤을 즐겨 보았던 시청자로, 이번 기회에 영어를 공부하는 데 이 프로그램을 사용하여 다시 한번 정주행하기로 했습니다.\nScript : https://www.springfieldspringfield.co.uk/episode_scripts.php?tv-show=how-i-met-your-mother\n"
},
{
	"uri": "http://kimmj.github.io/ibiza/2020-plan/",
	"title": "2020 Plan",
	"tags": ["blog", "hugo"],
	"description": "",
	"content": "2020 새해에는 몇가지 목표가 있다.\n 꾸준하게 이 블로그 운영하기 꾸준하게 영어공부 하기 (쉐도잉) 꾸준하게 운동하기 나만의 hugo blog 만들기 적금으로 목돈만들기 개인 공부 많이 하기 CKA 취득  적다보니 너무 많아진 감이 없지않아 있지만, 올해는 자기계발을 많이 할 수 있는 한해가 되었으면 한다.\n특히 지금은 누군가가 만든 블로그 테마를 사용하고 있지만 나중에는 내가 원하는 대로 커스터마이징이 가능하도록 나만의 블로그 테마를 만들고 싶다.\n이를 위해서는 무엇이 필요한지도, 어떤 기술 스택을 쌓아야 할지도 모르지만 일단 도전해보고자 한다.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season2/episode03/",
	"title": "Episode03",
	"tags": [],
	"description": "",
	"content": "Lily calling off the wedding and dumping me?\nMarshall and Lily had seen each other since breaking up, but to their credit, it wasn't that awkward.\nIt's kind of revealing.\nI've been doing all these toe lifts lately, and so my calves have really been cramping up.\nTo us, sure, in very small, infrequent doses.\nWay to wreck the curve, kiss ass.\nThe woman's basically a ride at a water park.\nNo, it wasn't a snap decision\nYou know, he mentioned he was divorced last night. I totally spaced on that.\nYour father's kind of a head-in-the-clouds romantic, and I'm much more down-to-earth.\n"
},
{
	"uri": "http://kimmj.github.io/ansible/ansible-for-devops/local-infrastructure-development-ansible-and-vagrant/",
	"title": "Chapter 2 - Local Infrastructure Development: Ansible and Vagrant",
	"tags": ["ansible", "ansible-for-devops"],
	"description": "",
	"content": "Prototyping and testing with local virtual machines Ansible은 remote, local 가리지 않고 연결할 수 있는 서버면 모두 잘 동작한다. 일반적으로 테스트를 할 때, Ansible Playbook 개발 속도를 빠르게 하기 위해 로컬로 테스트한다. 로컬로 하는 것이 실제 환경에서 테스트하는 것보다 훨씬 안전하다.\n최근 트렌드는 단연 TDD이다. 따라서 Infrastructure에도 테스트는 필요하다.\n소프트웨어에 대한 변경사항은 수동 또는 자동적으로 이루어진다. 이러한 것들이 Ansible과 다른 개발, configuration management 툴과 함께 구현되어 테스트를 할 수 있도록 구현되어있다. 단순하게 로컬에서 테스트를 해본다고 한들, 하지 않는 것(cowboy coding)보다 수천배 낫다.\n cowboy coding: production 환경에서 직접 작업하며, 문서화나 코드의 변경점을 감싸지 않는 방법이며, roll back에 대한 대응책이 없다.\n지난 십년간 많은 가상화 툴들이 개발되었고, 이에따라 로컬에서 infrastructure emulation을 할 수 있게 되었다. 중요한 서버에 장애를 내지 않고도 여러 테스트를 마음껏 할 수 있다. 단순히 VM을 새로 만들면 되기 때문에 실제 application의 downtime은 존재하지 않을 것이다.\nVagrant와 VirtualBox로 테스트 인프라를 구축할 수 있고 개별적인 서버 구성을 할 수 있다.\n여기에서는 Vagrant와 VirtualBox로 Ansible을 테스트 할 새로운 서버를 만들 것이다.\nYour first local server: Setting up Vagrant 첫 local virtual server를 생성하기 위해 Vagrant와 VirtualBox를 다운로드 받고 Vagrantfile을 설정하여 virtual server에 대한 설정을 할 것이다.\n Vagrant와 VirtualBox를 OS에 맞게 설치한다.  Download Vagrant Download VirtualBox   Vagrantfile과 provisioning instructions를 저장할 폴더 생성 Terminal이나 PowerShell을 열고 해당 폴더로 이동 vagrant box add geerlingguy/centos7을 이용하여 CentOS 7.x 64-bit을 추가한다. vagrant init geerlingguy/centos7으로 방금 다운로드 받은 default virtual server configuration을 생성할 수 있다. vagrant up으로 CentOS를 부팅할 수 있다.  Vagrant는 이미 만들어진 64-bit CentOS 7 가상 머신을 다운로드 한다. 또는 원할 경우 커스텀 boxes를 생성할 수 있다. 이를 통해 VirtualBox에서 사용할 configuration 파일인 Vagrantfile을 생성하여 이를 가상 머신의 부팅에 사용한다.\n이 가상 서버를 관리하는 것은 상당히 쉽다.\n vagrant halt: VM 종료 vagrant up: VM을 실행한다. vagrant destroy: VirtualBox에서 완전히 머신을 삭제한다.  이 때 vagrant up을 하게 되면 다시 base box에서 재 생성을 하게 된다.   vagrant ssh: 가상 머신으로 ssh 접속. Vagrantfile이 위치한 폴더에서 입력하면 된다. vagrant ssh-config로 수동으로 접속하거나 다른 어플리케이션에서 접속할 수 있다.  Using Ansible with Vagrant Vagrant는 preconfigured boxes를 사용하여 간편하게 하지만 VirtualBoxGUI에서도 이와 비슷하게 할 수 있다. Vagrant는 다음과 같은 특징이 있다.\n Network interface management: port를 VM에 포워드할 수 있고, public network를 공유하거나 inter-VM과 host-only 통신을 위한 private networking을 사용할 수 있다. Shared folder management: VirtualBox에서 host와 VM간에 NFS나 VirtualBox의 native folder sharing을 통해 폴더 공유를 하도록 설정한다. Multi-machine management: Vagrant는 하나의 Vagrantfile로 여러개의 VM을 관리할 수 있다. 더 중요한 점은, 문서에도 나와있듯 역사적으로 복잡한 환경을 동작시키는 것은 이를 하나의 머신에 관리하도록 만들었다. 이는 프로덕션 셋업의 부정확한 모델로 많은 차이가 있다. Provisioning: 처음 vagrant up을 실행하면 Vagrant는 Vagrantfile에서 어떤 provider를 선택했든지, 자동으로 금방 생겨난 VM을 provision할 것이다. 또한 VM이 생성되고 난 후에도 vagrant provision 명령어를 통해 명시적으로 provisioning을 할 수 있다.  마지막 특징이 가장 중요하다. Ansible 또한 Vagrant의 provisoner 중 하나이다. vagrant provision을 하면 Vagrant는 Ansible에게 VM을 정의된 Ansible Playbook을 실행하도록 한다.\nVagrantfile을 열어서 다음을 추가한다. 마지막 end 전에 추가하면 된다. (Ruby syntax를 사용한다.)\n# Provisioning configuration for Ansible config.vm.provision \u0026#34;ansible\u0026#34; do |ansible| ansible.playbook = \u0026#34;playbook.yml\u0026#34; # Run commands as root. ansible.sudo = true end 이것이 Vagrant에서 Ansible을 사용하도록 하는 가장 기본적인 설정이다. 깊게 들어가면 더 다양한 옵션들이 있다. 지금은 기본 playbook을 사용할 것이다.\nYour first Ansible Playbook 이제 palybook.yml 파일을 생성할 것이다. Vagrantfile이 있는 파일과 동일한 위치에서 다음을 입력한다.\n--- - hosts: all tasks: - name: Ensure NTP (for time synchronization) is installed. yum: name=ntp state=installed - name: Ensure NTP is running. service: name=ntpd state=started enabled=yes playbook에 대해 간단히 알아보고 넘어가겠다. 이제 playbook을 VM에서 실행시켜본다. Vagrantfile과 playbook.yml은 동일한 위치에 있어야 한다. 그 다음 vagrant provision을 입력한다. 그러면 tasks에서 지정한 동작을 하고, 이에대한 status를 확인할 수 있다. 그 후 VM에서 동작한 것들에 대한 요약을 보여준다.\nAnsible은 방근 정의한 간단한 playbook을 파싱하고, 여러 명령어들을 ssh를 통해 실행하여 우리가 정의한 대로 서버를 설정한다. 한 줄씩 playbook을 확인해보자.\n--- 첫 줄은 뒤의 문서가 YAML 형식으로 작성되었음을 알려준다.\n- hosts: all Ansible이 playbook을 어느 host에 적용할지 알려준다. all을 사용한 이유는 Vagrant가 자체의 개별적인 Ansible inventory file(이전에 생성한 /etc/ansible/hosts와는 다른)을 사용하여 방금 정의한 Vagrant VM을 관리하기 때문이다.\ntasks: 뒤에 나오게 될 task들은 모든 host에서 실행될 것이다. (이 경우 우리의 VM)\n- name: Ensure NTP daemon (for time synchronization) is installed. yum: name=ntp state=installed 이 명령어는 yum install ntp와 동일하지만 좀 더 똑똑하다. ntp가 설치되어있는지 확인하고 안되어있으면 설치한다. 다음의 shell script와 동일하다.\nif ! rpm -qa | grep -qw ntp; then yum install ntp fi 그러나 위의 스크립트는 Ansible의 yum command만틈 robust하지는 않다. ntp가 아닌 ntpdate가 설치되어 있을 경우엔 어떻게 해야하나? 이 스크립트는 Ansible의 yum command와 단순 비교하기에는 무리가 있다.\n- name: Ensure NTP is running. service: name=ntpd state=started enabled=yes 마지막 단계는 ntpd service가 시작되었고 동작하는지 확인한다. 그리고 system boot 시 시작되도록 설정한다. 동일한 결과를 내는 shell script는 다음과 같다.\n# Start ntpd if it\u0026#39;s not already running. if ps aux | grep -v grep | grep \u0026#34;[n]tpd\u0026#34; \u0026gt; /dev/null then echo \u0026#34;ntpd is running.\u0026#34; \u0026gt; /dev/null else /sbin/service ntpd restart \u0026gt; /dev/null echo \u0026#34;Started ntpd.\u0026#34; fi # Make sure ntpd is enabled on system startup chkconfig ntpd on shell script가 얼마나 복잡한 지 확인할 수 있다. 그리고 여전히 Ansible만큼 robust하지는 않다. idempotency를 보장하려면 shell script에 많은 작업이 필요하다.\n더 간결하게 하여 Ansible의 name module을 사람이 읽을 수 있는 이름으로 각 command에 부여하면 결과적으로 다음과 같은 playbook이 완성된다.\n--- - hosts: all tasks: - yum: name=ntp state=installed - service: name=ntpd state=started enabled=yes  code와 configuration file처럼 Ansible에서의 documentation(function에 name을 부여하는 것, 복잡한 tasks에 대해 comments를 다는 것)은 절대적으로 필요한 것은 아니다. 이렇게 하면 사람이 읽을 수 있는 정보를 가지고 어떻게 playbook이 실행되는지 확인하기 쉽다.\n Summary 이제 workstatin이 infrasturcture-in-a-box가 되었다. 그리고 그 infrastructure가 코드로 잘 테스트되었음을 보장할 수 있다. 이 작은 예시에서 간단하면서도 강력한 Ansible playbook을 경험할 수 있었다. 나중에 Ansible playbook에 대해서 더 깊게 알아볼 것이다. 또한 Vagrant에 대해서도 다루어 볼 것이다.\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/choose-cloud-providers/",
	"title": "Choose Cloud Providers",
	"tags": ["install", "spinnaker"],
	"description": "",
	"content": "Spinnaker를 배포할 환경을 설정해 주어야 합니다. 여기에서는 제가 구축한 local kubernetes cluster를 사용할 것입니다.\n먼저 2가지가 필요합니다.\n kubeconfig 파일 kubeconfig 파일은 일반적으로 ~$HOME/.kube/config 파일을 의미합니다. 저는 local kubernetes cluster로 이동하여 해당 파일을 halyard를 위한 vm으로 복사하였습니다. kubectl CLI 툴  이제 hal config 명령어를 통해 kubernetes cluster를 추가합니다.\nhal config provider kubernetes enable CONTEXT=$(kubectl config current-context) hal config provider kubernetes account add wonderland \\  --provider-version v2 \\  --context $CONTEXT hal config features edit --artifacts true "
},
{
	"uri": "http://kimmj.github.io/kubernetes/installation/create-a-single-control-plane-cluster-with-kubeadm/",
	"title": "Create a Single Control Plane Cluster With Kubeadm",
	"tags": ["kubeadm", "instll"],
	"description": "",
	"content": "이 문서에서는 Master 노드 한대로 클러스터를 구성하는 방법에 대해 알아보도록 하겠습니다.\n먼저, 파드 네트워크에 사용할 add-on을 선정합니다. 그런뒤 kubeadm init을 할 때 필요로 하는 사항이 있는지 확인해야 합니다.\n저는 Calico를 사용할 것입니다. Calico는 kubeadm init에서 --pod-network-cidr=192.168.0.0/16을 해주거나, 나중에 calico.yml 파일에서 적절하게 수정해주어야 한다고 합니다. 저는 Pod Network에 사용될 IP 대역을 10.1.0.0/16 대역을 사용하고자 합니다. 그러기 위해 kubeadm init을 --pod-network-cidr=10.1.0.0/16 옵션을 통해 실행할 것입니다.\nkubeadm init --pod-network-cidr=10.1.0.0/16 몇분 후 설치가 완료될 것입니다. 그러면 아래에 kubeadm join 이라면서 어떻게 다른 node들을 join 시키는지 설명이 되어 있습니다.\n클러스터를 사용하려면 다음과 같은 명령어를 통해서 kubectl에서 접근이 가능하도록 해야합니다.\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 그 다음엔 각 worker node로 접속하여 설치시 나왔던 kubeadm join 명령어를 복사하여 입력합니다. 그런 뒤 master node로 접속하여 kubectl get nodes를 입력하고 결과를 확인합니다. 성공했을 경우 node들이 보일 것입니다.\n이제 calico를 설치하도록 합니다.\ncurl -o calico.yaml https://docs.projectcalico.org/v3.8/manifests/calico.yaml 이후 calico.yaml에서 CALICO_IPV4POOL_CIDR 부분을 수정해줍니다.\n- name: CALICO_IPV4POOL_CIDR value: \u0026#34;10.1.0.0/16\u0026#34; Reference https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\n"
},
{
	"uri": "http://kimmj.github.io/ibiza/ibiza-project/",
	"title": "Ibiza Project",
	"tags": ["blog", "hugo"],
	"description": "",
	"content": "Ibiza Project는 나만의 블로그을 만들기 위한 프로젝트이다.\n기본적으로 hugo-theme-learn에서 시작하여, 나의 커스텀 파일들을 추가하여 내가 원하는 사이트를 만들 것이다.\n기간 : 2020.4.15 (작성일 기준 + 100일)\n"
},
{
	"uri": "http://kimmj.github.io/ansible/ansible-for-devops/ad-hoc-commands/",
	"title": "Ad Hoc Commands",
	"tags": ["ansible", "ansible-for-devops"],
	"description": "",
	"content": "지난 챕터에서는 Vagrant와 간단한 Ansible playbook으로 local infrastructure를 테스트해보았다. 이번에는 간단한 Ansible ad-hoc command를 사용하여 하나의 명령어로 다수의 remote server에 명령을 보낼 것이다.\n나중 챕터에서는 playbook에 대해 자세히 알아볼 것이지만, 지금은 어떻게 Ansible이 하나 이상의 서버에 대해 ad-hoc command로 빠르게 공통적인 일을 수행하는지, 데이터를 가져오는지에 대해 알아볼 것이다.\nConducting an orchestra 각 개인 administrator가 관리하는 서버의 수는 수년간 급격하게 증가했다. 특히 virtualization과 cloud application의 발전은 표준처럼 되었다.\n어느 때든 system administrator는 여러가지 업무가 있다.\n patch 적용과 yum, apt, 다른 package manager를 통한 update resource usage 확인 (disk space, memory, CPU, swap space, network) log file 확인 system user와 group 관리 DNS 설정, hosts 파일 관리 등 서버에 파일 업로드/다운로드 application 배포하기 또는 application 유지 server 재부팅 cron jobs 관리  최근에는 이런 작업들이 조금이나마 자동화 되어있다. 하지만 실시간 진단같은 문제에는 사람의 손길이 필요하긴 하다. 또한 multi-server 환경은 복잡하여 각 server에 접속하는 것은 좋은 솔루션이 아니다.\nAnsible은 admin이 ad-hoc command로 ansible 명령어를 사용하여 수백개의 서버에 동시에 명령을 전달할 수 있다. 챕터 1에서는 Ansible inventory file에 기록된 서버에 두개의 command를 실행했다. 이 챕터에서는 ad-hoc command와 multi-server 환경을 자세히 볼 것이다. 다른 Ansible의 강력한 기능들은 제쳐두고라도 이 챕터를 읽으면 더 효과적으로 server들을 관리할 수 있다.\nBuild infrastructure with Vagrant for testing 우리의 production server에 영향을 주지 않고 설명을 하기 위해 이 챕터의 나머지 부분에서는 Vagrant의 multi-machine capabilites를 사용하여 몇개의 server들을 설정해볼 것이다. 이것들은 Ansible을 통해 관리될 것이다.\n먼저 Vagrant에서 CentOS 7을 실행시키는 하나의 virtual machine을 사용할 것이다. 이 예시에서 우리는 Vagrantfile에 정의된 Vagrant의 기본 설정들을 사용할 것이다. 이 예시에서 우리는 Vagratn의 강력한 multi-machine management feature를 사용할 것이다.\n우린 3개의 VM을 생성할 것이다. (두개의 app server, 하나의 database server) 이정도면 Ansible의 server management 능력을 확인해볼 수 있을 것이다.\nlocal drive에 새로운 폴더를 생성하고 Vagrantfile을 생성한다. 이를 editor로 연 뒤 다음과 같이 입력한다.\n# -*- mode: ruby -*- # vi: set ft=ruby : VAGRANTFILE_API_VERSION = \u0026quot;2\u0026quot; Vagrant.configure(VAGRANTFILE_API_VERSION) do |config| config.ssh.insert_key = false config.vm.provider :virtualbox do |vb| vb.customize [\u0026quot;modifyvm\u0026quot;, :id, \u0026quot;--memory\u0026quot;, \u0026quot;256\u0026quot;] end # Application server 1. config.vm.define \u0026quot;app1\u0026quot; do |app| app.vm.hostname = \u0026quot;orc-app1.dev\u0026quot; app.vm.box = \u0026quot;geerlingguy/centos7\u0026quot; app.vm.network :private_network, ip: \u0026quot;192.168.60.4\u0026quot; end # Application server 2. config.vm.define \u0026quot;app2\u0026quot; do |app| app.vm.hostname = \u0026quot;orc-app2.dev\u0026quot; app.vm.box = \u0026quot;geerlingguy/centos7\u0026quot; app.vm.network :private_network, ip: \u0026quot;192.168.60.5\u0026quot; end # Database server. config.vm.define \u0026quot;db\u0026quot; do |db| db.vm.hostname = \u0026quot;orc-db.dev\u0026quot; db.vm.box = \u0026quot;geerlingguy/centos7\u0026quot; db.vm.network :private_network, ip: \u0026quot;192.168.60.6\u0026quot; end end 이 Vagrantfile은 세 server를 정의하고 각각 고유한 hostname, machine name, IP 주소를 부여한 것이다. 간단하게 하기 위해 셋 모두 CentOS 7을 사용한다.\n터미널을 열고 Vagrantfile이 있는 폴더로 이동한다. 그 다음 vagrant up을 이용하여 세개의 VM을 생성한다. 이미 챕터 2에서 box를 다운로드 받았다면 5~10 내로 생성될 것이다.\n진행되는 동안 서버에 대한 Ansible을 설명하도록 하겠다.\nInventory file for multiple servers 관리하는 서버를 다루는 Ansible에 대해 이야기 할 것들이 많다. 하지만 대부분의 경우 서버를 시스템의 main Ansible inventory file(보통 /etc/ansible/hosts)에 추가하면 된다. 지난 챕터에서 파일을 생성하지 않았다면 돌아가서 파일을 생성해야한다. 또한 user가 해당 파일에 대해 read 권한이 있어야 한다.\n다음을 파일에 추가한다.\n# Lines beginning with a # are comments, and are only included for # illustration. These comments are overkill for most inventory files. # Application servers [app] 192.168.60.4 192.168.60.5 # Database server [db] 192.168.60.6 # Group 'multi' with all servers [multi:children] app db # Variables that will be applied to all servers [multi:vars] ansible_ssh_user=vagrant ansible_ssh_private_key_file=~/.vagrant.d/insecure_private_key  첫 번째 block은 우리의 application server들을 app group에 추가한다. 두 번째 block은 database server를 db group에 추가한다. 세 번째 block은 Ansible이 새 그룹 multi를 생성하고, child group으로 app과 db를 추가한 것이다. 네 번째 block은 multi group에 variables를 추가한 것이다. 이는 multi group과 그 내부의 모든 children 서버에 적용된다.  나중 챕터에서 variables, group definition, group hiearchy, Inventory file topics에 대해 알아볼 것이다. 여기서는 어떻게 Ansible이 간단히 서버 정보를 다루는지 확인하고 빠르게 이를 이용할 것이다.\n inventory file을 저장하고 Vagrant가 세개의 VM들을 성공적으로 build 하였는지 확인한다. Vagrant가 성공하고 나면 이들을 Ansible에서 관리할 것이다.\nYour first ad-hoc commands 가장 먼저 해야할 것은 서버 안에서 체크할 것이다. 제대로 설정이 되었는지 확인하고, 올바른 날짜 및 시간이 설정 되었는지(우린 time synchronization과 관련된 에러를 경험하고 싶지 않다!), 어플리케이션을 실행하기에 충분한 리소스가 있는지 확인해 보자.\n여기서 확인하는 것들은 production server에서 자동화 시스템으로 모니터링되어야 하는 것들이다. 재앙을 막는 가장 좋은 방법은 언제 올지 알고, 발생하기 전에 어떻게 문제점을 해결하는 것을 아는 것이다. Munin, Nagios, Cacti, Hyperic과 같은 툴을 사용하여 서버에서의 과거와 현재의 리소스 사용량을 확인할 수 있다. 인터넷에서 웹사이트나 웹 어플리케이션을 돌리고 있다면 Pingdom이나 Server Check in 같은 외부 모니터링 솔루션이 필요하다.\n Discover Ansible's parallel nature 먼저, Vagrant가 설정한 VM들이 올바른 hostname을 가지고 있는지 확인할 것이다. Ansible에서 -a argument를 \u0026ldquo;hostname\u0026quot;으로 줘서 모든 서버에 대해 hostname을 실행한다.\n$ ansible multi -a \u0026#34;hostname\u0026#34; Ansible은 이 명령어를 세 서버 모두에 대해 실행하고, 결과를 리턴받는다. (만일 Ansible이 하나의 서버에 도달하지 못할 경우 이는 해당 서버에 대해 error를 출력하지만 나머지 서버에 대해서는 계속해서 명령어를 수행한다.)\nAnsible이 No hosts matched나 다른 inventory 관련 에러를 리턴하면 ANSIBLE_HOSTS 환경 변수를 설정해보아라. export ANSIBLE_HOSTS=/etc/ansible/hosts를 하면 된다. 일반적으로 Ansible은 /etc/ansible/hosts 파일을 자동으로 읽지만 어떻게 Ansible을 설치했는지에 따라 명시적으로 ANSIBLE_HOSTS을 설정해야 할수도 있다.\n 명령어들이 각 서버에 대해서 예상했던 순서대로 실행되는 것은 아님을 확인할 수 있다. 명령어를 몇번 더 입력하여 순서를 확인해보자.\n기본적으로 Ansible은 명령어를 process fork를 이용해서 병렬적으로 실행한다. 따라서 명령어는 좀 더 빨리 완료될 수 있다. 몇개의 서버만 관리한다면 하나씩 실행하는 것에 비해 속도 체감이 별로 안들지만 5-10개의 서버만 관리한다고 하더라도 Ansible의 parallelism(기본적으로 활성화되어있다)을 이용하면 엄청난 속도 절감 효과가 있을 것이다.\nfork를 하나만 한다는 것을 의미하는 -f 1 argument를 이용해서 동일한 명령어를 다시 입력해보자. (일반적으로 각 서버에 대해 순서대로 실행할 때 쓴다)\n동일한 명령어를 계속 반복해도 항상 같은 순서대로 결과가 나올 것이다. 이걸 사용할 일은 거의 없겠지만 값을 늘리는 일은 그래도 더 많을 것이다. (-f 10이나 -f 25처럼 시스템과 네트워크 연결이 얼마나 감당 가능한지에 따라 수정할 수 있다) 이를 통해 수십 수백개의 서버에 대한 명령어 실행을 빠르게 할 수 있다.\n대부분의 사람들은 action의 target을 command/action 자체보다 더 앞에 배치한다. (\u0026ldquo;X 서버에서, Y 명령어를 실행해라\u0026rdquo;) 하지만 머랫속에서 반대로 작동한다면 (\u0026ldquo;Y 명령러를 실행해라. X 서버에서.\u0026quot;) target을 arguments 다음에 배치할 수도 있다. (ansible -a \u0026quot;hostname\u0026quot; multi) 이 둘은 완전히 일치하는 것이다.\n Learning about your environment 이제 우리는 Vagrant가 정상적으로 hostname을 설정한 것을 확인했다. 이제 다른것들을 확인해 보도록 하자.\n먼저, application을 위한 hard disk space가 충분한지 확인해보자.\n$ ansible multi -a \u0026#34;df -h\u0026#34; 192.168.60.6 | success | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 19G 1014M 18G 6% / devtmpfs 111M 0 111M 0% /dev tmpfs 120M 0 120M 0% /dev/shm tmpfs 120M 4.3M 115M 4% /run tmpfs 120M 0 120M 0% /sys/fs/cgroup /dev/sda1 497M 124M 374M 25% /boot none 233G 217G 17G 94% /vagrant 192.168.60.5 | success | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 19G 1014M 18G 6% / devtmpfs 111M 0 111M 0% /dev tmpfs 120M 0 120M 0% /dev/shm tmpfs 120M 4.3M 115M 4% /run tmpfs 120M 0 120M 0% /sys/fs/cgroup /dev/sda1 497M 124M 374M 25% /boot none 233G 217G 17G 94% /vagrant 192.168.60.4 | success | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 19G 1014M 18G 6% / devtmpfs 111M 0 111M 0% /dev tmpfs 120M 0 120M 0% /dev/shm tmpfs 120M 4.3M 115M 4% /run tmpfs 120M 0 120M 0% /sys/fs/cgroup /dev/sda1 497M 124M 374M 25% /boot none 233G 217G 17G 94% /vagrant 현재 충분한 만큼의 공간이 있는 것처럼 보인다. 우리의 application은 가벼운 편이다.\n두번째로 서버에 메모리가 충분한지 확인한다.\n$ ansible multi -a \u0026#34;free -m\u0026#34; 192.168.60.4 | success | rc=0 \u0026gt;\u0026gt; total used free shared buffers cached Mem: 238 187 50 4 1 69 -/+ buffers/cache: 116 121 Swap: 1055 0 1055 192.168.60.6 | success | rc=0 \u0026gt;\u0026gt; total used free shared buffers cached Mem: 238 190 47 4 1 72 -/+ buffers/cache: 116 121 Swap: 1055 0 1055 192.168.60.5 | success | rc=0 \u0026gt;\u0026gt; total used free shared buffers cached Mem: 238 186 52 4 1 67 -/+ buffers/cache: 116 121 Swap: 1055 0 1055 메모리는 약간 타이트하다. 하지만 우리는 localhost에 3개의 VM을 돌리고 있음을 감안해야한다.\n세 번째로 날짜 및 시간이 잘 맞춰졌는지 확인한다.\n$ ansible multi -a \u0026#34;date\u0026#34; 192.168.60.5 | success | rc=0 \u0026gt;\u0026gt; Sat Feb 1 20:23:08 UTC 2021 192.168.60.4 | success | rc=0 \u0026gt;\u0026gt; Sat Feb 1 20:23:08 UTC 2021 192.168.60.6 | success | rc=0 \u0026gt;\u0026gt; Sat Feb 1 20:23:08 UTC 2021 대부분의 어플리케이션은 각 서버의 시간 jitter에 약간은 견딜 수 있게 설계되어있지만 다른 서버들의 시간들을 가능한 가깝게 하는 것은 좋은 방법이고 이를 간단하게 할 수 있는것은 설정하는 것이 쉬운 Network Time Protocol을 사용하는 것이다. 나중에 이를 Ansible의 modules를 이용하여 힘쓰지 않고 프로세스를 진행해 볼 것이다.\n특정 서버에 대해서 모든 환경적인 자세한 부분(Ansible의 lingo에서는 facts라고 한다)을 확인하고 싶으면 ansible [host-or-group] -m setup을 입력하면 된다. 이는 매 분마다 서버에 대한 자세한 사항들을 보여준다. (file system, memory, OS, network interface 등이 포함된다)\n Make changes using Ansible modules 우리는 NTP daemon을 서버에 설치하여 시간을 동기화할 것이다. yum install -y ntp 명령어를 각 서버에서 실행하는 대신 ansible의 yum module을 이용해서 같은것을 해볼 것이다. (우리가 앞선 playbook 예제에서 했던 것과 같지만 이번에는 ad-hoc command를 사용할 것이다.)\n$ ansible multi -b -m yum -a \u0026#34;name=ntp state=installed\u0026#34; NTP가 이미 설치되어있기 때문에 세개의 \u0026ldquo;success\u0026rdquo; 메시지를 볼 수 있을 것이다. 이는 모든 작업이 순서대로 잘 되었음을 의미한다.\n-b 옵션은 Ansible이 sudo 권한으로 명령어를 실행할 수 있게 한다. 이는 우리의 Vagrant VM에서는 잘 작동하지만 sudo password를 요구로 하는 서버에 대해서는 -k 옵션도 지정하여 Ansible이 필요로 하는 sudo password를 입력해야한다.\n 이제 NTP daemon이 시작되었는지 확인하고 부팅 시 시작되도록 할 것이다. 우리는 service ntpd start 와 chkconfig ntpd on 두 명령어를 사용하기 보단 Ansible의 service module을 사용할 것이다.\n$ ansible multi -b -m service -a \u0026#34;name=ntpd state=started enabled=yes\u0026#34; 모든 서버에서 다음과 같은 메시지를 출력할 것이다.\n\u0026quot;changed\u0026quot;: true, \u0026quot;enabled\u0026quot;: true, \u0026quot;name\u0026quot;: \u0026quot;ntpd\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;started\u0026quot; 동일한 명령어를 다시 쳐도 Ansible이 nothing has changed라고 리포트하는 것 빼곤 모든 결과는 같을 것이고 이 경우 changed 값은 false가 될 것 이다.\nAnsible의 module을 일반 shell command 대신 사용할 경우 Ansible이 제공하는 상화와 idempotency를 이용할 수 있다. shell command를 실행시키더라도 이를 Ansible의 shell이나 command module로 감싸줘야 하지만(ansible -m shell -a \u0026quot;date\u0026quot; multi처럼), ad-hoc으로 실행하는 것들은 Ansible module을 사용할 필요는 없다.\n마지막으로 체크해야하는 사항은 NTP server의 official time과 거의 일치하는지 확인하는 것이다.\n$ ansible multi -b -a \u0026#34;service ntpd stop\u0026#34; $ ansible multi -b -a \u0026#34;ntpdate -q 0.rhel.pool.ntp.org\u0026#34; $ ansible multi -b -a \u0026#34;service ntpd start\u0026#34; ntpdate 명령어를 실행하려면 ntpd service가 중지되어야 하기 때문에 service를 중지했고 명령어를 실행한 뒤 다시 서비스를 시작했다.\n나의 테스트에서 모든 세 서버에서 3/100초 내에 차이를 보여줬다. 내 목적에는 충분한 것이었다.\nConfigure groups of servers, or individual servers 우리의 가상 웹 어플리케이션은 Django를 사용할 것이며 따라서 우리는 Django와 그 dependency들을 설치해야한다. Django는 official CentOS yum repository에 없지만 우리는 Python의 easy_install을 통해서 설치할 것이다. (편리한 Ansible module이 있다.)\n$ ansible app -b -m yum -a \u0026#34;name=MySQL-python state=present\u0026#34; $ ansible app -b -m yum -a \u0026#34;name=python3-setuptools state=present\u0026#34; $ ansible app -m pip -a \u0026#34;name=django executable=pip3\u0026#34; 우리는 easy_install을 통해 설치한 django를 pip를 통해서도 설치할 수 있다. (Ansible의 easy_install module은 pip처럼 uninstall을 지원하 지않기 때문에 사용한다) 하지만 간단하게 하기 위해 easy_install을 사용하였다.\nDjango가 설치 되었고 제대로 동작하는지 확인해보자.\n$ ansible app -a \u0026#34;python3 -c \u0026#39;import django; print (django.get_version())\u0026#39;\u0026#34; 192.168.60.5 | CHANGED | rc=0 \u0026gt;\u0026gt; 3.0.3 192.168.60.4 | CHANGED | rc=0 \u0026gt;\u0026gt; 3.0.3 우리의 앱 서버가 정상적으로 동작하는 것처럼 보인다. 이제 우리는 database server에 대해 해볼 것이다.\n이 챕터에서 한 대부분의 설정은 Ansible playbook으로 하는 것이 더 좋다. (이 책의 뒷부분에서 더 자세히 다뤄볼 것이다.) 이 챕터는 Ansible을 통해 얼마나 쉽게 여러 서버를 관리할 수 있는지에 대해서 좀 더 집중할 것이다. 서버를 shell command를 통해 설정했다고 하더라도 Ansible은 굉장히 많은 시간을 줄여줄 수 있고 더 안전하고 효과적인 방법으로 모든 것들을 처리해줄 수 있다.\n Configure the Database servers 우리는 어플리케이션 서버를 Ansible의 main inventory에서 app group으로 정의하여 사용하였고 database server를 이와 비슷하게 db group으로 정의하여 설정할 것이다.\nMariaDB를 설치하고 이를 실행시키고 서버의 방화벽에서 MariaDB의 deafult port인 3306을 허용시키자.\n$ ansible db -b -m yum -a \u0026#34;name=mariadb-server state=present\u0026#34; $ ansible db -b -m service -a \u0026#34;name=mariadb state=started enabled=yes\u0026#34; $ ansible db -b -a \u0026#34;iptables -F\u0026#34; $ ansible db -b -a \u0026#34;iptables -A INPUT -s 192.168.60.0/24 -p tcp -m tcp --dport 3306 -j ACCEPT\u0026#34; 여기서 app server에서 database를 연결하려고 시도할 경우 연결이 불가능하지만, 연결할 필요가 없다. 왜냐면 MariaDB를 계속해서 셋업해야하기 때문이다. 전형적으로 이를 서버에 접속하여 mysql_secure_installation을 통해 한다. 그러나 운좋게도 Ansible은 MariaDB server를 mysql_* module로 제어할 수 있다. 이제 app server에서 MySQL로 접속할 수 있게 허용할 것이다. MySQL module은 MySQL-python module이 managed server에 설치되어있어야 한다.\n왜 MySQL이 아닌 MariaDB인가? RHEL 7과 CentOS 7는 MariaDB를 default supported MySQL-compatible database server로 지원한다. MariaDB와 관련된 몇몇 툴들은 MySQL* 네이밍 규칙을 가진 예전 것들을 사용하며 MySQL로 하더라도 MariaDB를 하는것과 비슷할 것이다.\n $ ansible db -b -m yum -a \u0026#34;name=MySQL-python state=present\u0026#34; $ ansible db -b -m mysql_user -a \u0026#34;name=django host=% password=12345 priv=*.*:ALL state=present\u0026#34; 여기서 Django application을 app server에 생성하거나 배포할 수 있어야 한다. 그 뒤 database server에 username=django, password=12345로 접속할 수 있을 것이다.\n여기서 사용한 MySQL configuration은 예시/개발 목적으로만 사용해야 한다. MySQL의 안전하게 하려면 test database의 삭제와 root user account에 password를 추가하고, 3306 port로 접근하는 IP address들을 제한하는 등 몇가지 더 할 일들이 있다. 이 중 몇몇은 이 책의 뒷부분에서 다루도록 하겠지만, 당신의 서버를 보호하는 것은 당신의 책임이다. 제대로 보호했는지 확실히 하라.\n Make changes to just one server 축하한다! 이제 Django와 MySQL을 실행시킬 작은 웹 어플리케이션 환경을 가지게 되었다. 앱 서버 앞단에 요청을 분배시켜줄 로드밸런서도 없어 충분하지는 않다. 하지만 서버에 접속하지 않고도 빠르게 이것들을 설정할 것이다. 더 인상깊은 점은 어느 ansible command도 다시 실행할 수 있고, 이것이 어떤 차이점도 만들지 않는다는 것이다. 이런 것들은 \u0026quot;changed\u0026quot;: false를 리턴할 것이고 기존의 설정이 변경되지 않았음을 알려준다.\n이제 local infrastructure가 동작하는 동안 로그를 보다보면 두 앱 서버중 하나의 시간이 NTP daemon이 충돌나거나 어떤 이유로 멈췄을 경우 다른 서버와 일치하지 않을 수 있다. 빠르게 다음의 명령어를 통해 ntpd의 상태를 체크해보자.\n$ ansible app -b -a \u0026#34;service ntpd status\u0026#34; 그리고 app server의 서비스들을 재시작한다.\n$ ansible app -b -a \u0026#34;service ntpd restart\u0026#34; --limit \u0026#34;192.168.60.4\u0026#34; 이 명령어에서 --limit argument는 명령어를 지정된 그룹 내에서 특정한 호스트에서만 실행하도록 제한하는 것이다. --limit은 정확한 string 또는 regular expression을 쓸 수 있다. (~를 prefix로 쓰면 된다) 위의 명령어는 .4 서버에서만 실행하고 싶다면 더 간단히 할 수 있다. (.4로 끝나는 IP 주소가 하나만 있다고 확신해야 한다) 다음의 명령어는 정확히 같은 동작을 한다.\n# Limit hosts with a simple pattern (asterisk is a wildcard). $ ansible app -b -a \u0026#34;service ntpd restart\u0026#34; --limit \u0026#34;*.4\u0026#34; # Limit hosts with a regular expression (prefix with a tilde). $ ansible app -b -a \u0026#34;service ntpd restart\u0026#34; --limit ~\u0026#34;.*\\.4\u0026#34; 이 예시에서 우리는 IP 주소를 hostname 대신에 사용하였다. 하지만 많은 실제 시나리오에서는 nyc-dev-1.example.com처럼 hostname을 많이 사용하게 된다. 따라서 정규식을 활용하는 것이 더 유용할 것이다.\n하나의 서버에 대해 명령어를 실행할때만 --limit 옵션을 주어라. 동일한 세트의 서버에 --limit 명령어를 자주 사용하게 된다면 이들을 inventory file에서 group으로 묶는 것을 고려해 보아라. 그 방법이 ansible [my-new-group-name] [command]를 사용할 수 있는 방법이고 타이핑을 줄일 수 있다.\n Manage users and groups 내가 Ansible의 ad-hoc command를 사용하는 일반적인 사용법은 user와 group 관리이다. 내가 user를 생성하며 home folder를 생성할지 말지와, 특정 유저를 특정 group에 추가하는 방법을 얼마나 많이 구글링했는지 모른다.\nAnsible의 user와 group module은 이런 것들을 어느 Linux 에서나 꽤 간단하고 표준적인 방법으로 할 수 있게 해준다.\n먼저, 간단히 server administrator를 위한 admin group을 app server에 추가하자.\n$ ansible app -b -m group -a \u0026#34;name=admin state=present\u0026#34; group module은 매우 간단하다. group을 state=absent로 하면 삭제가 되고 group id는 gid=[gid]로 설정할 수 있으며 group이 system group인지 나타내려면 system=yes를 설정하면 된다.\n이제 johndoe라는 user를 app server에 추가하고 생성한 group에 넣을 것이며 /home/johndoe에 home directory를 추가할 것이다. (Linux 배포판에서 default location이다)\n$ ansible app -b -m user -a \u0026#34;name=johndoe group=admin createhome=yes\u0026#34; 새로운 유저에 대해 자동으로 SSH key를 생성하고 싶다면 (존재하지 않는 경우) 같은 명령어를 generate_ssh_key=yes를 넣어 실행하면 된다. 또한 user의 UID를 uid=[uid]를 통해 설정할 수 있고, user의 shell을 shell=[shell]로 설정할 수 있으며 password를 password=[encrypted-password]로 설정할 수 있다.\naccount를 삭제하려면 어떻게 해야 할까?\n$ ansible app -b -m user -a \u0026#34;name=johndoe state=absent remove=yes\u0026#34; Ansible의 user module을 통해 useradd, userdel, usermod의 모든 것을 사용할 수 있으며 심지어 더 쉽다. 공식 User module 가이드에 더 자세한 설명이 있다.\nManage files and directories 또 다른 ad-hoc command의 일반적인 사용법은 remote file management이다. Ansible은 host에서 remote server로 파일을 복사하는 것, 디렉토리를 생성하는 것, 파일과 디렉토리의 권한과 소유권을 관리하는 것, 파일과 디렉토리를 삭제하는 것이 매우 쉽다.\nGet information about a file 파일의 권한, MD5, 소유자를 확인하려면 Ansible의 stat module을 사용하면 된다.\n$ ansible multi -m stat -a \u0026#34;path=/etc/environment\u0026#34; 이는 stat 명령어를 실행했을 때와 같은 정보를 보여주지만 JSON 형태로 출력해주어 좀 더 쉽게 parsing할 수 있게 된다. (또는 나중에 playbook에서 조건을 걸어 어떤일을 할지 말지 결정할 수 있게 한다)\nCopy a file to the servers 아마도 scp나 rsync를 통해 파일과 디렉토리를 remote server로 복사해왔을 것이다. Ansible은 rsync module을 가지고 있으며 대부분의 파일 복사관련 명령은 copy module로도 할 수 있다.\n$ ansible multi -m copy -a \u0026#34;src=/etc/hosts dest=/tmp/hosts\u0026#34; src는 파일이나 디렉토리가 될 수 있다. 마지막에 슬래쉬로 끝나게 되면 디렉토리의 내용들만 dest로 복사가 된다. 슬래쉬를 생략하면 내용과 디렉토리 그 자체가 dest로 복사된다.\ncopy module은 단일 파일 복사에 완벽하며 작은 디렉토리에서도 잘 작동한다. 수백개의 파일을 복사하려는 경우, 특히 서브 디렉토리가 많은 경우에는 Ansible의 unarchive module이나 synchronize module을 이용해서 복사하는 것을 고려해보면 좋을 것이다.\nRetrieve a file from the servers fetch module은 copy module과 거의 비슷하게 동작하지만 반대인 것이 다르다. 가장 주요한 차이점은 파일이 local dest의 디렉토리로 일치하는 host의 파일을 가져온다. 예를 들어 다음의 명령어는 hosts file을 서버에서 가져오는 것이다.\n$ ansible multi -b -m fetch -a \u0026#34;src=/etc/hosts dest=/tmp\u0026#34; Fetch는 default로 각 서버의 /etc/hosts 파일을 destination folder 안에 host의 이름을 추가하여 저장할 것이다. (우리의 경우 세 IP 주소이다) 따라서 db server의 hosts file은 /tmp/192.168.60.6/etc/hosts로 저장될 것이다.\nflat=yes라는 파라미터를 추가하고 dest를 dest=/tmp/로 설정하여(슬래쉬로 끝내기) Ansible이 file을 직접 /tmp 디렉토리로 fetch할 수 있다. 하지만 filename은 반드시 유일해야 이것이 동작하고 따라서 여러 호스트에서 파일을 가져올 때는 적합하지 않다. flat=yes는 하나의 호스트에서 파일을 가져올 때만 써야한다.\nCreate directories and files file module을 사용하여 파일과 디렉토리를 생성(touch 처럼)할 수 있고, 권한 관리와 파일과 디렉토리의 소유권을 관리, SELinux 속성 수정, symlink 생성을 할 수 있다.\n디렉토리를 생성하는 방법이다.\n$ ansible multi -m file -a \u0026#34;dest=/tmp/test mode=644 state=directory\u0026#34; symlink를 생성하는 방법이다.\n$ ansible multi -m file -a \u0026#34;src=/src/symlink dest=/dest/symlink owner=root group=root state=link\u0026#34; Delete directories and files state를 absent로 설정하여 파일이나 디렉토리를 삭제할 수 있다.\n$ ansible multi -m file -a \u0026#34;dest=/tmp/test state=absent\u0026#34; Ansible을 통해 원격 파일을 관리하는 방법은 매우 많다. 우리는 짧게 copy와 file module을 살펴보았지만, 다른 lineinfile, ini_file, unarchive같은 file-management module의 문서도 읽어보도록 해라. 이 책에서는 이런 module에 대해 나중 챕터에서 다루도록 하겠다. (playbooks와 함께.)\nRun operatioins in the background 몇몇 operation은 약간 시간이 걸린다(수 분에서 몇 시간까지 걸리기도 한다). 예를 들어, yum date나 apt-get update \u0026amp;\u0026amp; apt-get dist-upgrade를 할 경우, 서버에서 모든 패키지가 업데이트 되기까지 수 분이 걸릴 수 있다.\n이러한 상황에서 Ansible이 명령어를 asynchronous하게 실행하고 명령어가 끝났을 때 서버에서 결과를 가져오게 할 수 있다. 하나의 서버만 관리한다면 이는 그렇게 효과적이지는 않겠지만 많은 서버를 관리한다면 모든 서버에서 명령을 굉장히 빠르게 시작하고(특히 --forks 값을 늘리면 더욱 더 빨라진다) 이후에 서버에서 최신 상태를 polling할 수 있다.\n명령어를 background에서 실행하려면 다음의 옵션을 설정한다.\n -B \u0026lt;seconds\u0026gt;: job이 동작할 수 있는 최대 시간 (초) -P \u0026lt;seconds\u0026gt;: job 상태를 업데이트하기 위해 polling할 때 대기하는 시간 (초)  Update servers asynchronously, monitoring progress yum -y update를 모든 서버에서 시작하여 기다려 보자. -P 옵션을 쓰지 않으면 Ansible은 default로 10초마다 polling 한다.\n$ ansible multi -b -B 3600 -a \u0026#34;yum -y update\u0026#34; 조금 기다리면(VM을 설치한 host에 따라 오래 걸릴수도 있다) 다음과 같은 결과를 볼 수 있다.\n\u0026lt;job 763350539037\u0026gt; finished on 192.168.60.6 =\u0026gt; { \u0026#34;ansible_job_id\u0026#34;: \u0026#34;763350539037\u0026#34;, \u0026#34;changed\u0026#34;: true, \u0026#34;cmd\u0026#34;: [ \u0026#34;yum\u0026#34;, \u0026#34;-y\u0026#34;, \u0026#34;update\u0026#34; ], \u0026#34;delta\u0026#34;: \u0026#34;0:13:13.973892\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2021-02-09 04:47:58.259723\u0026#34;, \u0026#34;finished\u0026#34;: 1, ... [more info and stdout from job] ... background 작업이 실행되는 동안 Ansible의 async_status module에 jid에 ansible_job_id를 넣어 작업 상태를 확인할 수 있다.\n$ ansible multi -m async_status -a \u0026#34;jid=763350539037\u0026#34; Fire-and-forget tasks 또한 장기간 동작하는 유지보수 스크립트를 돌리거나 완료되기까지 오래 걸리는 어떤 작업을 하면, 그 작업을 가만히 기다리고 싶지는 않을 것이다. 이런 경우에 -B를 높게 설정할 수 있다. (그렇게 해서 작업이 Ansible이 이를 죽이기 전에 끝내도록 할 수 있다.) 그리고 -P를 0으로 설정하여 Ansible이 명령을 실행하고 잊어버리게 할 수 있다.\n$ ansible multi -B 3600 -P 0 -a \u0026#34;/path/to/fire-and-forget-script.sh\u0026#34; jid를 통해 상태를 추적할 수 없지만 fire-and-forget 작업에는 유용하다.\n원격으로 추적이 불가능한 작업에 대해서는 task의 진행 경과를 log로 남기는 것, 실패 시 알람을 보내는 것은 좋은 방법이다. 특히, backup을 하는 background 작업이나 business-critical database 유지관리 작업에 유용할 것이다.\n 또한 Ansible의 playbook을 async와 poll 파라미터를 정의하여 background에서 asynchrnous로 동작할 수도 있다. 나중 챕터에서 playbook의 background 동작을 자세히 살펴볼 것이다.\nCheck log files 때로 application의 에러를 디버깅 할때 또는 다른 문제를 진단할 때 서버의 log 파일을 확인해야할 필요가 있다. 일반적인 log 명령(tail, cat, grep 등)은 ansible 명령어를 통해 할 수 있다. 여기엔 몇가지 경고가 있다.\n 지속적으로 파일을 모니터링하는 tail -f같은 것은 Ansible을 통해서는 할 수 없다. 왜냐면 Ansible은 명령이 완료되었을때의 결과만 출력하기 때문이고, file을 following하는 것은 Control+C를 입력하기 전까지는 완료되지 않기 때문이다. 언젠가 async module이 이 기능을 가질지 모르지만 현재로썬 가능하지 않다. Ansible에서 명령어를 통해 방대한 양의 데이터를 stdout을 통해 리턴받는 것은 좋은 생각이 아니다. 수 KB 이상의 파일을 cat하려 한다면 각 서버에 개별적으로 로그인 해야한다. Ansible을 통해 실행된 명령어의 결과를 redirect 하거나 filtering 하려면 Ansible의 default command module이 아닌 shell module을 써야 한다. (-m shell을 명령어에 추가한다.)  간단한 예제를 통해 각 서버에서 메시지 로그 파일의 끝의 몇 줄을 확인해보자.\n$ ansible multi -b -a \u0026#34;tail /var/log/messages\u0026#34; 경고 사항에서 언급했듯이 grep같은 것으로 메시지 로그를 필터링 하고싶으면 Ansible의 default command module이 아닌 shell을 사용해라.\n$ ansible multi -b -m shell -a \u0026#34;tail /var/log/messages | grep ansible-command | wc -l\u0026#34; 192.168.60.5 | success | rc=0 \u0026gt;\u0026gt; 12 192.168.60.4 | success | rc=0 \u0026gt;\u0026gt; 12 192.168.60.6 | success | rc=0 \u0026gt;\u0026gt; 14 이 명령어는 얼마나 많은 Ansible command가 각 서버에서 동작했었는지를 보여준다. (숫자는 다를 수 있다)\nManage cron jobs cron을 통한 주기적인 작업은 시스템의 crontab을 통해 할 수 있다. 일반적으로 서버에서의 cron job 설정을 변경하려면 서버에 접속하고 crontab -e를 cron job이 있는 계정에서 사용하여 간격과 작업을 입력한다.\nAnsible은 cron module을 통해 cron jobs를 관리할 수 있다. 매일 4 a.m.에 모든 서버에서 shell script를 실행하고 싶으면 다음과 같은 cron job을 추가하면 된다.\n$ ansible multi -b -m cron -a \u0026#34;name=\u0026#39;daily-cron-all-servers\u0026#39; hour=4 job=\u0026#39;/path/to/daily-script.sh\u0026#39;\u0026#34; Ansible은 지정하지 않은 값에 대해서는 *이라고 가정할 것이다. (유효한 값은 day, hour, minute, month, weekday이다) 또한 special_time=[value]를 사용하여 reboot, yearly, monthly같은 특정 시간을 설정할 수도 있다. job을 특정 유저로 하고싶으면 user=[user]를 사용하면 되고 현재 crontab을 백업하고 싶으면 backup=yes를 사용하면 된다.\ncron job을 제거하려면 어떻게 해야할까? 간단히 동일한 cron 명령어에다가 삭제하고 싶은 cron job 이름을 적고 state=absent를 사용하면 된다.\n$ ansible multi -b -m cron -a \u0026#34;name=\u0026#39;daily-cron-all-servers\u0026#39; state=absent\u0026#34; 또한 Ansible로 custom crontab 파일을 관리할 수 있다. 앞선 syntax와 동일하게 사용하지만 cron file의 location을 cron_file=cron_file_name으로 설정하면 된다. (cron_file_name은 /etc/cron.d에 위치한 cron file이다)\nAnsible은 Ansible-managed crontab 목록을 바로 위에 #Ansible: daily-cron-all-servers같은 comment를 남겨서 나타낸다. 이 crontab은 이대로 남겨두는 것이 제일 좋고, 항상 ad-hoc command 또는 Ansible의 cron module을 사용하는 playbook으로 관리해야 한다.\n Deploy a version-controlled application git checkout으로 업데이트를 하거나 새로운 코드를 서버에서 복사한 뒤 배포를 위해 명령어를 실행시키는 간단한 어플리케이션의 배포에서 Ansible의 ad-hoc mode가 도움이 될 수 있다. 더 복잡한 배포에서 Ansible playbook과 rolling update 기능(이후에 더 설명할 것이다)을 사용하여 zero downtime으로 배포를 성공적으로 할 수 있다.\n아래의 예시에서 하나 또는 두개의 서버에서 /opt/myapp 디렉토리에 있는 간단한 어플리케이션을 실행한다고 가정한다. 이 디렉토리는 중앙 서버 또는 GitHub같은 곳에서 clone한 git repository이고 어플리케이션의 배포와 업데이트는 clone을 업데이트 하고나서 /opt/myapp/scripts/update.sh에 있는 shell script를 실행시켜 진행된다.\n먼저, 모든 app 서버에서 application의 새로운 branch인 1.2.4로 git checkout을 하여 업데이트 한다.\n$ ansible app -b -m git -a \u0026#34;repo=git://example.com/path/to/repo.git dest=/opt/myapp update=yes version=1.2.4\u0026#34; Ansible의 git module은 branch, tag 또는 version parameter와 함께 특정한 commit을 지정할 수 있도록 한다. (이 경우 우리는 1.2.4 tag로 checkout하지만 prod같은 brach 이름으로 명령어를 실행하고자 한다면 Ansible은 이를 해줄 것이다) Ansible이 강제로 checked-out copy를 업데이트하도록 하려면 update=yes를 추가하면 된다. repo와 dest 옵션은 의미가 명확하다.\n그 다음 application의 update.sh shell script를 실행시킨다.\n$ ansible app -b -a \u0026#34;/opt/myapp/update.sh\u0026#34; ad-hoc command는 (위에서 본 예제와 같은)간단한 배포에 적합하지만 더 복잡한 어플리케이션 또는 복잡한 인프라를 필요로 할 경우 사용할 수 있는 Ansible의 더 강력하고 유연한 어플리케이션 배포 기능은 이 책의 뒷부분에 설명되어있다. 특히 Rolling Updates 섹션을 보아라.\nAnsible's SSH connection history Ansible의 가장 좋은 기능 중 하나는 추가적인 어플리케이션이나 daemon을 관리하는 서버에서 실행시키지 않아도 된다는 것이다. 대신 서버와 적절한 프로토콜로 통신을 하며 Ansible은 거의 모든 Linux 서버에서 동작하는 일반적인 관리를 위해 표준화되고 안전한 SSH 연결을 사용한다.\n안정적이고 빠르고 안전한 SSH 연결은 Ansible 통신 기능의 심장과도 같기 때문에 Ansible의 SSH 구현은 지난 몇년간 지속적으로 개선되어왔고 지금도 계속되고있다.\nAnsible의 SSH 연결 방법의 일반적인 것 중 하나는 Ansible이 연결을 통해 play나 command로 정의한 하나 또는 몇가지 파일을 원격 서버로 전송하고, play/command를 실행하고, 전송된 파일을 삭제하고, 결과를 리포트하는 것이다. 이런 이벤트 sequence는 나중의 Ansible에서는 변경될 수 있고 더 간단하고 직접적으로 변할 수 있다. (아래 Ansible 1.5를 보아라) 하지만 빠르고, 안정적이고 안전한 SSH 연결은 Ansible에서 무엇보다도 중요하다.\nParamiko 먼저 Ansible은 paramiko(Python에서 SSH2 implementaion을 한 open source)만을 사용한다. 하지만 단일 언어(Python)에 대한 단일 라이브러리로 paramiko의 개발은 OpenSSH의 개발을 따라잡지 못하고 있다. (거의 모든 곳에서 사용되는 SSH의 표준 구현이다) 그리고 OpenSSH보다 퍼포먼스와 보안이 약간은 떨어진다. 최소한 작성자의 관점에서는 말이다.\nAnsible이 계속해서 paramiko를 지원하며, 그리고 이를 (OpenSSH 5.6 또는 이후버전에서 option으로 지원하는)ControlPersist에서는 지원하지 않는 system의 default로 선택하며(RHEL 5/6 처럼) (ControlPersist는 서버의 SSH config에서 설정된 ControlPersist timeout이 될때까지 SSH 연결이 유지되도록 한다)\nOpenSSH (default) Ansible 1.3부터 Ansible은 default로 OpenSSH 연결을 사용하여 ControlPersist를 지원하며 서버에 연결하도록 하였다. Ansible은 이 기능을 0.5 버전부터 가지고 있었지만 1.3부터 default가 되었다.\n대부분의 local SSH configuration parameters(hosts, key files, 등)은 사용되지만 22 포트(default SSH Port)가 아닌 포트로 연결을 해야한다면 inventory file(ansible_ssh_port 옵션)에 포트를 지정하거나 ansible command를 이용해야 한다.\nOpenSSH는 paramiko보다 빠르고 더 믿을 수 있다. 하지만 Ansible을 빠르게 하는 방법은 여전히 더 존재한다.\nAccelerated Mode ad-hoc command가 그렇게 도움이 되지 않더라도 Ansible의 Accelerated mode는 playbook에 보다 더 좋은 퍼포먼스를 보여준다. 반복적으로 SSH를 통해 연결하는 것 대신, Ansible은 SSH를 처음에 연결하고, 처음 연결에 사용한 AES key를 사용하여 나머지 명령어와 통신하고 분리된 포트를 통해 전송한다(5099가 default지만 설정 가능하다).\naccelerated mode를 위해 필요한 추가적인 패키지는 python-keyczar 뿐이고 OpenSSH/Paramiko mode에서 사용가능한 대부분의 것은 sudo를 사용할 때 빼고 Accerlerated mode에서 사용 가능하다.\n sudoers 파일에 requiretty가 disabled 되어있다. (여기서 주석을 해제하거나 각 유저에 대해 Defaults:username !requiretty로 줄을 변경한다) sudoers 파일에서 NOPASSWD 설정을 하여 sudo password를 disable한다.  Accelerated mode는 OpenSSH에 비해 2~4배 더 빠른 성능(특히 파일 전송같은 것들에서)을 보여주고 playbook에서 accelerate: true를 설정하여 활성화 할 수 있다.\n--- - hosts: all accelerate: true 말할 것도 없이 accelerated mode를 사용하면 통신을 할 때 사용할 포트가 방화벽에서 뚫려있어야 한다. (5099 port가 default이며 accelerate 뒤에 이은 accelerate_port 옵션을 통해 지정한 포트 어느것도 될 수 있다.)\naccelerate mode는 Ansible의 통신을 가속화하는 비슷한 방법이지만 ZeroMQ가 controlled 서버에 설치(Ansible의 simple no-dependency와 no-daemon philosophy에 위배된다)되어야 하고 sudo command는 작동하지 않는, 지금은 deprecated된 Fireball mode에서 영감을 얻었다.\nFaster OpenSSH in Ansible 1.5+ Ansible 1.5부터 Ansible의 default OpenSSH 구현에 매우 큰 개선이 있었다.\n파일을 복사하는 대신 이를 원격 서버에서 실행하게 하고 이들을 지우는 새로운 OpenSSH 전송 방법은 SSH 통신을 통해 대부분의 Ansible module에 대한 명령어를 전송하고 실행할 것이다.\n이 연결 방법은 Ansible 1.5+에서만 사용할 수 있고 pipelining=True를 Ansible configuration file(나중에 좀 더 자세히 설명할, ansible.cfg)의 [ssh_connection] 섹션 아래에 추가하여 활성화 할 수 있다.\npipelining=True 설정 옵션은 /etc/sudoers의 Defaults requiretty 옵션을 제거했거나 주석처리 했다면 도움되지 않을 것이다. 대부분의 OS에서 이는 default configuration으로 설정되어 있지만, 이 세팅을 다시 한번 확인하여 fastest connection이 가능할지 확인해라.\n Mac OS X, Ubuntu, Cygwin을 사용한 Windows나 다른 대부분의 OS의 최신 버전으로 ansible과 ansible-playbook을 실행하는 host를 사용한다면, OpenSSH 5.6 이후 버전을 실행해야 Ansible의 SSH connection 세팅과 함께 사용되는 ControlPersist setting과 잘 동작한다.\n만일 Ansible이 실행되고 있는 호스트가 RHEL이나 CentOS를 가지고 있다면 OpenSSH 버전을 최슨으로 업데이트 하여 빠르고/지속 가능한 연결 방법을 사용할 수 있다. OpenSSH 5.6버전 이후는 전부 다 잘 작동한다. 이후의 버전들을 설치하려면 소스코드로부터 컴파일하거나 CentALT같은 다른 레파지토리를 사용하고 yum update openssh를 하면 된다.\n Summary 이 챕터에서 우리는 어떻게 local workstation에 test 목적을 위한 multi-server infrastructure를 Vagrant를 통해 구축하는지, 이를 설정하고 모니터링하고 인프라를 각 서버에 접속하지 않고도 관리하는 방법에 대해 배웠다. 또한 어떻게 Ansible이 원격 서버에 접속하는지에 대해 배웠고 어떻게 ansible 명령어가 많은 서버의 작업들을 빠르게 병렬적으로 수행할 수 있는지 하나씩 보았다.\n이제 우리는 Ansible의 basic과 익숙해지게 되었고, 더 효과적으로 우리만의 infrastructure를 관리할 수 있게 되었다.\n"
},
{
	"uri": "http://kimmj.github.io/ibiza/2020-new-year-holiday-plans/",
	"title": "2020 New Year Holiday Plans",
	"tags": ["holiday"],
	"description": "",
	"content": "설 연휴 계획 date : 2020-01-22T00:34:37+09:00\n- [ ] 연돈 가보기\n  블로그에 댓글기능 추가하기\n  블로그 레이아웃 구성\n 왼쪽 사이드바를 더 넓게.  - [ ] 오른쪽 여백 생성하여 가운데 정렬이 되도록\n- [ ] 배경 설정?\n 폴더 구분지을 prefix 추가 active 상태인 폴더는 다른 prefix로 임시 변경    연휴에도 할일 다 하기\n  Kubernetes localization 확인하기\n  "
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/choose-your-environment/",
	"title": "Choose Your Environment",
	"tags": ["install", "spinnaker"],
	"description": "",
	"content": "Spinnaker를 배포하는 방법에는 3가지가 있습니다. Kubernetes 환경에 배포하기, local debian으로 배포하기, local git으로 배포하기가 있습니다.\n여기에서는 Kubernetes 환경에 배포하기를 진행할 것입니다.\nACCOUNT=wonderland hal config deploy edit --type distributed --account-name $ACCOUNT 위와같이 설정하면 됩니다. ACCOUNT는 kubernetes cluster를 추가할 때 사용했던 이름을 사용하면 됩니다.\n"
},
{
	"uri": "http://kimmj.github.io/ansible/ansible-for-devops/ansible-playbooks/",
	"title": "Ansible Playbooks",
	"tags": ["ansible", "ansible-playbooks"],
	"description": "",
	"content": "Power plays 다른 여느 configuration management solution처럼 Ansible은 configuration file을 설명하는데 메타포를 사용한다. 이를 playbooks라고 부르고 여기에는 특정한 서버나 특정 서버 그룹에서 실행되는 tasks(Ansible의 용어에서는 play)의 리스트가 있다. 미식 축구에서 팀은 게임에서 이기기 위해 사전 정의된 playbook을 플레이의 기반으로 실행하고 따른다. Ansible에서 우리는 playbook(서버가 특정한 configuration state로 가기 위해 실행해야 하는 스텝들의 리스트)을 작성하고 서버 위에서 play되도록 할 것이다.\nPlaybook은 configuration을 정의하는 상황에서는 자주 쓰이고 사람이 읽을 수 있는 간단한 문법을 가진 YAML로 작성되어있다. Playbook은 다른 playbook에 포함될 수 있고 특정 metadata와 옵션들은 다른 play를 하도록 할 수 있으며 또는 playbook이 서버마다 다른 시나리오로 동작하게 할 수도 있다.\nad-hoc 명령어는 그 자체로 Ansible을 powerful하게 만들어준다. playbook은 Ansible을 최고의 server provisioning과 configuration management tool로 만들어준다.\n대부분의 DevOps 사람들이 Ansible에 매료된 이유는 shell scripts를 쉽게 직접 ansible play로 변경할 수 있기 때문이다. 다음의 스크립트가 있다고 가정해보자. 이는 RHEL/CentOS 서버에 Apache를 설치하는 것이다.\n# Install Apache yum install --quiet -y httpd httpd-devel # Copy configuration files cp /path/to/config/httpd.conf /etc/httpd/conf/httpd.conf cp /path/to/config/httpd-vhosts.conf /etc/httpd/conf/httpd-vhosts.conf # Start Apache and configure it to run at boot service httpd start chkconfig httpd on shell script를 실행하려면(이 경우에 파일 이름은 shell-script.sh이다), command line에서 직접 호출하면 된다.\n# (From the same directory in which the shell script resides) $ ./shell-script.sh Ansible Playboook "
},
{
	"uri": "http://kimmj.github.io/jenkins/",
	"title": "Jenkins",
	"tags": [],
	"description": "",
	"content": "Jenkins "
},
{
	"uri": "http://kimmj.github.io/iac/",
	"title": "IaC",
	"tags": [],
	"description": "",
	"content": "Infrastructure as Code "
},
{
	"uri": "http://kimmj.github.io/english/himym/season2/",
	"title": "Season2",
	"tags": [],
	"description": "",
	"content": "Chapter X Some Chapter title Lorem Ipsum.\n"
},
{
	"uri": "http://kimmj.github.io/ansible/ansible-for-devops/",
	"title": "Ansible for DevOps",
	"tags": [],
	"description": "",
	"content": "Ansible Ansible For DevOps Ansible For DevOps라는 책에 대해 공부하고 정리한 것들입니다.\n"
},
{
	"uri": "http://kimmj.github.io/cicd/",
	"title": "CICD",
	"tags": [],
	"description": "",
	"content": "CICD "
},
{
	"uri": "http://kimmj.github.io/css/",
	"title": "CSS",
	"tags": [],
	"description": "",
	"content": "CSS "
},
{
	"uri": "http://kimmj.github.io/kubernetes/concepts/controllers-overview/",
	"title": "Controllers Overview",
	"tags": ["kubernetes", "concepts"],
	"description": "",
	"content": "Contents 이 포스트에서는 Kubernetes의 Controller들에 대해서 알아보도록 하겠습니다. 가장 작은 단위인 Container부터, 상위 개념인 Deployment, StatefulSet까지 다루어 보도록 하겠습니다.\n Containers Pods ReplicaSets Deployments StatefulSets  Monolithic vs. Microservice 우선 Monolithic과 Microservice에 대해서 짚고 넘어가도록 하겠습니다.\nMonolithic의 개념은 하나의 큰 어플리케이션을 말합니다. 여러 사람이 개발을 하고 나서 하나의 큰 패키지로 빌드하고 이를 배포하죠. 간단한 서비스라면 문제가 발생하지는 않겠지만, 점점 코드의 수가 늘어나고 거대해질 수록 문제점이 생깁니다. 예를 들면 빌드시간이 오래걸린다던지, scale-out을 하기 힘들다던지 하는 문제가 있겠네요.\n반면 Microservice는 하나의 큰 어플리케이션을 여러 조각으로 쪼갠 것을 의미합니다. 각 조각(microservice)는 자신의 역할이 있고, 이를 잘 수행하면 됩니다. 전체적인 관점에서 보면 어플리케이션은 microservice들간의 통신으로 행해진다고 보면 될 것 같습니다.\nMonolithic에 비해 Microservice는 몇가지 장점들이 있습니다.\n scale-out이 용이합니다.\nMonolithic에 비해 microservice의 단위는 작기 때문에 scale-out 하는데 시간도 오래 걸리지 않고, 간단합니다. 빠른 배포가 가능합니다.\nMonolithic에서는 사이즈가 커질수록 빌드하는 시간이 점점 길어진다고 설명했었습니다. 이는 곧 요즘처럼 트렌드라던지 상황이 급변하는 상황에서 약점이 될 수 밖에 없습니다. 반면 Microservice는 작은 조각이기 때문에 빌드하는 시간이 Monolithic에 비해 뛰어날 수밖에 없습니다. 그리고 이를 배포하는 시간도 매우 줄어들게 되죠. 문제가 발생하였을 때 영향이 적습니다.\n쉽게 우리가 가장 잘 알고있는 게임중 하나인 LoL을 가지고 설명해 보도록 하겠습니다. 만약 LoL을 플레이하고 싶은데, 상점에 에러가 있어서 이용하지 못한다면 어떻게 되나요? LoL이 Monolithic이었다면 게임 플레이가 막혀서 엄청난 원성을 샀을 것입니다. 하지만 LoL또한 Microservice이기 때문에 문제가 발생한 곳만 이용하지 못할 뿐, 나머지 서비스는 정상적으로 이용이 가능합니다. 따라서 복구하기도, 운영하기도 훨씬 쉽습니다.  이렇게 보면 무조건 Microservice만 해야하는 것처럼 보이기도 합니다. 하지만 세상일이 모두 그렇듯 여기에도 정답은 없습니다. 자신이 개발하고자 하는 어플리케이션의 특성을 잘 파악해서 한가지를 선택하고 개발하는 것이 좋은 방향이 될 것 같습니다.\nConatiners 이제 본격적인 설명으로 넘어가보도록 하겠습니다.\nDocker를 사용해 보았다면 container도 친숙한 개념이 될 것 같습니다. container는 VirtualBox처럼 가상화를 하지만, OS까지 가상화하는 것이 아니라 host OS 위에서 커널을 공유하는 방식으로 가상화를 합니다. 어려운 말일수도 있지만 간단하게 말하자면 VirtualBox같은 hypervisor에 의한 가상화보다 훨씬 가벼운 방법으로 가상화를 할 수 있다고 생각하시면 됩니다. 여기서 가볍다는 의미는 빠르게 생성/삭제할 수 있고 용량도 작다는 의미입니다.\nKubernetes는 이런 Docker와 같은 container runtime 기반으로 동작합니다. 그리고 각 container는 어플리케이션 내에서 자신의 역할을 수행하는 것들입니다. Docker를 통해 컨테이너를 동작시키는 것처럼, Kubernetes도 컨테이너를 Docker같은 container runtime의 힘을 빌려 동작시킵니다.\nPods Pod는 Kubernetes에서 어플리케이션을 관리하는 단위입니다.\n하나의 Pod는 여러개의 Container로 구성될 수 있습니다. 즉, 너무나 밀접하게 동작하고 있는 여러 Container를 하나의 Pod로 묶어 함께 관리하는 것입니다.\n이 때, 하나의 Pod 내에 존재하는 모든 Container들은 서로 localhost를 통해 통신할 수 있습니다.\nKubernetes에서 Pod는 언제 죽어도 이상하지 않은 것으로 취급됩니다. 동시에 언제 생성되어도 이상하지 않은 것, 어디에 떠있어도 이상하지 않은 것이죠. 그 만큼 어플리케이션 개발자는 Pod를 구성할 때 하나의 Pod가 장애가 나는 경우에도 어플리케이션이 제대로 동작할 수 있도록 만들어야 합니다. 언제 없어졌다가 생성될지 모르니까요.\nReplicaSet ReplicaSet은 Pod를 생성해주는 녀석입니다.\n단일 Pod를 그냥 생성해도 되지만 그렇게 할 경우 Kubernetes가 주는 여러 이점들, 예를 들어 auto healing, auto scaling, rolling update 등을 이용하지 못합니다. 때문에 Pod를 관리해주는 Controller가 필요하게 되는데 이것이 ReplicaSet입니다.\nReplicaSet은 자신이 관리해야하는 Pod의 template을 가지고 있습니다. 그리고 주기적으로 Kubernetes를 주시하며 내가 가지고 있는 template에 대한 Pod가 원하는 숫자만큼 잘 있는지 확인합니다. 부족하다면 Pod를 더 생성하고 너무 많으면 Pod를 삭제합니다.\nReplicaSet은 Pod를 label을 기준으로 관리합니다. 자신이 가지고 있는 matchLabels와 일치하는 Pod들이 자신과 관련된 Pod라고 인식하는 것이죠. 따라서 label을 운영중에 바꾸는 일은 웬만해선 피해야 합니다. 고아가 발생하여 어느 누구도 관리해주지 않는 Pod가 남게 될 수 있기 때문입니다.\n또한 ReplicaSet은 자신이 생성한 파드들을 \u0026lt;ReplicaSet의 이름\u0026gt;-\u0026lt;hash 값\u0026gt;으로 생성합니다. 따라서 Pod의 이름만 보고도 어떤 ReplicaSet이 생성했는지 알 수 있게되죠.\nDeployments 위에서는 ReplicaSet에 대해서 이야기해 보았습니다. Deployments는 ReplicaSet보다 상위 개념의 Controller입니다.\n만약 Pod의 template을 수정하는 경우가 생긴다면 어떻게 해야 할까요? 예를 들어 cpu 할당량을 바꾼다던지, image를 다른 이미지로 변경한다던지 하는 경우가 발생한다면요. ReplicaSet만 존재한다면 이런 상황에서 새로운 template을 가지고 ReplicaSet을 생성하고, 기존의 ReplicaSet을 삭제하거나 replicas: 0으로 변경하여 ReplicaSet만 남아있고 실제 Pod는 없도록 해야합니다.\n그렇다면 새로 만든 template에 오류가 있어서 이전 버전으로 돌아가고 싶다면 어떻게 해야할까요? 이전에 작성했던 ReplicaSet의 replicas를 늘리고, 현재 올라가있던 ReplicaSet의 replicas를 줄이면 될 것 입니다. 하지만 이는 일일이 기억해야하는 크나큰 단점이 있겠죠.\n때문에 ReplicaSet을 관리해주는 Deployment가 필요합니다. Deployment는 ReplicaSet을 생성하고 이 ReplicaSet이 Pods를 생성하도록 만듭니다. 그리고 자신이 관리하는 ReplicaSet의 labels를 자신의 matchLabels로 일치시켜 구분합니다.\n그렇다면 Pod의 template이 변경되는 상황엔 이번에는 어떻게 적용이 될까요?\nDeployment는 새로운 ReplicaSet을 생성하고, 기존 ReplicaSet의 replicas를 0으로 줄입니다. 그러면서 자신이 생성했던 ReplicaSet들을 revision으로 관리하죠. 이렇게 되면 사용자는 kubectl 명령어만 가지고 이전 template을 가진 Pod로 변경할 수 있습니다.\n또한 Deployments가 ReplicaSet을 생성할 때는 \u0026lt;Deployment의 이름\u0026gt;-\u0026lt;hash 값\u0026gt;으로 생성합니다. 위에서 ReplicaSet도 Pod를 생성할 때 \u0026lt;ReplicaSet의 이름\u0026gt;-\u0026lt;hash 값\u0026gt;이라고 설명했었습니다. 따라서 Deployments에 의해 만들어진 Pod들은 \u0026lt;Deployment의 이름\u0026gt;-\u0026lt;ReplicaSet에 대한 hash 값\u0026gt;-\u0026lt;Pod에 대한 hash 값\u0026gt;과 같은 형태를 띄게 됩니다.\nStatefulSets StatefulSet은 좀 특이한 녀석입니다.\nPod는 어디에 떠있어도 이상하지 않은 것이라고 언급했었습니다. 그런데 StatefulSet은 그렇지 않습니다. 이름에 걸맞게 이전의 상태를 그대로 보존하고 있어야 합니다. 따라서 여러 제약사항들이 생기기도 합니다.\n여기에서는 Pod와의 관계만 알아보고 넘어가도록 하겠습니다.\nStatefulSets는 Deployments와는 다르게 ReplicaSet을 생성하지 않습니다. 대신 자신이 직접 Pod를 생성합니다. 이 때 Pod의 label 속성을 자신의 matchLabels과 일치시켜 자신이 관리하고 있는 Pod를 구분합니다.\n또한 이름도 hash값을 사용하지 않고 0부터 시작하는 숫자를 사용합니다. 즉, \u0026lt;StatefulSets의 이름\u0026gt;-\u0026lt;0부터 오름차순\u0026gt;의 이름을 가지는 Pod를 생성합니다.\n만약 생성해야하는 Pod의 template에 변화가 있다면 어떻게 해야할까요?\nStatefulSets는 Deployments와 다르게 변경할 수 있는 부분에 제약이 있습니다. 이 경우 절대 StatefulSet을 update할 수 없습니다. 따라서 기존 StatefulSet을 삭제하고 다시 kubectl apply와 같은 명령어로 새로운 template을 가지고 생성해야합니다.\nRollback에도 제약사항이 있습니다.\nRollback시 StatefulSet은 Pod가 완전히 Ready상태가 되길 기다립니다. 그런데 만약 StatefulSet이 생성한 Pod가 ImagePullbackOff같은 에러에 빠지게 된다면, 또는 영원히 rediness probe에 의해 Ready 상태가 되지 않는다면 StatefulSet의 rollback은 멈춰버립니다. 이는 Known Issue로 수동으로 해당 Pod를 삭제하는 방법밖에 없습니다.\n따라서 웬만하면 설계를 할 때 StatefulSet을 지양하는 것이 Kubernetes의 Design에 더욱 맞는 방향일 것입니다.\n마치며.. 이렇게 Container, Pods, ReplicaSets, Deployments, StatefulSets의 관계를 중심으로 알아보는 시간을 가졌습니다. 혹시나 잘못된 부분이 있다면 언제든지 댓글 또는 메일로 알려주시면 감사하겠습니다.\n"
},
{
	"uri": "http://kimmj.github.io/kubernetes/concepts/",
	"title": "Concepts",
	"tags": [],
	"description": "",
	"content": "Kubernetes Concepts "
},
{
	"uri": "http://kimmj.github.io/ubuntu/tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": "Ubuntu Tools "
},
{
	"uri": "http://kimmj.github.io/prometheus/",
	"title": "Prometheus",
	"tags": [],
	"description": "",
	"content": "Prometheus "
},
{
	"uri": "http://kimmj.github.io/spinnaker/canaryanalysis/",
	"title": "CanaryAnalysis",
	"tags": [],
	"description": "",
	"content": "Spinnaker Canary Analysis Canary Analysis는 Spinnaker에서 자동으로 분석을 통해 새로운 버전에 문제가 없는지 확인해주는 pipeline입니다.\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/choose-a-storage-service/",
	"title": "Choose a Storage Service",
	"tags": ["install", "spinnaker", "minio"],
	"description": "",
	"content": "Spinnaker들의 데이터를 저장할 공간입니다.\n여러가지 옵션들이 있지만, 저는 local로 운용할 수 있는 minio를 통해 데이터를 저장해 볼 것입니다.\nminio를 docker-compose를 통해 쉽게 배포하도록 할 것입니다. 먼저, docker-compose를 설치합니다.\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 그 뒤 minio의 docker-compose.yaml을 만듭니다.\nversion: '3.7' services: minio: image: minio/minio:RELEASE.2020-01-16T22-40-29Z volumes: - ./data:/data ports: - \u0026quot;9000:9000\u0026quot; environment: MINIO_ACCESS_KEY: minio MINIO_SECRET_KEY: minio123 command: server /data healthcheck: test: [\u0026quot;CMD\u0026quot;, \u0026quot;curl\u0026quot;, \u0026quot;-f\u0026quot;, \u0026quot;http://localhost:9000/minio/health/live\u0026quot;] interval: 30s timeout: 20s retries: 3 docker-compose를 통해서 deamon으로 실행합니다.\ndocker-compose up -d 이제 halyard와 연동을 하도록 합니다.\n먼저, ~/.hal/default/profiles/front50-local.yml 파일을 다음과 같이 생성합니다.\nspinnaker: s3: versioning: false 그 다음 다음의 명령어로 연동을 합니다.\nENDPOINT=http://10.0.2.4:9000 MINIO_ACCESS_KEY=minio MINIO_SECRET_KEY=minio123 echo $MINIO_SECRET_KEY | hal config storage s3 edit --endpoint $ENDPOINT \\  --access-key-id $MINIO_ACCESS_KEY \\  --secret-access-key hal config storage edit --type s3 "
},
{
	"uri": "http://kimmj.github.io/kubernetes/",
	"title": "Kubernetes",
	"tags": [],
	"description": "",
	"content": "Kubernetes Kubernetes는 deploy, scaling, 그리고 컨테이너화된 애플리케이션의\nmanagement를 자동화 해주는 open source container orchestration engine입니다.\n"
},
{
	"uri": "http://kimmj.github.io/hugo/ibiza/",
	"title": "Ibiza",
	"tags": [],
	"description": "",
	"content": "Hugo Ibiza Ibiza는 이 블로그를 만드는 프로젝트입니다.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/network/",
	"title": "Network",
	"tags": [],
	"description": "",
	"content": "Ubuntu Network "
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode5/",
	"title": "Episode5",
	"tags": [],
	"description": "",
	"content": "Did I just have a stroke? 여기서 stroke은 뇌졸증이라고 해석할 수 있습니다. 이를 약간은 의역하자면 내가 뇌졸증에 걸렸나?보단 내 머리가 이상해졌나? 이정도로 생각해보면 될 것 같습니다.\nAll the things you do when you know where your next thousand lays are coming from. 이 말 앞에는 마샬, 릴리가 약혼 후에 더욱 성숙해지고자 북클럽에 가입하고, 와인파티를 한다는 내용이 있습니다. 여기서 바니가 위의 대사를 하는데 이러한 것들(성숙해지고자 하는 행동들)은 where your next thousand lays are coming from을 알때나 하는 행동이라는 뜻입니다.\n여기서 lays라는 표현은 sexual encounters 즉, 성적인 만남의 대상들이라는 의미로 해석됩니다.\n결국 이 문장의 의미는 \u0026ldquo;다음 천번의 관계를 누구랑 할 지 알때나 하는 행동이다\u0026quot;라는 의미가 되고, 그 이유는 마샬과 릴리가 약혼을 했다는 사실을 기반으로 한 이야기가 될 것입니다.\nGrandma, Grandpa, don't wait up wait up이라는 의미는 누군가 집에 오기를 자지 않고 기다린다는 뜻입니다. 영영사전에도 다음과 같이 설명이 되어있습니다.\n to not go to bed at night because you are expecting someone to arrive\n 즉, 윗 문장의 의미는 \u0026ldquo;기다리지 말고 자\u0026quot;라는 뜻이겠네요.\nIt's so stupid and arbitrary, isn't it? arbitrary는 \u0026ldquo;임의적인, 제멋대로인\u0026quot;이라는 뜻입니다.\n따라서 이 의미는 \u0026ldquo;이건 너무 멍청하고 제멋대로야. 그렇치 않아?\u0026ldquo;가 되겠네요\nWe're really starting to click with these guys. click with someone은 어떤 사람과 이제 알아가기 시작했다는 말입니다.\n즉, \u0026ldquo;우리는 이제 진짜 이 사람들이랑 친해지기 시작했어\u0026quot;라는 뜻입니다.\nShould've snuck in with Brian Affleck. snuck은 sneak의 과거, 과거분사형입니다. \u0026ldquo;몰래 가다\u0026quot;라는 뜻이 있습니다.\n즉, \u0026ldquo;Brian Affleck이랑 같이 몰래 들어갔어야죠\u0026quot;라는 의미가 되겠네요.\nI heard that in college you flashed a campus tour group on a dare on a dare라는 표현은 \u0026ldquo;감히\u0026rdquo;, \u0026ldquo;무모하게\u0026rdquo; 이런 의미로 사용됩니다.\nNo! And you know why? Becuase, italics, \u0026ldquo;This night did not happen.\u0026rdquo; italics는 영문에서 보통 강조하는 문장이 있을 때 사용하곤 합니다. 따라서 윗 문장에서는 강조하는 부분 앞에 italics라고 표현했네요.\n\u0026ldquo;안돼! 왠줄 알아? 왜냐면 - 이탤릭체로 - 오늘 밤엔 아무일도 없었으니까\u0026quot;라는 의미로 해석이 됩니다.\n"
},
{
	"uri": "http://kimmj.github.io/hugo/",
	"title": "Hugo",
	"tags": [],
	"description": "",
	"content": "Hugo fast static website engine\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/",
	"title": "Spinnaker",
	"tags": [],
	"description": "",
	"content": "CI/CD Spinnaker Spinnaker는 Kubernetes 환경에서 배포 자동화를 위해 만들어진 툴입니다.\n배포하려는 클러스터가 GKE인지, EKS인지, On-Premise 환경인지 상관없이 하나의 툴로 배포하기 위해 만들어졌습니다.\n이 툴 자체가 MSA 구조로 만들어져있습니다.\n"
},
{
	"uri": "http://kimmj.github.io/ansible/",
	"title": "Ansible",
	"tags": [],
	"description": "",
	"content": "Ansible Ansible은 자동화를 할 때 사용하는 툴입니다.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/",
	"title": "Ubuntu",
	"tags": [],
	"description": "",
	"content": "Ubuntu Ubuntu에서 배운 것들을 기록하는 공간입니다.\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/deploy-and-connect/",
	"title": "Deploy and Connect",
	"tags": ["spinnaker", "install"],
	"description": "",
	"content": "드디어 마지막 절차입니다.\n먼저 어떤 버전을 설치할지 확인후 설정합니다.\nhal version list 작성 기준으로 최신 버전이 1.17.6이므로 이를 설정합니다.\nhal config version edit --version 1.17.6 halyard를 NodePort로 노출시키기 위해 api와 ui에 base url을 부여합니다.\nhal config security ui edit --override-base-url http://192.168.8.22:30100 hal config security api edit --override-base-url http://192.168.8.22:30200 이제 본격적으로 deploy를 하도록 합니다.\nhal deploy apply 그 후 Spinnaker를 NodePort로 서비스합니다.\nkubectl patch svc spin-deck -n spinnaker --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;}]\u0026#39; kubectl patch svc spin-gate -n spinnaker --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;}]\u0026#39; kubectl patch svc spin-deck -n spinnaker --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;: 30100}]\u0026#39; kubectl patch svc spin-gate -n spinnaker --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;: 30200}]\u0026#39; 이제 Spinnaker로 접속하여 확인합니다. url은 http://:30100 입니다.\n여기까지 했으면 Spinnaker를 Kubernetes에서 사용할 수 있습니다.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode6/",
	"title": "Episode6",
	"tags": [],
	"description": "",
	"content": "Do they rule? They rule.\nIt's the one night of the year chicks use to unleash their inner ho-bag\ntrot out your new fella\nIt was carve3d in strategic places\nShe could be engaged, or married, or, God forbid, fat\nOh, yeah. Weirdly hor, right?\nWhat are you going as? Oh, like I evend need to ask.\nWhat? She thought it was hilarious\nWhat a sad commentary on our national attention span, that we could forget such a turbulent time in our political history\nIt's an elaborate custume.\nYour ego's writing checks your body can't cash\nHere's the plan, and I crap you not.\nIt's so hard to convey tone.\nTwould think it would be Arby's\nI'm kind of in the zone here.\nOh, for God's sakes.\nLet's bail\nNone of these other costumes even come close to ours.\nI'm also a horny devil.\nI cannot get enough of it.\nScooch.\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/installation/install-in-air-gaped-environment/",
	"title": "Install in Air Gaped Environment",
	"tags": ["install", "spinnaker", "air-gaped"],
	"description": "",
	"content": "이번에는 인터넷이 되지 않는 환경에서 어떻게 Spinnaker를 설치하는지에 대해 알아보도록 하겠습니다.\n먼저 halyard에서 언제 인터넷과 통신하는지를 대강 추려보도록 하겠습니다.\n Spinnaker의 version.yaml을 불러와서 최신의 halyard 버전과 최신 Spinnaker의 버전들을 보여줍니다.  gs://halconfig/version.yml   설치하고자 하는 Spinnaker의 버전을 선택하면, 그에 따른 배포에 필요한 yaml들을 불러옵니다.  gs://halconfig/bom/VERSION.yml gs://halconfig/MICRO_SERVICE/TAG.yml   deploy를 하기 위해 Google Cloud Repository에서 이미지를 가지고 옵니다.  gcr.io/spinnaker-marketplace/SERVICE   마지막으로 dependency가 있는 몇가지 서비스를 Google Cloud Repository에서 가지고옵니다. (consul, redis, vault)  gcr.io/kubernetes-spinnaker/SERVICE    여기서 local 설정으로 변경이 가능한 것은 2020.01.20 현재 1,2,3번 항목들입니다. 이것들을 어떻게 인터넷이 되지 않는 환경에서 설치가 가능하도록 설정하는지에 대해 알아보겠습니다.\ngsutil로 gs://halconfig 파일들을 로컬에 복사하기 우선 인터넷이 잘 되는 서버가 하나 필요합니다. 이 서버에서 우리는 필요한 BOM(Bill of Materials)를 미리 다운로드 할 것입니다.\ngsutil이 설치되어 있어야 합니다.\ngsutil -m cp -r gs://halconfig 이렇게하면 로컬에 halconfig라는 폴더가 생겼을 것입니다. 이를 인터넷이 안되는 halyard가 설치된 서버로 복사합니다. 이때, halconfig 폴더 내의 내용들은 ~/.hal/.boms/ 폴더 내에 복사합니다.\n$ ls ~/.hal/.boms/ bom clouddriver deck echo fiat front50 gate igor kayenta monitoring-daemon orca rosco versions.yml 여기서 rosco/master 폴더로 들어가면 packer.tar.gz라는 폴더가 있습니다. 이를 rosco 폴더로 옮기고 압축을 해제합니다.\nmv ~/.hal/.boms/rosco/master/packer.tar.gz ~/.hal/.boms/rosco cd ~/.hal/.boms/rosco tar xvf packer.tar.gz halyard에서 gcs의 version.yml이 아닌 로컬의 version.yml을 참조하도록 설정 기본적으로 halyard는 gs://halconfig/version.yml을 참조하려 할 것입니다. 이를 local:이라는 접두사를 붙여 로컬을 바라보게 할 수 있습니다.\nhal config version edit --version local:1.17.4 그러고 난 뒤, 각 서비스들의 BOM도 로컬을 바라보게 설정해야 합니다. 아까 위에서 1.17.4 버전을 사용한다고 했으니, 해당 yaml파일을 열고 local: 접두사를 추가합니다.\nartifactSources: debianRepository: https://dl.bintray.com/spinnaker-releases/debians dockerRegistry: gcr.io/spinnaker-marketplace gitPrefix: https://github.com/spinnaker googleImageProject: marketplace-spinnaker-release dependencies: consul: version: 0.7.5 redis: version: 2:2.8.4-2 vault: version: 0.7.0 services: clouddriver: commit: 024b9220a1322f80ed732de9f58aec2768e93d1b version: local:6.4.3-20191210131345 deck: commit: 12edf0a7c05f3fab921535723c8a384c1336218b version: local:2.13.3-20191210131345 defaultArtifact: {} echo: commit: acca50adef83a67e275bcb6aabba1ccdce2ca705 version: local:2.9.0-20191029172246 fiat: commit: c62d038c2a9531042ff33c5992384184b1370b27 version: local:1.8.3-20191202102650 front50: commit: 9415a443b0d6bf800ccca8c2764d303eb4d29366 version: local:0.20.1-20191107034416 gate: commit: a453541b47c745a283712bb240ab392ad7319e8d version: local:1.13.0-20191029172246 igor: commit: 37fe1ed0c463bdaa87996a4d4dd81fee2325ec8e version: local:1.7.0-20191029183208 kayenta: commit: 5dcec805b7533d0406f1e657a62122f4278d665d version: local:0.12.0-20191023142816 monitoring-daemon: commit: 59cbbec589f982864cee45d20c99c32d39c75f7f version: local:0.16.0-20191007112816 monitoring-third-party: commit: 59cbbec589f982864cee45d20c99c32d39c75f7f version: local:0.16.0-20191007112816 orca: commit: b88f62a1b2b1bdee0f45d7f9491932f9c51371d9 version: local:2.11.2-20191212093351 rosco: commit: 269dc830cf7ea2ee6c160163e30d6cbd099269c2 version: local:0.15.1-20191202163249 timestamp: \u0026#39;2019-12-12 14:34:16\u0026#39; version: 1.17.4 이렇게 설정하면 echo를 예로 들 때 ~/.hal/.boms/echo/2.9.0-20191029172246/echo.yml을 참조하게 될 것입니다.\n배포에 필요한 이미지들을 private registry에 불러오기 이제 실제 배포에 필요한 이미지를 로컬로 복사해두어야 합니다. 저는 내부에서 사용하는 docker registry에다가 저장해 둘 것입니다. 인터넷이 되는 서버에서 다음과 같이 작업하면 됩니다.\ndocker pull gcr.io/spinnaker-marketplace/SERVICE:TAG docker tag gcr.io/spinnaker-marketplace/SERVICE:TAG private-docker-registry/repository-name/SERVICE:TAG docker push private-docker-registry/repository-name/SERVICE:TAG 이렇게 private registry로 저장을 해 두었을 경우 VERSION.yml 파일에서 dockerRegistry 항목을 수정합니다.\nartifactSources: debianRepository: https://dl.bintray.com/spinnaker-releases/debians #dockerRegistry: gcr.io/spinnaker-marketplace dockerRegistry: private-docker-registry/repository-name gitPrefix: https://github.com/spinnaker googleImageProject: marketplace-spinnaker-release 또는 docker pull을 이용해서 이미지를 다운받고, 이를 docker save 명령어를 통해 tar.gz 파일로 변환한 뒤, Kubernetes의 모든 워커노드에서 이를 이리 docker load 하는 방법도 있습니다. 이렇게 하면 이미 로컬에 있는 이미지이기 때문에 외부로 접속하지 않습니다.\ndocker pull gcr.io/spinnaker-marketplace/SERVICE:TAG docker save -o SERVICE.tar.gz gcr.io/spinnaker-marketplace/SERVICE:TAG scp SERVICE.tar.gz TARGET_IP:~/path/to/target ssh TARGET_IP docker load -i ~/path/to/target/SERVICE.tar.gz 이번에는 dependency와 관련된 이미지를 불러와야 합니다. 먼저 Image Registry를 변경하기 위해서는 다음과 같이 조치합니다.\n ~/.hal/default/service-settings/redis.yml파일을 생성합니다. 다음과 같이 작성합니다. artifactId: private-docker-registry/repository-name/redis-cluster:v2   이 다음에는 마찬가지로 image를 pull하고 이를 private docker registry로 push합니다.\ndocker pull gcr.io/kubernetes-spinnaker/SERVICE:TAG # redis-cluster:v2 docker tag gcr.io/kubernetes-spinnaker/SERVICE:TAG private-docker-registry/repository-name/SERVICE:TAG docker push private-docker-registry/repository-name/SERVICE:TAG 또는 이미지를 tar로 묶어서 복사하는 방법도 있습니다.\ndocker pull gcr.io/kubernetes-spinnaker/SERVICE:TAG docker save -o SERVICE.tar.gz gcr.io/kubernetes-spinnaker/SERVICE:TAG scp SERVICE.tar.gz TARGET_IP:~/path/to/target ssh TARGET_IP docker load -i ~/path/to/target/SERVICE.tar.gz Image Registry가 kubernetes-spinnaker로 변경된 것을 주의하시면 됩니다.\nDeploy 여기까지 왔으면 모든 준비작업은 끝났습니다. 이제 배포만 하면 됩니다.\nhal deploy apply Reference https://www.spinnaker.io/guides/operator/custom-boms/\nhttps://github.com/spinnaker/spinnaker/issues/3967#issuecomment-522306893\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode7/",
	"title": "Episode7",
	"tags": [],
	"description": "",
	"content": "Yeah, we do that behind you back.\nYou're messing with me, right?\nSummer Breeze is my guilty-pleasure song.\nWell, by some million-to-one long shot, and I'm not rooting for this, you wind up not getting married this weekend, give me a call\nBrace yourself, dude.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode8/",
	"title": "Episode8",
	"tags": [],
	"description": "",
	"content": "You're making this up.\nNever even saw the bus.\nJust keep your eyes open.\nBut this girl, she wants the same stuff, and it's bumming me out.\nBut in the meantime, wish me luck.\nMay lead to an argument, but we're settling this.\nIs this a discussion of the degree to which you stabbed me?\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode9/",
	"title": "Episode9",
	"tags": [],
	"description": "",
	"content": "Okay, Lily, we're putting you on salad duty.\nWhy are we even talking about this? This is, like, way down the road.\nAll is right with the world again.\nLook, I don't wanna be exactly like my family. And don't take this the wrong way, but I don't wanna be exactly like your family, either.\nJust a little joke to lighten up the mood.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/ssh-tunneling/",
	"title": "SSH Tunneling 사용법",
	"tags": ["ubuntu", "tunneling"],
	"description": "",
	"content": "-D 옵션으로 socks proxy 사용하기 A라는 서버에서 B라는 서버에 있는 서비스를 보려고 합니다. 이 때, 해당 웹 어플리케이션은 B에서만 연결된 특정 IP로 통신을 하고 있고, 이 때문에 A에서 어플케이션이 제대로 동작하지 않는 상황입니다.\n이 때 사용할 수 있는 것이 -D 옵션입니다.\n예시\nssh -D 12345 user@server.com 해당 세션이 꺼져있지 않은 상태에서 A 서버에서 웹 브라우저가 localhost:12345를 프록시로 사용하도록 하면 해당 웹 어플리케이션이 제대로 동작합니다.\n만약 windows라면 다음과 같이 진행하면 socks proxy를 사용하도록 할 수 있습니다. CMD를 열고 다음과 같이 입력하면 새로운 창으로 chrome이 뜰 것입니다.\n\u0026#34;C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\u0026#34; --user-data-dir=\u0026#34;%USERPROFILE%\\proxy-profile\u0026#34; --proxy-server=\u0026#34;socks5://localhost:12345\u0026#34; 해당 창에서 어플리케이션을 실행하면 실제 B 서버의 desktop에서 동작하는 것과 같은 효과를 볼 수 있습니다.\n-L 옵션으로 특정 포트로 접속하기 A에서 B라는 서버의 어플리케이션을 사용하려 합니다. 이 어플리케이션은 특정 포트를 사용하고 있습니다. 쉬운 예시를 위해 jenkins를 B에서 구동한다고 하고 포트를 8080이라고 하겠습니다.\n이 상황에서 A에서는 server-b.com:8080에 접속할 수 없는 상황입니다.\n이 경우 -L 옵션을 사용하면 됩니다.\nssh -L 1234:localhost:8080 user@server-b.com 해당 설정을 읽어보자면, A서버의 localhost:1234로 들어오는 요청들을 user@server-b.com으로 접속한 뒤 localhost:8080으로 보내라는 의미입니다.\n다음과 같은 설정도 있을 수 있습니다.\nssh -L 12345:server-c.com:8080 user@server-b.com 이 설정은 A에서 C로 직접 통신이 안되지만, B에서 C로 통신이 되는 상황입니다.\n이 때, 위의 설정은 localhost:12345로 들어오는 요청들을 user@server-b.com으로 접속한 뒤 server-c.com:8080으로 보내라는 의미입니다.\n-R 옵션을 이용하여 Reverse Proxy 사용하기 A에서 B로 ssh 접속을 하고 있습니다. 이 때, B에서 A로는 접속이 방화벽으로 막혀있는 상황입니다.\n이런 상황에서 -R 옵션을 주면 B에서도 A로 접속할 수 있습니다.\nssh 12345:localhost:22 user@server-b.com 해당 설정은 A서버에서 접속하는 localhost의 22 포트를 B서버의 12345 포트와 연결하라는 의미입니다.\n그 다음 해당 세션이 유지된 상태에서 B에서 다음과 같이 접속합니다.\nssh localhost -p 12345 그러면 B서버에서 A서버로 접속이 가능한 것을 볼 수 있습니다.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/ssh-with-jump/",
	"title": "Gateway를 이용하여 SSH 접속하기",
	"tags": ["ssh", "linux"],
	"description": "",
	"content": "ssh cli 이용하는 방법 -J 옵션을 이용한다.\nssh user@server -J user2@server2 두개 이상의 경우 ,로 구분한다.\n예: user2@server2로 접속 후 user3@server3로 접속한 뒤 user@server로 접속해야 할 경우\nssh user@server -J user2@server2,user3@server3 이 상황에서 ssh-copy-id를 이용해 패스워드를 입력하지 않고 이동하려면\nlocaluser@localhost $ ssh-copy-id user2@server2 localuser@localhost $ ssh user2@server2 user2@server2 $ ssh-copy-id user3@server3 user2@server2 $ ssh user3@server3 user3@server3 $ ssh-copy-id user@server 이후 ssh를 통해 진입하면 패스워드 없이 접속 가능.\n만약 port가 필요한 경우 server:port 형태로 입력\nssh user@server:port -J user2@server2:port2,user3@server3:port3 ssh config 파일 이용하는 방법 Host server HostName remote-server User user ProxyJump gateway2 Host server2 HostName gateway1 User user2 Host server3 HostName gateway2 User user3 ProxyJump gateway1 "
},
{
	"uri": "http://kimmj.github.io/iac/translate-what-is-infrastructure-as-a-code/",
	"title": "[번역] What Is Infrastructure as a Code? How It Works, Best Practices, Tutorials",
	"tags": ["IaC", "infrastructure-as-code"],
	"description": "",
	"content": "link: https://stackify.com/what-is-infrastructure-as-code-how-it-works-best-practices-tutorials/\n과거에 IT infrastructure를 관리하는 것은 힘든 일이었다. 시스템 관리자는 수동으로 관리하고 어플리케이션을 구동시키기 위해 모든 하드웨어와 소프트웨어를 설정해야 했다.\n하지만 최근 몇년간 급격하게 상황들이 바뀌었다. cloud computing같은 트렌드가 디자인, 개발, IT infrastructure의 유지를 하는 방법을 혁명화하고 발전시켰다.\n이러한 트렌드의 핵심 요소는 infrastructure as code이다. 여기에 대해 이야기 해보도록 하겠다.\nDefining Infrastructure as Code infrastructure를 코드로 정의하는 것부터 시작해보도록 하자. 이것이 무엇을 의미하는지, 어떤 문제들을 해결하는지 배우게 될 것이다.\nWikipedia에서 IaC는 다음과 같이 정의되어 있다.\n Infrastructure as code is the process of managing and provisioning computer data centers through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools.\n  Infrastructure as code는 물리적인 하드웨어 설정이나 상호작용을 하는 설정 툴을 이용하는 것이 아닌, 기계가 읽을 수 있는 파일로 정의하여 computer data center들을 관리하고 프로비저닝하는 프로세스이다.\n 이 정의는 나쁘지 않지만 약간 너무 장황하게 설명했다. 더 간단하게 해보자.\n Infrastructure as code (IaC)는 IT infrastructure를 설정 파일로 관리한다는 의미이다.\n 다음 질문은 이렇게 될 것이다. \u0026ldquo;왜 그걸 쓰고싶어 하나요?\u0026rdquo;\nWhat Problem Does IaC Solve? \u0026ldquo;what\u0026quot;에 대해 생각하기 전에 \u0026ldquo;why\u0026quot;에 먼저 집중해보자. 왜 IaC가 필요한가? 이것이 어떤 문제를 풀어주는가?\nThe Pain of Managing IT Infrastructure 역사적으로 IT infrastructure를 관리하는 것은 수동 프로세스였다. 사람들은 물리적으로 서버를 위치시키고 이를 설정했다. 머신이 OS와 어플리케이션이 원하는 설정으로 되었을 때에, 어플리케이션을 배포할 수 있게 된다. 당연하게도 수동 프로세스는 자주 문제를 일으킨다.\n첫번째 큰 문제는 비용이다. 네트워크 엔지니어에서부터 하드웨어 관리 기술자까지 많은 전문가를 고용해서 프로세스의 각 단계를 수행시키도록 해야한다. 이런 모든 사람에게 돈을 지불해야 하면서 또한 관리되어야 한다. 이는 관리 오버헤드를 야기하고 기업 내의 소통의 복잡성을 증대시킨다. 결과적으로? 돈이 사라진다. 또한 우린 아직 비용을 더 많이 늘리는 데이터센터를 관리하는 것과 빌딩에 대한 이야기를 하지 않았다.\n그 다음 문제는 확장성과 가용성이다. 하지만 결국 모든 것은 속도 문제다. 수동으로 설정하는 것은 너무 느리고, 어플리케이션의 접속은 스파이크를 치고 있는 동안 시스템 관리자는 부하를 관리하기 위해 필사적으로 서버를 세팅할 것이다. 이는 가용성에도 무조건 영향을 미친다. 기업이 백업 서버나 심지어 데이터 센터가 없다면 어플리케이션은 장기간동안 이용불가능해질 것이다.\n마지막으로 가장 중요한 문제는 inconsistency이다. 몇몇 사람들이 수동으로 설정을 배포한다면, 균열은 생길수밖에 없다.\nCloud Computing: A Cure? Cloud computing은 방금 읽었던 고통들을 완화시켜준다. 이는 데이터센터를 구축하고 유지보수하는 것과 그 비용으로부터 자유롭게 해준다.\n그러나 Cloud computing은 만병통치약과는 거리가 멀다. 이것이 infrastructure를 빠르게 셋업하는데에는 도움을 주겠지만 (그래서 고가용성이나 확장성의 문제는 해결해 준다) 이는 inconsistency 이슈를 해결하지는 못한다. 설정을 수행하는 사람이 한명보다 많다면, 불균형이 생길 수 있다.\nInfrastructure as Code: The Missing Piece of the Puzzle IaC 정의를 다시 한번 봐보자.\n Infrastructure as code (IaC)는 IT infrastructure를 설정 파일로 관리한다는 의미이다.\n 정의에서 가져온 핵심은 바로 다음과 같다. IaC 이전에 IT 사람들은 infrastructure에 대해 수동으로 설정을 바꾸어야 했다. 아마 스크립트를 쓰거나 몇몇 작업은 자동화를 시켰겠지만, 그냥 그 정도였다. IaC를 통해 infrastructure의 설정은 코드 파일의 형태를 띄게 되었다. 이는 단순한 텍스트이지만 수정하고 복사하고 분배하는 것이 쉽다. 당신은 다른 소스코드 파일들처럼 source control로 이를 관리할 수 있고 또 그래야 한다.\nInfrastructure as Code Benefits 이제까지 수동으로 infrastructure를 관리하는 것의 문제점들을 알아 보았다. 우리는 여기서 어떻게 cloud computing이 이런 몇가지 문제점을 해결해 주는지, 또 어떤것들은 해결해주지 않는지 알아보았다. 그리고 우리는 IaC가 퍼즐의 마지막 조각이라고 말하며 이 논의를 마쳤다.\n이제 우리는 IaC solution을 사용할 때의 이점에 대해서 알아볼 것이다.\nSpeed IaC의 가장 중요한 이점은 스피드이다. Infrastructure as Code는 script를 실행시켜 빠르게 완전한 infrastructure를 셋업할 수 있게 해준다. 이를 개발환경과 production 환경부터 staging, QA 등등까지 모든 환경에 대해서 할 수 있다. IaC는 전체 소프트웨어 개발 라이프사이클을 효과적으로 만들어준다.\nConsistency 수동 프로세스는 실수를 불어일으키고 시간이 걸린다. 사람은 실수할 수 있다. 우리의 기억은 잘못될 수 있다. 소통은 어렵고 우리는 일반적으로 소통을 어려워한다. 여기서 읽었던 것 처럼 수동으로 인프라를 관리하는 것은 얼마나 열심히 하던지 간에 불균형을 일으키게 된다. IaC는 믿을 수 있는 하나의 소스코드로 이 설정 파일을 관리하여 이를 해결해준다. 이런 방식으로 동일한 설정이 어떤 불균형도 없이 계속해서 배포됨을 보장한다.\nAccountability 이는 빠르고 쉬운 것이다. IaC 설정 파일을 소스 코드 파일처럼 버전화 할 수 있기 때문에 설정들의 변경사항을 추적할 수 있다. 누가 이를 했고 언제 했는지 추측할 필요가 없다.\nMore Efficiency During the Whole Software Development Cycle infrastrucutre as code를 적용하면 infrastructure 아키텍쳐를 어려 단계로 배포할 수 있다. 이는 전체 소프트웨어 개발 라이프 사이클을 더욱 효율적으로 해주어 팀의 생산성을 더 끌어올릴 수 있다.\n프로그래머들이 IaC를 사용하여 sandbox 환경을 생성하여 독립된 공간에서 안전하게 개발할 수 있게 할 수 있다. 같은 방식으로 테스트를 돌리기 위해 production 환경을 복사해야 하는 QA 전문가들도 사용할 수 있다. 결과적으로 배포 시에 infrastructure as code는 하나의 단계가 될 것이다.\nLower Cost IaC의 주된 장점 중 하나는 의심할 여지 없이 인프라 관리의 비용이 줄어든다는 것이다. IaC를 통해 cloud computing을 하면 극적으로 비용을 줄일 수 있다. 이는 하드웨어에 많은 시간을 사용하지 않아도 됨을 의미하고 이를 관리할 사람을 고용하지 않아도 되며 저장할 물리적인 장소를 만들거나 대여하지 않아도 됨을 의미한다. 하지만 IaC는 기회비용이라 부르는 다른 미묘한 방식으로 비용을 더 줄여준다.\n보았듯이 똑똑하고, 높은 급료를 받는 전문가가 자동화 할 수 있는 작업을 수행하는 것은 돈 낭비이다. 이제 모든 포커스는 기업에 더 가치있는 일에 맞춰져야 한다. 그리고 자동화 전략을 사용하면 편하다. 이를 사용하여 수동적이고 느리고 에러가 나기 쉬운 작업을 수행하는 것으로부터 엔지니어들을 해방시켜주고 더 중요한 일에 집중할 수 있게 한다.\nHow Does IaC Work? IaC 툴은 어떻게 작동하는지가 굉장히 다양하지만 이를 일반적으로 두가지 종류로 나눠볼 수 있다. 하나는 imperative approach를 따르는 것이고 다른 하나는 declarative approach를 따르는 것이다. 이 위의 카테고리를 프로그래밍 언어 패러다임과 엮을 수 있다면 완벽하다.\nimperative approach는 순서를 제공하는 것이다. 이는 명령어나 지시사항의 순서를 정의하여 인프라가 최종적인 결과를 가지게 하는 것이다.\ndeclarative approach는 완하는 결과를 정의하는 것이다. 명백하게 원하는 결과로 가는 단계들의 순서를 정의하지 않고, 어떻게 최종 결과가 보여야 하는지만 정의한다.\nLearn Some Best Practices 이제 IaC 전략의 모범사례를 확인해 볼 것이다.\n 코드가 하나의 믿을 수 있는 소스로부터 나온다. 명시적으로 모든 인프라 설정을 설정 파일 안에 작성해야 한다. 설정 파일은 인프라 관리 문제에 대해서 단 하나의 관리포인트이다. 모든 설정 파일에 대해 Version Control을 하라. 이는 말할 필요도 없겠지만, 모든 코드는 source control이 되어야 한다. 인프라 스펙에 대한 약간의 문서화만 필요하다. 이 포인트는 첫번째의 논리적인 결과이다. 설정 파일이 단일 소스이므로, 문서화가 필요하지 않다. 외부 문서는 실제 설정과 싱크가 잘 안맞을 수 있지만 설정 파일은 그럴 이유가 없다. 설정을 테스트하고 모니터한다. IaC는 코드로 모든 코드와 같이 테스트될 수 있다. 따라서 가능하면 테스트해라. IaC에 대한 테스트와 모니터링을 하여 production에 어플리케이션을 배포하기 전에 서버에 문제가 있는지 확인할 수 있다.  Resources At Your Disposal 다음은 IaC를 배우기 좋은 유용한 리소스들이다.\n Wikipedia’s definition Edureka’s Chef tutorial Ibexlabs’s.The Top 7 Infrastructure As Code Tools For Automation TechnologyAdvice’s Puppet vs. Chef: Comparing Configuration Management Tools  Infrastructure as Code Saves You Time and Money IaC는 DevOps 움직임의 중요한 부분이다. cloud computing이 많은 수동 IT 고나리의 문제점을 해결하는 데 첫 번째 단계라고 본다면 IaC는 다음의 논리적인 단계가 될 것이다. 이는 cloud computing의 모든 가능성을 열어주고 개발자와 다른 전문가들로부터 수동적이고 에러가 발생하기 쉬운 업무를 없애준다. 또한 소프트웨어 개발 라이프사이클의 효율성을 늘리고 비용을 절감한다. IaC와 함께 Retrace같은 툴을 쓰는것도 좋다. Retrace는 코드 레벨의 Application Performance Manager 솔루션으로 전체 개발 라이프사이클에서 어플리케이션의 퍼포먼스를 관리하고 모니터하게 할 수 있다. 에러 추적이나 로그 관리, 어플리케이션 메트릭과 같은 또한 많은 다른 기능들을 가지고 있다.\n"
},
{
	"uri": "http://kimmj.github.io/cicd/deploy-strategy/",
	"title": "Deploy Strategy",
	"tags": ["deploy", "cicd", "canary", "blue-green", "roll-out"],
	"description": "",
	"content": "Deploy Strategy 실제 시스템을 운용할 때 중요하게 여겨지는 것 중 하나가 downtime을 없애는 것이다. 새로운 업데이트가 있을 때마다 해당 인스턴스가 동작하지 않는다면, 자주 업데이트 하는 것이 어려워질 수 있습니다. 따라서 deploy strategy를 가지고 어떻게 downtime을 줄이는지 알아보도록 하겠습니다.\nCanary canary deploy는 트래픽 비율을 바꾸어가며 배포하는 전략입니다. 이해하기 편하도록 Kubernetes 환경이라고 생각해 보도록 하겠습니다. (또는 LoadBalancer가 있어서 부하를 분산하고 있다고 생각하면 좋을 것 같습니다.) 이 때 업데이트된 버전을 따로 올리고 트래픽을 old:new = 100:0으로 줍니다. 이러면 새로운 버전이 정상적으로 실행할 준비가 될 때까지는 우리의 인스턴스가 정상적으로 동작하고 있을 것입니다.\n준비가 되었다면, old:new = 90:10처럼 약간의 트래픽을 새로운 버전으로 흘려줍니다. 이 어플리케이션이 만약 웹사이트라면, 전체 유저 중 10%의 사람만이 새로운 버전의 웹사이트를 보게 될 것입니다.\n이 때 각종 통계라던지 테스트를 통해 새로운 버전에 문제가 없는지 확인합니다. 혹시나 문제가 발생하더라도, 10%의 사람만이 문제를 경험하게 될 것입니다. 문제점이 발견되면 다시 old:new = 100:0으로 트래픽을 돌려버리면 이전의 잘 돌아가던 상태로 복구할 수 있습니다.\n이런식으로 새로운 버전의 트래픽을 능동적으로 조금씩 늘려가며 여러 지표를 확인하고 정상적이라고 판단되면 old:new = 0:100으로 변경합니다. 그 다음 이전 버전을 삭제하면 이제 완전히 새로운 버전으로 업데이트 된 것입니다.\n이 방식은 특정 부분을 운용중에 긴급 패치하는 경우 사용할 수 있는 전략입니다. 장애가 발생하더라도 큰 위험 부담이 없기 때문이죠.\n그러나 이를 위해서는 새로운 버전이 얼마나 이전 버전과 호환이 잘 되는지가 중요합니다. 만약 이전 버전과는 너무나도 다른 새로운 버전이 있다면 전체 어플리케이션은 정상적으로 동작하지 않을 수 있습니다.\n             Blue-Green blue-green deploy는 두개의 버전을 동시에 올려놓고, 트래픽을 한번에 바꾸는 전략입니다.\n하나의 인스턴스에 대해 버전을 두가지 올립니다. 이 때, 트래픽의 비율은 old:new = 100:0으로 항상 이전 버전으로만 흐르도록 합니다. 그러다가 어느 순간 old:new = 0:100으로 트래픽을 아예 바꾸어버립니다. 그러면 유저는 항상 새로운 버전만 경험하게 될 것입니다.\n이렇게 새로운 버전을 운용하며 문제점을 파악합니다. canary와는 다르게 문제점이 있을 경우 해당 인스턴스가 아예 중단되어 downtime이 생깁니다. 이럴 때에는 다시 원래대로 트래픽을 old:new = 100:0으로 바꾸면 이전 버전으로 빠르게 roll back이 가능합니다.\n또한 canary에서는 긴급 패치하는 경우, 하나의 인스턴스에 대해서만 행해진다고 하였습니다. 그러나 blue-green의 경우 전체 패키지 또는 어플리케이션에 대해서도 사용할 수 있는 전략입니다. 물론 장비가 2배로 들겠지만, 트래픽만 바꾸면 되니 빠른 roll back이 가능하기 때문에 그 비용을 감수할 수 있습니다.\n당연하게도 하나의 인스턴스만 업데이트하는 경우에도 사용할 수 있습니다. 이 경우에는 다른 인스턴스들과 잘 호환이 되어야 합니다. 반면 전체 어플리케이션에 대해 할 경우 함께 설치되는 인스턴스들끼리의 호환성만 확인하면 됩니다. dependency가 복잡할 경우, 어플리케이션이 빠르게 변화하는 경우 사용해볼 수 있을 것입니다.\n          roll out roll out은 하나의 인스턴스에 대해 Pod 또는 VM이 여러개 떠있다고 가정합니다.\n이 때, 하나씩 순차적으로 새로운 버전으로 변경합니다. downtime을 줄이고 싶다면 업데이트하는 동안에는 트래픽을 흐르지 않도록 하면 될 것입니다.\n이런식으로 순차적으로 새로운 버전으로 변경하여 최종적으로는 모든 노드에 대해 업데이트가 완료될 것입니다.\ncanary와 마찬가지로 다른 버전의 인스턴스들과 잘 동작해야함을 보장해야 합니다. 그래야 두 버전이 동시에 사용되고 있다고 하더라도 정상적으로 어플리케이션이 동작하게 될 것입니다.\n          "
},
{
	"uri": "http://kimmj.github.io/kubernetes/concepts/pods/",
	"title": "Pods",
	"tags": ["kubernetes", "pod"],
	"description": "",
	"content": "Pod\nPod는 Kubernetes에서 가장 작은 배포 오브젝트. 최소 관리 단위. 클러스터에서 실행중인 프로세스를 의미 어플리케이션 콘테이너, 스토리지 리소스, 유일한 network ip, 컨테이너가 어떻게 실행할지를 캡슐화\n각각의 파드는 주어진 어플리케이션에서 단일 인스턴스를 수행한다. -\u0026gt; 어플리케이션을 수직확장하고 싶다면 각 인스턴스에 대해 여러 파드를 생성하면 된다.\n파드는 서비스에서 서로 연관성이 높은 프로세스를 지원하기 위해 디자인되었다. 컨테이너는 리소스와 의존성들을 공유하고, 서로 통신하며, 언제/어떻게 종료하는지에 대해 조정한다.\n파드 내에 여러 컨테이너를 두는 것은 컨테이너가 정말 강하게 결합될 때 이다.\ninit container로 app container가 시작하기 전의 동작을 할 수 있다. 파드 내의 컨테이너는 Networking과 Storage를 공유한다.\nNetworking 각 파드 단위로 네트워크 IP 주소를 할당받는다. 그 내부의 컨테이너는 localhost로 통신하게 되고 외부와의 통신을 위해선 공유중인 네트워크 리소스를 어떻게 분배할 지 합의 및 조정해야한다. (port)\nStorage 파드는 공유하는 저장공간을 volumes로 지정한다. 하나의 컨테이너만 재시동되는 경우에도 데이터를 보존할 수 있다.\n파드는 하나만 생성하지 말 것.\n파드의 재시작과 컨테이너의 재시작을 헷갈려하면 안된다. 파드 자체만으로는 동작하지 않고, 오히려 컨테이너가 동작하는 환경이라고 보면 된다. 삭제 전까지는 유지 되는.\n파드는 컨테이너 전에 VM에서 하나의 VM에 실행하는 것들처럼 하나의 논리적 호스트에서 컨테이너들을 실행하는 개념이다.\n파드 내의 컨테이너들은 IP주소와 port space를 공유한다. 그리고 localhost로 통신한다. + SystemV semaphore, POSIX shared memory로 통신 가능 다른 파드에 있는 컨테이너와는 IP 주소로 통신\nVolumes도 공유 가능\n파드는 컨테이너처럼 임시적인 자원이기 때문에 삭제시 reschedule이 아닌 새로운 동일한 spec의 파드를 생성한다. (새로운 UID로)\nvolume도 파드가 삭제되면 삭제된다.\n각각의 파드는 보통 하나의 어플리케이션의 여러 인스턴스를 담당하지 않는다.\n왜 하나의 컨테이너에서 여러 프로그램을 돌리지 않는가?\n 투명성 쓰기 쉬움 소프트웨어 의존성 제거 효율성  privileged 플래그로 LINUX단의 조작을 할 수 있다.\nPod Lifecycle Pod의 status 필드는 PodStatus의 phase 필드이다.\nPod의 phase는 간단하게 Pod가 위치한 lifecycle의 상위 개념에서의 요약이다.\nphase 의 value들\n Pending : Pod가 kubernetes 시스템에 의해 받아들여졌지만 하나 이상의 container image가 생성되지 않은 상태. Running : Pod가 node에 바운드되고 모든 container들이 생성되었다. 최소한 하나의 container가 실행 중이거나 시작 또는 재시작 중이다. Succeeded : 모든 container가 성공적으로 종료되었고, 재시작되지 않는다. Failed : 모든 container가 정료되었고, 최소 하나의 container가 failure 상태이다. Unknown : 어떤 이유로 인해 Pod의 state를 얻어낼 수 없다. 보통 파드의 호스트와 통신이 안되는 문제.  Container probe\nkubelet이 container에 대해 수행하는 진단. container에서 구현된 Handler를 호출함.\n ExecAction: 컨테이너 내부에서 지정된 명령어를 실행한다. 종료 코드가 0이면 성공. TCPSocketAction: Container의 IP 주소에서 특정 port에 대해 TCP를 확인한다. port가 열려있으면 성공. HTTPGetAction: HTTP Get 요청을 한다. 200\u0026lt;= status code \u0026gt; 400일 경우 성공.  3가지 probe들\n livenessProbe: container가 실행 중인지 나타냄. liveness probe가 실패하면 kubelet은 container를 죽이고, 이 컨테이너는 restart policy를 실행한다. redinessProbe: container가 service requests를 받을 준비가 되었는지 나타냄. readiness probe가 실패할 경우 endpoint controller는 Pod의 IP 주소를 Pod와 매칭되는 Service들의 endpoints에서 삭제한다. initial delay 이전의 default 값은 Failure이다. startupProbe: container 내부의 application이 시작되었는지를 나타냄. 다른 probe들은 startup probe가 성공할 때까지 비활성화 상태.  livenessProbe를 사용해야하는 상황\ncontainer가 crash되었을 때 실행하는 process가 이미 있다면 사실 livenessProbe는 사용하지 않아도 됨. 만약 container에 문제가 있을 때 이를 재시작하고 싶으면 livenessProbe를 지정하고 restartPolicy를 설정한다.\nreadinessProbe를 사용해야하는 상황\nprobe가 성공했을 때에만 트래픽을 흘리고 싶은 경우 사용. 단순하게 삭제할 때 트래픽이 안흐르게 하고 싶은 경우에는 사용하지 않아도 알아서 됨.\nstartupProbe를 사용해야하는 상황\n컨테이너가 initialDelaySeconds + failureThreshold × periodSeconds 이후에 시작될 경우 사용해야함.\nRestart policy\nAlways, OnFailure, Never. default는 Always. restartPolicy는 Pod 내의 모든 container에 적용된다. restartPolicy는 exponential back-off delay로 재시작된다. 성공적으로 실행되고 나서 10분이 지나면 초기화된다.\nPod lifetime\n일반적으로 Pod는 사람 또는 컨트롤러가 명백하게 이를 지우지 않는 이상 유지된다. control plane은 파드의 총 개수가 지정된 threshold를 초과하면 종료된 파드들(Succeeded 또는 Failed)를 삭제한다.\n컨트롤러는 3가지 타입이 있다.\n Job은 batch computations처럼 종료될것으로 예상되는 Pod이다. ReplicationController, ReplicaSet, Deployment는 종료되지 않을 것으로 예상되는 Pod이다. DaemonSet은 머신마다 하나씩 동작해야하는 Pod이다.  Init Container Init container는 app image에서 사용하지 않는 setup script나 utility들을 포함할 수 있다.\nPod Specification에서 containers 배열과 같은 개위로 작성하면 된다.\nInit container는 completion이 되기 위해 실행된다. 각 init container는 다음 init container가 실행되기 전에 반드시 성공적으로 종료되어야 한다.\ninit container가 실패하면 될때까지 재시작한다. 하지만 Pod의 restartPolicy가 Never이면 재시작하지 않는다.\napp container가 사용할 수 있는 대부분의 필드를 그대로 사용할 수 있다. 일반적인 container와의 차이점은 resource에 대해 다르게 관리된다는 것이다. 또한 completion을 위해 실행되므로 당연하게도 readinessProbe는 사용할 수 없다.\n여러개의 init container를 지정했다면 Kubelet은 순서대로 이를 실행할 것이다.\nInit container 사용하기\n Init container는 app image에는 없는 utility나 custom code를 포함할 수 있다. Init container는 동일한 Pod 내에 있는 app container와는 다른 filesystem view를 가질 수 있다. 따라서 app container는 접근할 수 없는 Secret을 가지고 동작할 수 있다. Init container가 성공할 때까지 Pod의 app container들은 생성되지 않는다. App container보다 안전하게 utility, custom code를 실행시킬 수 있다. 따라서 취약점이 줄어든다.  메인 app container를 실행할 때 필요한 configuration file에 필요한 value들을 주입할 때 사용할 수 있다.\nDetailed behavior Pod가 시작되는 동안 network와 volume들이 초기화 된 후 init container가 순서대로 실행된다. 각 container는 반드시 다음 container가 실행되기 전까지 성공적으로 종료되어야 한다.\nInit container에 대한 spec 변경은 container image에만 가능하다. 그리고 Init container는 idempotent1가 성립해야한다.\nInit container가 실패 시 계속해서 재시작 되는 것을 막으려면 Pod에 activeDeadlineSeconds와 Container에 livenessProbe를 설정하면 된다.\nResource 다루는 법  모든 init container에 대해 가장 높은 resource request나 limit은 effective init request/limit이라고 정의한다. Pod의 effective request/limit은 다음보다 커야한다.  모든 app container의 resource에 대한 request/limit의 합 resource에 대한 effective init request/lmit   effective request/limits를 기준으로 스케쥴링한다. 즉, init container의 resource는 Pod의 life 동안 사용되지 않음을 의미한다. Pod의 effective QoS tier에서 QoS tier는 init container와 app container의 QoS tier와 같다.  init container가 재시작되는 경우  user가 pod specification을 업데이트 하여 init container의 이미지가 변경되었다. App container image의 변화는 app container만 재시작시킨다. Pod infrastructure container가 재시작 되었을 때 restartPolicy가 Always로 설정이 되어있는 상태에서 파드가 재시작 되었을 때 init container가 이전 완료 상태를 저장한 것이 만료되거나 없을 경우  Disruptions 파드는 원래 누군가가(사람 또는 컨트롤러) 지우지 않는다면, 또는 피할 수 없는 하드웨어, 소프트웨어적인 에러가 아니라면 삭제되지 않는다.\n여기서 unavoidable인 경우를 involuntary disruptions라고 부를 것이다. 예시는 다음과 같다.\n hardware failure cluster administrator가 실수로 VM을 삭제 cloud provider나 hypervisor의 장애로 VM이 삭제됨. kernel panic cluster network partition에 의해 node가 cluster에서 사라짐 노드가 out-of-resource여서 pod의 eviction이 실행됨.  voluntary disruption은 application이나 cluster administrator에 의해 시작된 동작들이다. 예시는 다음과 같다.\n 해당 Pod를 관리하고 있던 delployment나 다른 controller의 삭제 deployment의 Pod template update가 재시작을 유발함. 직접적으로 Pod를 삭제  Cluster Administrator는 다음을 할 수도 있다.\n Upgrade를 위한 Draining Node cluster를 scale down 하기 위해 Draining Node 특정 노드에 띄워야 하는 요구사항 때문에 기존에 있던 해당 노드에서 Pod를 제거  Dealing with Disruptions  Pod에게 충분한 양의 resource 할당하기. 고가용성을 원할경우 application을 복제하기 application을 rack또는 zone에 분배하기.  How Disruption Budgets Work PodDisruptionBudget(PDB)를 각 application에 설정할 수 있다. 이는 voluntary disruption 상황에서 동시에 down될 수 있는 pod의 갯수를 제한한다.\nPodDisruptionBudget(PDB)를 사용하려면 Cluster Manager는 Eviction API를 통해서 파드를 삭제해야한다. 직접 삭제할 경우 동작하지 않는다. kubectl drain같은 것이 있다.\nPodDisruptionBudget(PDB)는 involuntary disruption 상황에서는 작동하지 않는다. 하지만 몇개가 종료되는지는 기록하여 budget에 추가한다.\nRolloing upgrade 때문에 파드가 삭제되거나 사용 불가능한 상태일 때에도 PodDisruptionBudget(PDB)는 이를 카운트하지만 PDB때문에 제한되지는 않는다. application의 업데이트 동안 발생한 장애처리는 controller spec에서 정의내린대로 한다.\n  멱등법칙. 여러번 실행하더라도 동일한 결과를 냄. \u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "http://kimmj.github.io/css/greater-than-sign/",
	"title": "Greater Than Sign",
	"tags": ["css"],
	"description": "",
	"content": "\u0026gt;의 의미 \u0026gt;는 child-combinator 입니다.\n다음의 예시를 통해 정확히 어떤 역할을 하는지 알아보도록 하겠습니다.\n\u0026lt;div\u0026gt; \u0026lt;p class=\u0026#34;some_class\u0026#34;\u0026gt;Some text here\u0026lt;/p\u0026gt; \u0026lt;!--Selected [1] --\u0026gt; \u0026lt;blockquote\u0026gt; \u0026lt;p class=\u0026#34;some_class\u0026#34;\u0026gt;More text here\u0026lt;/p\u0026gt; \u0026lt;!--Not selected [2] --\u0026gt; \u0026lt;/blockquote\u0026gt; \u0026lt;/div\u0026gt; 위와 같은 예시에서 div \u0026gt; p.some_class는 div 바로 밑에 있는 p.some_class만을 선택합니다. \u0026lt;blockquote\u0026gt;로 감싸진 p.some_class는 선택되지 않습니다.\n이와는 다르게 space만 사용하는 descendant combinator는 두개의 p.some_class 모두를 선택합니다.\n"
},
{
	"uri": "http://kimmj.github.io/hugo/insert-comment/",
	"title": "Hugo에 Comment 추가하기 (Utterance)",
	"tags": ["hugo", "utterance"],
	"description": "",
	"content": "댓글 서비스 선택 블로그를 운영하는데 관심을 가지기 시작하면서, 기본적으로 jekyll이나 hugo에는 댓글 기능이 없다는 것을 알게 되었습니다. static site를 만드는데 사실 댓글을 지원한다는게 이상한 상황이긴 하지요. 그래도 서드파티의 지원을 받으면 댓글 기능이 가능해집니다. 여러 블로그들을 탐방하며 git page 기능을 사용하는 블로그들에도 댓글이 있는것을 항상 봐왔으니까요.\n따라서 댓글을 어떻게 사용하는지 검색해보게 되었습니다. 대표적인 것이 Disqus 입니다. 실제로 많은 사이트들이 Disqus를 기반으로 댓글 기능을 사용합니다.\n저는 이 hugo 기반 블로그를 만드는 데 큰 도움을 준 https://ryan-han.com/post/etc/creating_static_blog/를 보고 Utterance에 대해 접하게 되었으며 개발자에게는 너무나도 친숙한 깃허브 기반이라는 점이 끌려서 이 서비스를 선택하게 되었습니다.\n적용 방법 적용하는 방법은 너무나도 쉽습니다.\n미리 댓글을 위한 레파지토리를 생각해둡니다(기존에 있는 레파지토리 혹은 댓글만을 위한 레파지토리). 저는 사이트를 렌더링해주는 kimmj.github.io 레파지토리로 선택하였습니다. https://utteranc.es/에 접속합니다. 중간쯤에 보이는 utterances app 하이퍼링크를 클릭합니다. 해당 앱을 적절한 레파지토리에 설치합니다. 설치한 레파지토리를 1번에서 접속한 사이트에 양식에 맞게 기입합니다. Blog Post ↔️ Issue Mapping 섹션에서 적절한 것을 선택합니다. 저는 default 옵션을 사용했습니다. Issue Label은 댓글로 생성된 이슈에 label을 달지, 단다면 어떤 label을 달지 선택하는 것입니다. 저는 comment로 작성했습니다. Theme을 선택합니다. 저는 default 옵션을 사용했습니다. 하단에 생성된 코드를 복사합니다. hugo에서 댓글이 보이게 될 위치에 8번에서 복사한 코드를 붙여넣습니다. 저의 경우 custom-comment.html이라는 파일에 붙여넣기 했습니다. 사이트에 제대로 뜨는지 확인합니다.  후기 이렇게 hugo에 댓글 기능을 추가하였습니다. 생각보다 너무나도 간단했네요. 이 댓글 기능을 하자고 생각하고 나서 적용까지 5분정도 걸렸던 것 같습니다. 댓글도 너무나 친숙한 레이아웃이라 정감이 가는 것 같네요.\nReference  https://github.com/Integerous/TIL/blob/master/ETC/Hugo%2BGithub_Page.md https://utteranc.es/  "
},
{
	"uri": "http://kimmj.github.io/ubuntu/tools/tmux/",
	"title": "Tmux",
	"tags": ["tmux", "ubuntu"],
	"description": "",
	"content": "tmux란? tmux는 하나의 화면에서 여러개의 터미널을 키고싶을 때 사용하는 프로그램으로, ubuntu를 설치하면 기본적으로 설치되는 프로그램입니다.\n다음과 같은 구조를 가집니다.\ntmux ├── session │ ├── windows │ │ ├── pane │ │ └── pane │ └── windows │ ├── pane │ └── pane └── session ├── windows │ ├── pane │ └── pane └── windows ├── pane └── pane session 사용법 먼저 가장 큰 단위인 session을 다루는 방법부터 시작해보도록 하겠습니다.\nsession 생성 tmux 위처럼 tmux를 생성할 수 있습니다. 이 경우 tmux session의 이름은 0부터 차례로 증가하는 숫자로 정의됩니다.\n여기에 session의 이름을 사용자가 정의할 수도 있습니다.\ntmux new -s \u0026lt;my-session\u0026gt; 이렇게 이름을 지어놓으면 용도에 따른 session을 구분할 때 좋습니다.\nsession에 접속하기 이번에는 이미 생성된 session에 접속하는 방법입니다.\ntmux a tmux a -t \u0026lt;my-session\u0026gt; tmux attach tmux attach -t \u0026lt;my-session\u0026gt; -t 옵션을 줘서 이름을 지정할 수도 있고, (임의로 생성된 숫자 또한 마찬가지입니다.) 옵션없이 실행할 경우 가장 최근 열린 session으로 접속합니다.\nsession 확인하기 session어떤 것들이 있는지 보려면 ls를 이용하면 됩니다.\ntmux ls 또는 이미 session에 들어간 상태에서, session들의 리스트를 봄과 동시에 미리보기 화면으로 어떤 작업중이었는지도 볼 수 있습니다.\n[prefix] s 여기서 [prefix]는 일반적으로 Ctrl+b를 의미하며, 사용자에 의해 변경될 수 있습니다.\nsession에서 빠져나오기 session을 빠져나오는 방법에는 두가지가 있습니다.\n 완전히 session을 로그아웃하여 session 삭제하기 session이 계속 돌아가는 상태에서 빠져나오기  1번의 경우는 모든 pane에서 log out을 하면 되므로 생략하도록 하겠습니다. 두번째 session이 계속 돌아가는 상태에서 빠져나오는 방법은 다음과 같습니다.\n[prefix] d session 죽이기 tmux 바깥에서 session을 없애려면 들어가서 로그아웃을 통해 끄는 방법도 있을테지만, kill-session이라는 명령어를 통해서도 session을 없앨 수 있습니다.\ntmux kill-session -t \u0026lt;my-session\u0026gt; session 이름 바꾸기 session에 들어가 있는 상태에서 현재 session의 이름을 변경할 수 있습니다.\n[prefix] $ 그러면 상태표시줄에서 session의 이름을 정해줄 수 있습니다.\nwindows 사용법 windows는 session내의 tab과 같은 존재입니다. session은 큰 사용 목적으로 묶어준다면 windows는 그에따라 tab으로 관리할 필요가 있을 때 사용하면 좋습니다. 물론 session과 pane만 가지고 사용해도 되지만, 그보다 더 유연하게 하려한다면 windows도 알아두는 것이 좋습니다.\nwindows의 생성 windows를 관리하고자 한다면, 우선 session에 들어가 있는 상태여야 합니다.\n[prefix] c 위처럼 windows를 생성하고 나면 아래 tmux 상태표시줄에 0:bash- 1:bash*와 같은 형태로 windows가 추가됨을 볼 수 있습니다. 여기서 *는 현재 사용중인 windows를 의미합니다.\nwindows 움직이기 먼저 기본적으로 앞, 뒤로 움직이는 방법입니다.\n[prefix] n # next window [prefix] p # previous window session에서 미리보기를 사용하여 순회했던 것처럼, windows도 list들을 미리보기형식으로 순회할 수 있습니다.\n[prefix] w windows 이름 변경하기 특정 window에 들어가있는 상태에서 해당 window의 이름을 변경할 수 있습니다.\n[prefix] , windows 죽이기 현재 window를 죽이려면 로그아웃을 하는 방법도 있지만, 강제로 죽이는 방법도 존재합니다.\n[prefix] \u0026amp; panes 다루기 pane이란 tmux의 화면을 분할하는 단위입니다. tmux를 사용하는 가장 큰 이유라고 볼 수 있습니다.\npane 분할하기 [prefix] % # vertical split [prefix] \u0026#34; # horizontal split 위와같은 방법으로 pane을 생성할 수 있습니다.\npane 이동하기 먼저 기본적으로 방향키를 이용하여 움직일 수 있습니다.\n[prefix] \u0026lt;방향키\u0026gt; 일정시간이 지나면 pane내에서의 방향키 입력으로 전환되어 pane을 움직일 수 없으므로 빠르게 움직여줍니다.\npane 위치 바꾸기 pane들을 rotate하는 방법입니다.\n[prefix] ctrl+o # 시계방향으로 회전 [prefix] alt+o # 반시계방향으로 회전 또는 하나를 이동할 수도 있습니다.\n[prefix] { # move the current pane left [prefix] } # move the current pane right pane 크게 보기 pane을 여러개 쓰다가 하나만 크게 보고싶은 경우가 있을 수 있습니다.\n[prefix] z 돌아가는 방법 또한 같은 명령어를 통해 할 수 있습니다.\n[prefix] z pane을 새로운 window로 분할하기 특정 텍스트를 마우스로 복사하거나 여러가지 상황에서 새로운 window로 분할하는 것이 편한 경우가 있습니다.\n[prefix] ! 모든 pane에서 동시에 입력하기 tmux를 통해서 여러개의 서버에 ssh 접속을 한 뒤, 동시에 같은 입력을 하게 할 수도 있습니다.\n[prefix] :set synchronize-panes yes (on) [prefix] :set synchronize-panes no (off) Tips tmux에는 기본 내장된 layout이 있습니다. 이를 통해서 pane들을 resize하지 않고 기본 형식에 맞게 쉽게 변경이 가능합니다. 그 중 가장 자주 사용할 수 있는 것은 다음 두가지입니다.\n[prefix] alt+1 # 수직 [prefix] alt+2 # 수평 Reference  https://gist.github.com/MohamedAlaa/2961058 https://gist.github.com/andreyvit/2921703  "
},
{
	"uri": "http://kimmj.github.io/prometheus/federation/",
	"title": "Federation",
	"tags": ["prometheus", "federation"],
	"description": "",
	"content": "What is Federation 영어 의미 그대로는 \u0026ldquo;연합\u0026quot;이라는 뜻입니다. 즉, Prometheus의 Federation은 여러개의 Prometheus에서 Metric을 가져와 계층구조를 만드는 것을 의미합니다.\n위의 그림에서 너무나도 잘 표현이 되어 있습니다. 그림에서 보시면 상위에 있는 Prometheus에서 하위의 Dev, Staging, Production쪽으로 화살표가 간 것을 볼 수 있습니다. 이는 아래에 있는 Prometheus가 http(s)://\u0026lt;url\u0026gt;/federation으로 보여주는 Metric들을 위쪽에 있는 Prometheus에서 scrape하기 때문입니다.\n저의 상황을 설명해드리고 지나가도록 하겠습니다. 저는 Kubernetes Cluster가 Dev(Canary), Staging, Production과 비슷하게 3개 있었습니다. 여기서 Spinnaker를 통해 Dev에 새로운 이미지들을 배포할 것이고, 이에 대한 Metric을 Canary Analysis를 통해 분석하여 Dev로 배포된 이미지가 이전 Staging의 이미지와 어떻게 다른지 등을 점수화하여 Staging 서버에 배포를 할지 말지 결정하도록 해야하는 상황이었습니다.\n이 때, Spinnaker의 설정상 Prometheus를 연동하고 나서 Canary Config를 설정할 때 하나의 Prometheus만 바라보도록 할 수 있었습니다. 따라서 여러대의 Promethus의 Metric을 비교하기 위해서는 여러대의 Prometheus가 가지고 있는 Metric을 상위개념의 Prometheus가 scrape하도록 해야했습니다. 어떻게 해야하는지 검색해본 결과 Federation이라는 기능이 있는 것을 알게 되었습니다.\nHow to configure Prometheus Federation Prerequisites 우선 여러대의 Prometheus가 필요합니다. 그리고 이를 하나로 모아줄 또 다른 Prometheus가 필요합니다.\n저의 경우 docker-compose를 통해 Prometheus를 구동하여 다른 서버의 Prometheus Metric을 가져오도록 설정하였습니다. Install에 관해서는 다른 문서를 참고해 주시기 바랍니다.\nConfiguring federation 다음은 공식 사이트에 나온 federation의 구성입니다.\nscrape_configs: - job_name: \u0026#39;federate\u0026#39; scrape_interval: 15s honor_labels: true metrics_path: \u0026#39;/federate\u0026#39; params: \u0026#39;match[]\u0026#39;: - \u0026#39;{job=\u0026#34;prometheus\u0026#34;}\u0026#39; - \u0026#39;{__name__=~\u0026#34;job:.*\u0026#34;}\u0026#39; static_configs: - targets: - \u0026#39;source-prometheus-1:9090\u0026#39; - \u0026#39;source-prometheus-2:9090\u0026#39; - \u0026#39;source-prometheus-3:9090\u0026#39; job_name job_name은 static_configs[0].targets에 적힌 Prometheus Metric에 어떤 job=\u0026quot;\u0026lt;job_name\u0026gt;\u0026quot;을 줄지 결정하는 것입니다. 이를 통해 저는 Canary, Stage 서버를 구분하였습니다.\nscrape_interval 얼마나 자주 Metric을 긁어올 지 결정하는 것입니다.\nmetrics_path 어떤 path에서 Metric을 가져오는지 설정합니다. 보통의 경우 federation으로 설정하면 됩니다.\nparams 실제로 \u0026lt;PrometheusUrl\u0026gt;/federation으로 접속해보면 아무것도 뜨지 않습니다. /federation은 param로 매칭이 되는 결과만 리턴하며, 없을 경우 아무것도 리턴하지 않습니다. 따라서 이는 필수 필드이고, 원하는 job만 가져오게 하거나 {job=~\u0026quot;.+\u0026quot;}와 같은 방법으로 모든 Metric을 가져오게도 할 수 있습니다.\nstatic_configs 어떤 Prometheus에서 Metric을 가져올지 결정하는 것입니다.\nValidation 위와같이 설정을 한 뒤, Prometheus에 접속하여 Targets에 들어가 봅니다. 리스트에 설정한 job_name들이 떠있고, UP인 상태로 있으면 정상적으로 구성이 된 것입니다.\nReference https://prometheus.io/docs/prometheus/latest/federation/\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/canaryanalysis/canary-analysis/",
	"title": "Canary Analysis",
	"tags": ["canary", "canary-update", "spinnaker"],
	"description": "",
	"content": "Spinnaker Canary Analysis Spinnaker에는 Canary Analysis라는 자동 분석 도구가 있습니다. Kayenta라는 micro service를 사용하는데, 이를 통해 자동으로 canary deploy가 괜찮은 버전인지를 확인해 줍니다.\n그러나 이 툴은 Spinnaker에서 사용하기에 여간 어려운 것이 아닙니다. 제일 먼저 봉착하는 난관은 바로 \u0026ldquo;어떻게 Canary Analysis를 활성화 하는가?\u0026ldquo;입니다.\n이곳에 방법이 나와있지만, 사실 저도 엄청 많이 헤멨습니다. 저는 bare-metal 환경에서 Kubernetes cluster를 구축하였었고, aws나 azure, gcp는 사용하지 못하는 상황었습니다. (물론 지금도 집에서 VM으로 로컬에 구성하였지만, cloud platform은 언제나 과금때문에 꺼려지게 됩니다.)\n이런 상황에서 어떻게 Canary Analysis를 활성화했는지부터, 어떻게 이를 통해 Metric을 비교하는지까지 한번 알아보도록 하겠습니다.\nPrerequisites 첫번째로 metric service를 선택해야 합니다. 여러가지가 있을 수 있겠지만, 저는 로컬에서 사용할 수 있는 Prometheus를 사용할 것입니다.\n두번째로 가져온 metric의 결과들을 저장해 놓을 storage service가 필요합니다. 저는 Spinnaker를 구성할 때 minio를 storage service로 구축을 했었으므로, 여기에서도 마찬가지로 minio를 통해 데이터를 저장할 것입니다.\nHow to enable Canary Analysis 제일 먼저 hal command를 통해서 Canary Analysis를 활성화시켜야 합니다.\nhal config canary enable 그다음엔 Prometheus를 canary analysis에 사용되도록 설정할 것입니다.\nhal config canary prometheus enable hal config canary prometheus account add my-prometheus --base-url http://192.168.8.22/9090 이처럼 Prometheus 콘솔창이 보이는 url을 입력하면 됩니다. 저는 docker-compose를 통해서 9090 port로 expose 시켰으므로 위와같이 적어주었습니다.\n그 다음에는 metric provider를 설정합니다. 앞서 말했듯이 여기서는 Prometheus를 사용할 것입니다.\nhal config canary edit --default-metrics-store prometheus hal config canary edit --default-metrics-account my-prometheus 위의 두 설정으로 Prometheus가 default metric store로 선택되었습니다. 이는 물론 나중에 canary configuration에서 원하는 것으로 선택할 수도 있습니다. 또한 default account도 my-prometheus라는 이름으로 선택해 주었습니다.\n이번엔 default storage account를 설정할 것입니다. 공식 docs에서는 minio에 관련된 설정방법이 잘 나와있지 않습니다.\n하지만 hal command를 잘 보시면 어떻게 해야할지 감이 약간은 잡히실 것입니다.\n--api-endpoint에는 minio의 url을 적고, --aws-access-key-id에는 minio의 ID였던 minio를 입력합니다. 그리고 --aws-secret-access-key는 minio의 PW인 minio123을 입력합니다.\nhal config artifact s3 account add my-minio \\  --api-endpoint http://192.168.8.22:9000 \\  --aws-access-key-id minio \\  --aws-secret-access-key minio123 그 뒤에는 위에서 입력했던 my-minio storage account를 Canary Analysis에 사용하도록 설정하면 됩니다.\nhal config canary edit --default-storage-account my-minio Validate 제대로 설정을 마쳤으면 pipeline의 config에서 Feature 탭에 Canary가 추가된 것을 볼 수 있습니다. 이를 활성화하면 본격적으로 Canary Analysis를 사용할 수 있습니다.\nReference https://www.spinnaker.io/guides/user/canary/\nhttps://www.spinnaker.io/guides/user/canary/config/\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode10/",
	"title": "Episode10",
	"tags": [],
	"description": "",
	"content": "Hey, it's on the hous.\nTed, as your mentor and spiritual guide, I forbid you from calling her.\nSleep it off, bro.\nThis way, if you pass out in the gutter someone with call me, and I will come get you.\nWhy do they call it \u0026lsquo;karaoke,\u0026rsquo; anyhow?\nYou've moved on. I've moved on.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/change-hostname/",
	"title": "Change Hostname",
	"tags": ["hostname", "ubuntu"],
	"description": "",
	"content": "hostname을 바꾸는 일은 흔치 않지만 최초 셋업할 때 많이 사용하곤 합니다.\n# hostnamectl set-hostname \u0026lt;host name\u0026gt; hostnamectl set-hostname wonderland 변경 후 터미널을 끄고 재접속을 하면 변경된 사항을 볼 수 있습니다.\nhostname "
},
{
	"uri": "http://kimmj.github.io/hugo/ibiza/font-change/",
	"title": "Font Change",
	"tags": ["font", "hugo"],
	"description": "",
	"content": "Ibiza 프로젝트를 진행하는데 폰트가 마음에 들지 않았습니다. 따라서 저는 폰트를 변경하기로 마음먹었습니다.\n먼저, 폰트 설정을 어디서 하는지 알아낼 필요가 있었습니다.\nfind . | grep font 결과를 보니, theme 폴더 안에 제가 사용하는 hugo-theme-learn 테마에서 static/fonts/ 폴더에 폰트들을 저장해두고 있었습니다. 그렇다면 어느 파일에서 어떤 폰트를 사용한다고 설정할까요?\nhugo-theme-learn폴더로 이동하여 어디에 사용되는지 확인해보았습니다.\ngrep -ri \u0026#34;font\u0026#34; 결과가 길게 나오는데요, 여기서 static/css/theme.css 안에 폰트에 대한 설정을 한 것이 보였습니다. 그 파일을 보니, @font-face라는 설정이 보이네요. 여기서 Work Sans라는 폰트를 불러오고 있었습니다.\n이 폰트를 Noto Sans CJK KR이라는 폰트로 바꾸려고 합니다. 따라서 먼저 폰트를 다운로드 받아야 합니다.\n다운로드 페이지 : https://www.google.com/get/noto/#sans-kore\n여기에서 다운로드 버튼을 눌러 폰트를 다운받습니다.\ncurl -o noto-mono.zip https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKkr-hinted.zip 이를 my-custom-theme 폴더 내의 static/fonts 폴더 안에다가 압축해제할 것입니다.\nmv noto-mono.zip mj-custom-theme/static/fonts unzip noto-mono.zip rm noto-mono.zip README 그러고나서 font-face 설정을 바꾸어 보도록 하겠습니다. 처음에는 이 설정으로 폰트가 정말 바뀌는지 확인해보기 위해 현재 사용중인 폰트의 url 부분을 Noto Mono 폰트로 변경해보았습니다.\n@font-face { font-family: \u0026#39;Work Sans\u0026#39;; font-style: normal; font-weight: 500; src: url(\u0026#34;../fonts/NotoSansMonoCJKkr-Bold.otf?#iefix\u0026#34;) format(\u0026#34;embedded-opentype\u0026#34;), url(\u0026#34;../fonts/NotoSansMonoCJKkr-Bold.otf\u0026#34;) format(\u0026#34;woff\u0026#34;), url(\u0026#34;../fonts/Work_Sans_500.woff2\u0026#34;) format(\u0026#34;woff2\u0026#34;), url(\u0026#34;../fonts/Work_Sans_500.svg#WorkSans\u0026#34;) format(\u0026#34;svg\u0026#34;), url(\u0026#34;../fonts/Work_Sans_500.ttf\u0026#34;) format(\u0026#34;truetype\u0026#34;); } 하지만 예상과 다르게 변경되지 않았습니다. 확인해보니 이는 font-weight이라는 설정때문이었습니다. body에 대한 font-weight은 300으로 설정이 되어있었고, 따라서 제가 설정한 폰트가 아닌 font-weight: 300인 폰트를 선택하게 된 것입니다.\n다시한번 body쪽의 font-weight을 500으로 바꾸어 실험해보았습니다.\nbody { font-family: \u0026#34;Work Sans\u0026#34;, \u0026#34;Helvetica\u0026#34;, \u0026#34;Tahoma\u0026#34;, \u0026#34;Geneva\u0026#34;, \u0026#34;Arial\u0026#34;, sans-serif; font-weight: 500; line-height: 1.6; font-size: 18px !important; } 그러자 제가 원하는 폰트로 변경이 된 것을 확인하였습니다. 다시 위로 돌아가서 @font-face 설정을 저의 폰트 이름으로 변경하고 제가 원래 하려던 폰트로 변경하였습니다. font-weight: 300으로 다시 돌려놓았고, 새로운 폰트를 font-weight: 300으로 주었습니다.\n@font-face { font-family: \u0026#39;Noto Mono Sans CJK KR \u0026#39;; font-style: normal; font-weight: 300; src: url(\u0026#34;../fonts/NotoSansMonoCJKkr-Regular.eot?#iefix\u0026#34;) format(\u0026#34;embedded-opentype\u0026#34;), url(\u0026#34;../fonts/NotoSansMonoCJKkr-Regular.woff\u0026#34;) format(\u0026#34;woff\u0026#34;), url(\u0026#34;../fonts/NotoSansMonoCJKkr-Regular.woff2\u0026#34;) format(\u0026#34;woff2\u0026#34;), url(\u0026#34;../fonts/NotoSansMonoCJKkr-Regular.svg#NotoSansMonoCJKkr\u0026#34;) format(\u0026#34;svg\u0026#34;), url(\u0026#34;../fonts/NotoSansMonoCJKkr-Regular.ttf\u0026#34;) format(\u0026#34;truetype\u0026#34;); } 여기서 보시면 format 속성들이 많은 것을 볼 수 있습니다. 이는 브라우저별로 지원하는, 지원하지 않는 폰트들에 대해서 처리를 해주기 위한 것입니다. 저는 폰트를 다운로드 받았을 때 otf 포멧밖에 없었습니다. 따라서 다른 포멧들로 변경해 줄 필요가 있었습니다.\nfont converter : https://onlinefontconverter.com/\n위 사이트에서 제가 필요한 eot, woff, woff2, svg, ttf 파일들로 변환후 저장했습니다.\n이제 body의 css에서 font-family 맨 앞에 앞서 정의한 폰트를 지정해줍니다.\nbody { font-family: \u0026#34;Noto Sans Mono CJK KR\u0026#34;, \u0026#34;Work Sans\u0026#34;, \u0026#34;Helvetica\u0026#34;, \u0026#34;Tahoma\u0026#34;, \u0026#34;Geneva\u0026#34;, \u0026#34;Arial\u0026#34;, sans-serif; font-weight: 300; line-height: 1.6; font-size: 18px !important; } 확인해보니 제대로 적용이 되었네요.\nbefore font change after font change Reference  https://wit.nts-corp.com/2017/02/13/4258 https://aboooks.tistory.com/153 https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/webfont-optimization?hl=ko  "
},
{
	"uri": "http://kimmj.github.io/hugo/hugo-with-html/",
	"title": "HUGO로 HTML이 되지 않을 때 가능하게 하는 방법",
	"tags": ["hugo", "html"],
	"description": "",
	"content": "Hugo는 markdown을 기본적으로 사용하지만 html을 이용해서 좀 더 다양하게 커스터마이징이 가능한 장점도 가지고 있습니다.\n하지만 저는 처음에 html 코드를 사용하게 되면 \u0026lt;!-- raw HTML omitted --\u0026gt;와 같은 줄로 대치가 되곤 했습니다. 구글링 결과 이는 Hugo의 버전이 0.60.0으로 되면서부터 기본적으로 disable 시켰기 때문입니다.\n따라서 다음과 같이 조치를 하면 간단하게 해결이 가능합니다.\n[markup.goldmark.renderer] unsafe= true 위와 같은 설정을 config.toml에 추가하기만 하면 됩니다. 추가를 한 뒤 다시 확인해보면 정상적으로 html 코드가 적용된 모습을 볼 수 있습니다.\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/tips/pipeline-expressions/",
	"title": "Pipeline Expressions",
	"tags": ["spinnaker", "pipeline"],
	"description": "",
	"content": "Spinnaker는 배포를 자동화할 때 사용합니다. 그렇기 때문에 자동화를 위해선 다른 곳에서 사용된 값들을 가지고 와야할 필요성이 생기기도 합니다.\n이 문서에서는 그럴 때 사용할 수 있는 pipeline function에 대해 알아보도록 하겠습니다.\npipeline에서 다른 pipeline의 값들 불러오기 Note: Pipeline expression syntax is based on Spring Expression Language (SpEL).\n 위의 Note에도 적었듯이, Spinnaker는 SpEL을 기반으로 Expressions를 사용합니다. SpEL에 대해 이미 잘 알고있다면 너무나도 좋겠지만, 저는 익숙하지가 않았기 때문에 많은 시행착오를 거쳐서 습득을 하게 되었습니다.\n기본적으로 ${ expression }의 형태를 가지게 됩니다.\n여기서 한가지 기억해 두어야 할 것은 nested가 되지 않는다는 것입니다. 즉, ${ expression1 ${expression2} }가 되지 않습니다.\n언제 pipeline expression을 사용하나요? pipeline expression은 Spinnaker UI로는 해결할 수 없는 문제들을 해결하여줍니다. 예를 들어 특정 stage가 성공했는지의 여부에 따라 stage를 실행할지, 말지 결정하는 방법을 제공해 줍니다. 또는 가장 최근에 deploy된 pod를 알아낸다거나, spinnaker를 통한 canary analysis를 할 때 비교할 두가지 대상을 선택하기 위해 사용할 수도 있습니다.\nSpinnaker는 모든 파이프라인을 JSON 형태로도 관리할 수 있기 때문에, UI에는 없는 값들도 입력할 수 있습니다. 이렇게 좀 더 유연한 방법으로 Spinnaker를 이용하고자 한다면 pipeline expression은 꼭 알아두어야 합니다.\n원하는 값을 어떻게 찾나요? pipeline이 구동되고 나면, Details를 누르고 Source를 눌렀을 때 해당 pipeline의 실행결과가 json형태로 출력됩니다. 이를 VS Code나 다른 편집기를 이용하여, json으로 인식하게 한 뒤, 자동 들여쓰기를 하면 보기 좋게 만들어줍니다.\n이를 통해서 어떤 값을 내가 사용할 지 확인하여 pipeline expression을 작성하면 됩니다.\n내가 작성한 pipeline expression은 어떻게 테스트하나요? 작성한 pipeline expression을 테스트하기 위해 파이프라인을 구동한다는 것은 끔직한 일입니다. Spinnaker는 이를 테스트하기 위해 API endpoint를 제공합니다. 즉, 파이프라인을 다시 구동시키지 않고도 어떤 결과값이 나오는지 확인할 수 있다는 것을 의미합니다.\n테스트 방법은 간단합니다. 다음과 같이 curl을 통해 endpoint로 테스트하면 됩니다.\nPIPELINE_ID=[your_pipeline_id] curl http://api.my.spinnaker/pipelines/$PIPELINE_ID/evaluateExpression \\  -H \u0026#34;Content-Type: text/plain\u0026#34; \\  --data \u0026#39;${ #stage(\u0026#34;Deploy\u0026#34;).status.toString() }\u0026#39; 여기서 api.my.spinnaker는 Gate의 Service를 보고 포트를 참조하여 작성하면 됩니다. 기본값은 localhost:8084입니다. 이렇게 하면 Deploy라는 stage가 성공했을 때 다음과 같은 결과를 볼 수 있습니다.\n{\u0026#34;result\u0026#34;: \u0026#34;SUCCEEDED\u0026#34;} Spinnaker가 expression을 통해 결과를 만들어내지 못한다면 다음과 같이 에러와 로그가 발생합니다.\n{ \u0026#34;detail\u0026#34;: { \u0026#34;{ #stage(\\\u0026#34;Deploy\\\u0026#34;).status.toString() \u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Failed to evaluate [expression] Expression [{ #stage( #root.execution, \\\u0026#34;Deploy\\\u0026#34;).status.toString() ] @0: No ending suffix \u0026#39;}\u0026#39; for expression starting at character 0: { #stage( #root.execution, \\\u0026#34;Deploy\\\u0026#34;).status.toString() \u0026#34;, \u0026#34;exceptionType\u0026#34;:\u0026#34;org.springframework.expression.ParseException\u0026#34;, \u0026#34;level\u0026#34;:\u0026#34;ERROR\u0026#34;, \u0026#34;timestamp\u0026#34;:1531254890849 } ] }, \u0026#34;result\u0026#34;:\u0026#34;${#stage(\\\u0026#34;Deploy\\\u0026#34;).status.toString() \u0026#34; } Reference Spinnaker Docs: https://www.spinnaker.io/guides/user/pipeline/expressions/\n"
},
{
	"uri": "http://kimmj.github.io/spinnaker/tips/",
	"title": "Tips",
	"tags": [],
	"description": "",
	"content": "Spinnaker Tips spinnaker를 운영하며 생기는 팁들을 모아보았습니다.\n"
},
{
	"uri": "http://kimmj.github.io/ansible/create-vm-with-ansible-libvirt/",
	"title": "Create Vm With Ansible Libvirt",
	"tags": ["ansible", "libvirt"],
	"description": "",
	"content": "Ansible은 어떠한 프로세스를 자동화 할 때 사용할 수 있는 툴입니다. 그리고 libvirt는 linux 환경에서 qemu를 이용하여 VM을 생성할 때 사용하는 python 모듈입니다.\n이 두가지를 합하여 Ansible을 통해 VM을 생성하는 방법에 대해 알아보도록 하겠습니다.\nansible-role-libvirt-vm 참조 Github : https://github.com/stackhpc/ansible-role-libvirt-vm\n위의 Github 프로젝트는 libvirt를 ansible에서 사용할 수 있도록 만든 오픈소스입니다. 이를 이용하여 ansible-playbook을 통해 VM을 생성해 볼 것입니다.\n이를 로컬에 clone 합니다.\ngit clone https://github.com/stackhpc/ansible-role-libvirt-vm 테스트 환경 저는 Ubuntu 18.04.3 Desktop을 사용하고 있습니다. 그리고 설치에 사용될 iso는 제 포스트에서 작성한 적이 있었던 preseed.cfg를 이용한 자동 설치 이미지입니다. 따라서 이미지를 넣고 부팅만 하면 실행할 수 있습니다.\nplay.yaml  저는 이러한 play.yaml 파일을 사용하였습니다.\n여기서 cdrom을 사용하였는데, 이미지는 baked-ubuntu.iso를 사용하였습니다.\n또한 장비들에 대한 설정을 xml로 추가적으로 하고싶어서 xml_file을 설정해 주었습니다.\nxml_file또한 업로드 해두었습니다.\n 네트워크는 설정을 빼놓을 경우 설치중에 확인창이 발생하여 기본적으로 NAT를 사용하도록 하였습니다. 이는 필요에 따라 변경을 해야 합니다. 또한 enable_vnc의 경우 virt-manager를 통해 상황의 경과를 확인하고 싶어서 추가하였습니다.\n위의 파일들을 workspace에 두시면 됩니다.\nTest 이렇게까지 한 뒤 play.yaml이 있는 위치에서 시작합니다.\n그러면 ansible-playbook은 ansible-role-libvirt-vm이라는 role을 해당 위치에서 검색하고, 실행이 될 것입니다.\nansible-playbook play.yaml 실행 중 sudo 권한이 필요하다고 할 수도 있습니다. 이럴 경우 sudo su로 잠시 로그인 후 exit로 빠져나오시면 에러가 발생하지 않습니다.\n확인 virt-manager를 통해 GUI 환경에서 실제로 잘 되고 있는지 확인할 수 있습니다.\nvirt-manager preseed.cfg를 사용한 이미지라면 30초 후 설치 언어가 자동으로 영어로 설정이 되면서 계속해서 설치가 진행될 것입니다.\n마치며 vm을 생성하는 일이 잦다면, 이 또한 굉장히 귀찮은 일이 아닐 수 없습니다. 소규모가 아닌 대규모로의 확장성을 생각한다면 당연히 자동화를 하는 것이 올바른 접근이라고 생각합니다.\nVM 설치 자동화의 방법이 여러가지가 있을 것이고 이 방법 또한 그 여러가지 방법 중 하나입니다.\n더 좋은, 더 편한 방법이 있다면 알려주시면 감사하겠습니다.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/unattended-ubuntu/",
	"title": "Unattended Ubuntu",
	"tags": ["ubuntu 18.04 server", "preseed.cfg"],
	"description": "",
	"content": "어디에 좋을까 Ubuntu Server를 설치하기 위해서는 많은 추가 입력이 있어야 합니다. 사용자가 어떻게 설치하기를 원하는지 모르기 때문에, 또 다양한 옵션을 사용자가 선택하기 위해서는 어찌보면 당연한 것이겠지요. 하지만 만약 똑같은 설정을 사용할 것인데, 여러대의 서버에 OS를 설치하는 상황이라고 생각해보면 정말 암울합니다. 온전히 시간을 OS 설치에만 투자하자니 이건 간단한 업무로 인해 다른 업무를 보지 못하게 됩니다. 또 다른 업무와 동시에 하자니 다음 입력창이 뜰 때인지 한번씩 확인해 주어야 합니다.\n따라서 어차피 같은 설정을 한다면, 이러한 설정을 미리 해 놓는 방법이 Ubuntu iso 파일 내부에 있을 것이라고 추측했습니다. 분명 누군가가 이런 불편함을 해결했으리라 생각했죠. 다행이 몇번의 구글링을 통해 preseed.cfg라는 파일이 제가 말했던 사용자의 입력을 미리 정해놓는 파일이라는 것을 알 수 있었습니다.\n이 preseed.cfg 파일을 잘만 활용한다면, 서버에 OS를 설치할 때 불필요한 시간 낭비를 줄일 수 있을 것입니다.\n차라리 VM이었다면, 그냥 VM을 복사해서 IP나 MAC, hostname 같은 것들만 변경해도 됐을 수 있습니다. 하지만 preseed.cfg를 이해하게 되면 언제 어디서든 내가 원하는 설정을 해주는 우분투 설치 파일을 만들 수 있을 것입니다.\n사전 준비 먼저, 설정을 넣어줄 Ubuntu 18.04 Server가 필요합니다. 물론 Ubuntu 18.04 Desktop에도 적용이 될 것으로 보입니다. (검색했을 때 대부분이 Desktop 설치 이미지에 관한 내용이었으니까요.)\n여기서 중요한 점은 live라고 적혀있는 이미지가 아니어야 합니다. live가 붙은 것은 인터넷으로 파일들을 다운로드 받게 되고, 그럴 경우 오프라인 설치가 필요한 환경에서는 적합하지도 않고 작업할 때 필요한 파일 또한 없습니다.\n두번째로 중요한 점은 amd64입니다. 처음에 잘못받고 arm64를 다운받았었는데, 내부 파일들의 폴더 명도 다르고 동작방식도 달라 구글링을 통해 amd64 이미지를 따로 받았습니다.\npreseed.cfg 작성 제가 설정했던 preseed.cfg 파일은 다음과 같습니다.\n 설명은 후에 추가하도록 하겠습니다.\niso 파일 생성하기 크게 순서를 정한다면 이렇게 됩니다.\n initrd.gz를 압축해제한 뒤 preseed.cfg 관련 정보를 initrd.gz에 추가 다시 initrd.gz로 압축 md5sum을 통한 checksum 재생성 genisoimage를 통한 부팅용 이미지 생성  그러나 preseed.cfg를 수정할 때마다 이를 반복하는 것은 여간 귀찮은 일이 아닐 수 없습니다. 그래서 저는 이를 bakeIsoImage.sh이라는 간단한 shell 프로그램으로 만들어서 iso파일을 생성하도록 하였습니다.\n 설치 테스트 위의 방식대로 진행을 했다면 baked-ubuntu.iso라는 파일이 생성되었을 것입니다. 이를 virt-manager나 virtual box등을 통해 가상머신을 생성하여 설치 테스트를 합니다.\n설치를 하면서 아무런 입력을 하지 않았다면, 원래의 의도대로 잘 설치가 된 것이라고 볼 수 있겠네요.\n마치며 preseed.cfg라는 엄청나게 유용한 방법이 있음에도 불구하고, 공식적인 가이드 자체가 많이 없는 상황입니다. 어떤 옵션들이 있는지도 잘 모르고, 설명도 자세히 되어있지 않았습니다. 단지 주어진 것이라고는 공식 문서에서 예시로 제공하는 preseed.cfg 파일 하나와, 다른사람들이 작성해 놓은 파일들 뿐이었습니다.\n저 또한 입력없이 설치하는 우분투 설치 이미지를 만들기 위해 고군분투했습니다. 누군가가 이 글을 통해서 환경에 맞는 설정을 해주는 우분투 설치 이미지를 생성하여 자동화를 할 수 있게된다면 정말 좋을 것 같습니다.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/how-to-edit-boot-parameter-during-install/",
	"title": "How to Edit Boot Parameter During Install",
	"tags": ["ubuntu", "install", "boot parameter"],
	"description": "",
	"content": "Ubuntu 설치할 때 boot parameter가 필요한 상황이 간혹 발생할 수 있습니다.\n특히 저의 경우, preseed.cfg를 수정하기 위해 인스톨러가 질의하는 것이 preseed.cfg의 어떤것과 대응이 되는지를 보기 위해 DEBCONF_DEBUG=5라는 옵션을 boot parameter로 주어야 했습니다. 이 때 사용할 수 있는 방법을 소개드립니다.\n먼저 평소와 같이 ubuntu를 설치하기 위해 설치 이미지를 삽입합니다. 그 다음에는 언어를 선택하시면, 다음으로 넘어가기 전에 메뉴가 뜹니다.\n이 상태에서 F6을 누르시면 옵션을 선택할 수 있고, 이 때 ESC키를 누르면 boot parameter가 하단에 보일 것입니다. 여기서 원하는 boot parameter를 입력하면 됩니다.\n이 때, 위아래 방향키를 누르게 되면 입력했던 내용이 사라지게 됩니다. 따라서 미리 맨 위 install ubuntu에 커서를 올리고 수정하시기 바랍니다.\ninstall 시에 설정으로 넣어버리기 preseed.cfg로 미리 질문에 대한 답을 다 정할 수 있었듯이, boot parameter 또한 미리 설정할 수 있습니다. 해당 파일은 iso 파일을 압축해제 하였을 때, /isolinux/txt.cfg 파일 내에 있습니다.\ngrep -ri \u0026#39;initrd\u0026#39; . 이렇게 검색해 보았을 때 quiet ---이라고 적힌 것들이 있는데, --- 뒤에가 boot parameter로 쓰이는 것들입니다.\nvim으로 /isolinux/txt.cfg 파일을 열고 원하는 설정을 기입하면 됩니다.\n이렇게 원하는 boot parameter를 적었다면, 다시 md5sum을 통해 체크섬을 만들어주어야 합니다. 이에 대한 내용은 앞선 [포스트]({% post_url 2020-01-05-unattended-ubuntu %})에서도 확인할 수 있으니 bakeIsoImage.sh 스크립트를 참조하여 md5sum을 하고 iso 파일을 만들면 됩니다.\n"
},
{
	"uri": "http://kimmj.github.io/ubuntu/how-to-use-sudo-without-password/",
	"title": "How to Use Sudo Without Password",
	"tags": ["sudo", "passwordless", "ubuntu"],
	"description": "",
	"content": "/etc/sudoers는 sudo를 사용할 수 있는 파일입니다. 이 파일을 열어보면 다음과 같은 글이 적혀 있습니다.\n Please consider adding local content in /etc/sudoers.d/ instead of directly modifying this file\n 즉, 직접 이 파일을 수정해서 sudo 권한을 주지 말고, /etc/sudoers.d/ 폴더 내에 파일을 추가하라는 의미입니다.\n이 곳에는 /etc/sudoers와 마찬가지로 계정에 대한 설정을 추가할 수 있습니다. 그리고 /etc/sudoers에서는 \u0026ldquo;NOPASSWD\u0026quot;라는 옵션을 주어 password없이 타 계정의 권한을 가지게 만들 수 있습니다.\n이 두가지를 종합하여 내 linux 계정이 sudo 명령어를 입력할 때, 즉 root 권한을 가지게 될 때 password를 입력하지 않도록 설정할 수 있습니다.\nexport ACCOUNT=$(whoami) echo \u0026#34;$ACCOUNTALL = (root) NOPASSWD:ALL\u0026#34; | sudo tee /etc/sudoers.d/$ACCOUNT sudo chmod 0440 /etc/sudoers.d/$ACCOUNT 이제 sudo 명령어를 쳐도 더 이상 password를 입력하라는 출력이 뜨지 않습니다.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode11/",
	"title": "Episode11",
	"tags": [],
	"description": "",
	"content": "She seems like she might be into me.\nI've moved up in the world.\nOh, well, my word.\nCan we swing by the aprtment so I can change?\nTed, Derek stood me up.\nWhat are the odds?\nOh, nuts.\nGive it a rest, Ted.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode12/",
	"title": "Episode12",
	"tags": [],
	"description": "",
	"content": "We never really clicked.\nTehy were buried in a shallow grave.\nI'm just saying that it's my wedding, too, and I should have a say in it.\nDid you see how fired up she was?\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode13/",
	"title": "Episode13",
	"tags": [],
	"description": "",
	"content": "It was her big break.\nLike just now, when I saw you doing the Chicken Dance out there, I'm not gonna lie to you, big time thunderbolt.\nRobin, care to chime in with anything?\nYou know, there's one little flaw in our plan.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode14/",
	"title": "Episode14",
	"tags": [],
	"description": "",
	"content": "Awkward conversations with middle-aged couples trying to stave off divorce.\nThat snuck up on me.\nI mean, the whole point was not to rush into this.\nHoney, Ted has been going out of his mind waiting for this.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode15/",
	"title": "Episode15",
	"tags": [],
	"description": "",
	"content": "I am smelling dirt.\nYou guys will pick it up.\nPrude-alert.\nSlut-alert.\nWhatevs.\nAs long as you're nailing that.\nListen to you.\nAnd FYI, Shannon and I have decided to wait till we're married.\nWay to step up.\nMy saga continues.\nYou let me dodge a bullet, Big Guy.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode16/",
	"title": "Episode16",
	"tags": [],
	"description": "",
	"content": "I'm flat broke.\nWe bust on each other.\nIt's a date.\nWhere does she get off?\nStop being sarcastic.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode17/",
	"title": "Episode17",
	"tags": [],
	"description": "",
	"content": "Marshall, sidebar.\nTry to keep up.\nNot even Old Reliable.\nBreak a leg.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode18/",
	"title": "Episode18",
	"tags": [],
	"description": "",
	"content": "Sorry to bug you with my problems.\nHe has more sense than that.\nAnd so, really, What's it gonna matter in 50 years if I jump the gun by one night?\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode19/",
	"title": "Episode19",
	"tags": [],
	"description": "",
	"content": "It's an intentional hiatus from girls.\nTed, you're my cabron.\nPeople get a kick out of it.\nGod, that pisses me off.\nI mean, talk about anal.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode20/",
	"title": "Episode20",
	"tags": [],
	"description": "",
	"content": "All tuckered out.\nMan, you really have snapped.\nThat's the spirit.\nOh, Robin, are you tearing up?\nWell, look, if you absolutely must bring Ted, it's not like I'm going to claw my own eyes out if he comes.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode21/",
	"title": "Episode21",
	"tags": [],
	"description": "",
	"content": "This is the high point of my day.\nDuck!\nBut Executive Mischief Consultant Marshall Eriksen reporting for duty.\nI just got in the zone and\u0026hellip;\nI was having second thoughts.\nCan't a brother go apple picking without getting the third degree?\nYou just made my night.\n"
},
{
	"uri": "http://kimmj.github.io/english/himym/season1/episode22/",
	"title": "Episode22",
	"tags": [],
	"description": "",
	"content": "Don't piss off the universe.\nIt's gonna rain cats and dogs, folks.\nBut how are you ever gonna top that?\nI will always treasure it.\nMy camping trip got rained out.\n"
},
{
	"uri": "http://kimmj.github.io/english/",
	"title": "English",
	"tags": [],
	"description": "",
	"content": "English "
},
{
	"uri": "http://kimmj.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/tunneling/",
	"title": "tunneling",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/ubuntu/",
	"title": "ubuntu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/ansible/",
	"title": "ansible",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/ansible-playbooks/",
	"title": "ansible-playbooks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/linux/",
	"title": "linux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/ssh/",
	"title": "ssh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/install/",
	"title": "install",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/jenkins/",
	"title": "jenkins",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/iac/",
	"title": "IaC",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/infrastructure-as-code/",
	"title": "infrastructure-as-code",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/ansible-for-devops/",
	"title": "ansible-for-devops",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/blue-green/",
	"title": "blue-green",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/canary/",
	"title": "canary",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/cicd/",
	"title": "cicd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/deploy/",
	"title": "deploy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/roll-out/",
	"title": "roll-out",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/kubernetes/",
	"title": "kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/pod/",
	"title": "pod",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/css/",
	"title": "css",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/concepts/",
	"title": "concepts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/prometheus/",
	"title": "prometheus",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/hugo/",
	"title": "hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/utterance/",
	"title": "utterance",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/tmux/",
	"title": "tmux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/holiday/",
	"title": "holiday",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/federation/",
	"title": "federation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/canary-update/",
	"title": "canary-update",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/spinnaker/",
	"title": "spinnaker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/air-gaped/",
	"title": "air-gaped",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/minio/",
	"title": "minio",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/instll/",
	"title": "instll",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/kubeadm/",
	"title": "kubeadm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/overview/",
	"title": "overview",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/hostname/",
	"title": "hostname",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/font/",
	"title": "font",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/halyard/",
	"title": "halyard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/proxy/",
	"title": "proxy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/html/",
	"title": "html",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/pipeline/",
	"title": "pipeline",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/blog/",
	"title": "blog",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/record/",
	"title": "record",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/libvirt/",
	"title": "libvirt",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/preseed.cfg/",
	"title": "preseed.cfg",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/ubuntu-18.04-server/",
	"title": "ubuntu 18.04 server",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/boot-parameter/",
	"title": "boot parameter",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/passwordless/",
	"title": "passwordless",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/tags/sudo/",
	"title": "sudo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://kimmj.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
}]